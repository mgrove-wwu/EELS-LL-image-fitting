{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading Hyperspy Utilities and additional libraries\n",
    "#from PySide import QtGui\n",
    "#from PySide.QtGui import QMainWindow, QPushButton, QApplication\n",
    "\n",
    "%matplotlib qt5\n",
    "import numpy as np\n",
    "import numpy.polynomial.polynomial as poly\n",
    "\n",
    "from decimal import Decimal\n",
    "\n",
    "import hyperspy\n",
    "import hyperspy.api as hs\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "from tqdm import tqdm, trange, tnrange, tqdm_notebook\n",
    "\n",
    "import cv2\n",
    "import sys\n",
    "import os\n",
    "\n",
    "from getch import getch, pause\n",
    "\n",
    "from sympy import Symbol\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "import multiprocessing\n",
    "\n",
    "from tkinter import Tk\n",
    "from tkinter.filedialog import askopenfilename, asksaveasfile, askdirectory\n",
    "\n",
    "import mendeleev as mend\n",
    "import sympy\n",
    "\n",
    "import scipy\n",
    "from scipy import ndimage as ndi\n",
    "from scipy.signal import argrelextrema, correlate2d\n",
    "from scipy.optimize import least_squares, curve_fit\n",
    "import scipy.integrate as integrate\n",
    "\n",
    "from mayavi import mlab\n",
    "\n",
    "hs.preferences.gui(toolkit='ipywidgets')\n",
    "\n",
    "#rc-Parameter definition\n",
    "from matplotlib import rc\n",
    "\n",
    "mpl.rcParams['text.latex.unicode'] = True\n",
    "mpl.rcParams['figure.figsize'] = 10, 5\n",
    "mpl.rcParams['figure.dpi'] = 200\n",
    "\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "nice_fonts = {\n",
    "        # Use LaTeX to write all text\n",
    "        \"text.usetex\": True,\n",
    "        \"font.family\": \"serif\",\n",
    "        # Use 12pt font in plots, to match 12pt font in document\n",
    "        \"axes.labelsize\": 10,\n",
    "        \"font.size\": 12,\n",
    "        # Make the legend/label fonts a little smaller\n",
    "        \"legend.fontsize\": 10,\n",
    "        \"xtick.labelsize\": 10,\n",
    "        \"ytick.labelsize\": 10,\n",
    "}\n",
    "mpl.rcParams.update(nice_fonts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# main module / python class [EELS_image_fit] \n",
    "\n",
    "### also includes sub routines that can be used but might lead to unexpected crashes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-2-6be5dbfe33ea>, line 4925)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-6be5dbfe33ea>\"\u001b[0;36m, line \u001b[0;32m4925\u001b[0m\n\u001b[0;31m    if (abs(peak[1]) >= np.nanmin(abs(minimum)):\u001b[0m\n\u001b[0m                                               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Class shall be used to map shear-transformation-zones for an image to visualize \n",
    "# shear-bands by considering energy-shifts of the plasmon-peaks aligned with the ZLP\n",
    "class EELS_image_fit(object): \n",
    "\n",
    "    # Initialize the class for STZ-mapping \n",
    "    def __init__(self,\n",
    "                 filename        = '', \n",
    "                 file            = None,\n",
    "                 is_stack        = False, \n",
    "                 is_lazy         = False, \n",
    "                 binning         = True, \n",
    "                 includes_fits   = False,\n",
    "                 deconv          = False,\n",
    "                 RL_deconv_sigma = 0,\n",
    "                 mkey            = None\n",
    "                ):\n",
    "        \"\"\"\n",
    "        EELS_image_fit: \n",
    "                    With careful analysis of an EELS-image the change of the plasmon energy due\n",
    "                    to the change in topology can be investigated with additional thickness analysis,\n",
    "                    Different outputs are possible to analyze the parameter shifts of the plasmon \n",
    "                    signature in the specimen.\n",
    "                    \n",
    "                    The minimum size of the spectrum image/list supported by this class is: \n",
    "                    (1-dim: 10 | 2-dim: 10*10=100) \n",
    "        ----------------------------------------------------------------------------------------------\n",
    "        Initialization parameters:\n",
    "                    filename: STRING      - specify filename and directory to load the EELS-image generated \n",
    "                                            (e.g. in GATAN)\n",
    "                    file: Hyperspy-Signal - only use this when not using filename. Previously initia-\n",
    "                                            lized Hyperspy Signals object. Read more on the Signals \n",
    "                                            objects http://hyperspy.org/hyperspy-doc/\n",
    "                    is_stack: BOOLEAN     - loading multiple files by a wildcard \"*\"\n",
    "                    \n",
    "                    is_lazy: BOOLEAN      - to analyze big data (e.g. .dm4 - files) can be a problematic\n",
    "                                            thing to due high memory requirements, therefore instead of\n",
    "                                            using a numpy nd.array one can fall back to dask.dask_array\n",
    "                                            resulting in an object which consists of multiple numpy arrays.\n",
    "                                            This makes it possible to only work on parts of the datafile\n",
    "                                            and therefore requiring only a small part of the memory require-\n",
    "                                            ments.\n",
    "                    binning: BOOLEAN      - operate on binned datasets. Due to caution set to FALSE as \n",
    "                                            default! Preferably, the datasets should only be binned using\n",
    "                                            hyperspy to verify correct results.\n",
    "                    RL_deconv_sigma: 0    - if this is set to a value other than 0, Richardson-Lucy deconv-\n",
    "                                            deconvolution is used to estimate the unblurred spectrum \n",
    "                                            filtering out noise due to electron-photon-electron conversion,\n",
    "                                            dark current image and the CCD readout process \n",
    "                                            [for more information see -> doi: 10.1016/S0304-3991(03)00103-7]\n",
    "        \"\"\"\n",
    "        self.Filename          = ''\n",
    "        self.File              = None\n",
    "        self.is_lazy           = False\n",
    "        \n",
    "        self.File_deconv       = None\n",
    "        self.attr_deconv       = deconv\n",
    "        \n",
    "        self.haadf             = None\n",
    "        \n",
    "        self.Fit_Model         = None\n",
    "        \n",
    "        self.all_models        = { '0' : 'VolumePlasmonDrude_leastsq_ls',\n",
    "                                   '1' : 'VolumePlasmonDrude_mpfit_ls',\n",
    "                                   '2' : 'VolumePlasmonDrude_NelderMead_ml',\n",
    "                                   '3' : 'Lorentzian_leastsq_ls',\n",
    "                                   '4' : 'Lorentzian_mpfit_ls',\n",
    "                                   '5' : 'Lorentzian_NelderMead_ml',\n",
    "                                   '6' : 'Gaussian_leastsq_ls',\n",
    "                                   '7' : 'Gaussian_mpfit_ls',\n",
    "                                   '8' : 'Gaussian_NelderMead_ml',\n",
    "                                   '9' : 'Voigt_leastsq_ls',\n",
    "                                   '10' : 'Voigt_mpfit_ls',\n",
    "                                   '11' : 'Voigt_NelderMead_ml'\n",
    "                                 }\n",
    "        self.models_dict       = { }\n",
    "        \n",
    "        self.Chisq             = None\n",
    "        self.red_Chisq         = None\n",
    "        \n",
    "        self.rchisq_mean       = None\n",
    "        self.rchisq_std        = None\n",
    "        \n",
    "        self.eels_axis         = None\n",
    "        self.function_set      = None\n",
    "        self.model_name        = None\n",
    "        self.optimizer         = None   \n",
    "        self.method            = None\n",
    "        \n",
    "        self.ZLP_Emax          = None\n",
    "        self.ZLP_FWHM          = None\n",
    "        self.ZLP_Int           = None\n",
    "        \n",
    "        self.FPP_Emax          = None\n",
    "        self.FPP_FWHM          = None\n",
    "        self.FPP_Int           = None\n",
    "        self.SPP_Emax          = None\n",
    "        self.SPP_FWHM          = None\n",
    "        self.SPP_Int           = None\n",
    "        \n",
    "        self.Ep_q0             = None\n",
    "        \n",
    "        self.param_dict        = {}\n",
    "        \n",
    "        self.linescans         = {}\n",
    "        self.linescan_plots    = {}\n",
    "        self.x0                = None\n",
    "        self.x0_err            = None\n",
    "\n",
    "        self.Elements          = None\n",
    "        self.Concentrations    = None\n",
    "        self.thickness_map     = None\n",
    "        \n",
    "        self.dir_list          = ['Plasmon characteristics', \n",
    "                                  'Thickness Evaluation'\n",
    "                                 ]\n",
    "        \n",
    "        self.roi               = None\n",
    "        self.roi_Ep            = None\n",
    "        self.line              = None\n",
    "        \n",
    "        self.time              = 30\n",
    "        \n",
    "        self.elastic_threshold = None # arithmetic mean of the elastic threshold over the navigation space\n",
    "        self.elastic_intensity = None\n",
    "        \n",
    "        self.load_data(filename, \n",
    "                       file, \n",
    "                       is_stack, \n",
    "                       is_lazy, \n",
    "                       binning,\n",
    "                       RL_deconv_sigma,\n",
    "                       mkey\n",
    "                      )\n",
    "        \n",
    "    \n",
    "    def check_underscores_in_title(self, \n",
    "                                   title,\n",
    "                                   sep='_'\n",
    "                                  ):\n",
    "        \"\"\"\n",
    "        Titles cant have underscores outside of math environment for latex.\n",
    "        This will check and if needed return the corrected title\n",
    "        \"\"\"\n",
    "        title_res=''\n",
    "        \n",
    "        for string in title.split(sep=sep):\n",
    "            title_res += string + ' '\n",
    "        \n",
    "        return title_res\n",
    "        \n",
    "\n",
    "    \n",
    "    def print_file_information(self):\n",
    "        \"\"\"\n",
    "        Printing standard metadata of file for beam and detector information as well as dataset information\n",
    "        and the currently stored models of the file\n",
    "        \"\"\"\n",
    "        if (self.attr_deconv == False):\n",
    "            print(self.File.metadata)\n",
    "            print(self.File.axes_manager)\n",
    "            print(self.File.models)\n",
    "        \n",
    "        else:\n",
    "            print(self.File_deconv.metadata)\n",
    "            print(self.File_deconv.axes_manager)\n",
    "            print(self.File_deconv.models)\n",
    "            \n",
    "        \n",
    "    def yes_or_no(self, question):\n",
    "        \"\"\"\n",
    "        Function for yes-no user input. Returns BOOLEAN value (y = True | n = False)\n",
    "        \"\"\"\n",
    "        reply = str(input(question+' (y/n): ')).lower().strip()\n",
    "        \n",
    "        if (reply == ''):\n",
    "            return self.yes_or_no(\"Pleas Enter\")\n",
    "        \n",
    "        elif (reply[0] == 'y'):\n",
    "            return True\n",
    "        \n",
    "        elif (reply[0] == 'n'):\n",
    "            return False\n",
    "        \n",
    "        else:\n",
    "            return self.yes_or_no(\"Please Enter\")\n",
    "        \n",
    "    \n",
    "    def detector_parameter_gui(self):\n",
    "        \"\"\"\n",
    "        Comments missing\n",
    "        \"\"\"\n",
    "        self.File.set_microscope_parameters()\n",
    "    \n",
    "    \n",
    "    def model_gui(self, model):\n",
    "        \"\"\"\n",
    "        Function to call the model attribute gui and await parameter adjustments until user is finished\n",
    "        \"\"\"\n",
    "        model.gui()\n",
    "        while True:\n",
    "            finished = self.yes_or_no('When finished type (y) :')\n",
    "            if (finished == True):\n",
    "                break\n",
    "        \n",
    "    \n",
    "    def split(self, txt, seps):\n",
    "        \"\"\"\n",
    "        Splitting a string by specified seperators seps taking a tuple as input.\n",
    "        \"\"\"\n",
    "        default_sep = seps[0]\n",
    "\n",
    "        # we skip seps[0] because that's the default seperator\n",
    "        for sep in seps[1:]:\n",
    "            txt = txt.replace(sep, default_sep)\n",
    "        return [i.strip() for i in txt.split(default_sep)]\n",
    "    \n",
    "    \n",
    "    def richard_lucy_deconv(self, sigma):\n",
    "        \"\"\"\n",
    "        Deconvolution using the Richardson-Lucy method using a gaussian \n",
    "        point spread function. Sigma is the standard deviation depending\n",
    "        on the noise contributions. \n",
    "        If we assume that the effect of defocus for the different energy losses \n",
    "        is insignificant, then the PSF does not vary with the position \n",
    "        in the EELS detector. The electron–photon–electron conversion, \n",
    "        the dark current image and the CCD readout process may introduce \n",
    "        poissonian noise.\n",
    "        The readout noise is Gaussian distributed.\n",
    "        As the Poisson noise for larger sample sizes converges to a gaussian\n",
    "        out of simplicity we assume an overall Gaussian approach for \n",
    "        deconvolution.\n",
    "        For more information see:\n",
    "            Improving energy resolution of EELS spectra: an alternative to the \n",
    "            monochromator solution\n",
    "            \n",
    "            A.Gloter,A.Douiri,M.Tencé,C.Colliex\n",
    "        \"\"\"\n",
    "        size = self.File.axes_manager.signal_axes[0].size\n",
    "        \n",
    "        psf  = hs.signals.Signal1D(scipy.signal.gaussian(size, sigma, False))\n",
    "        self.File.richardson_lucy_deconvolution(psf = psf)\n",
    "\n",
    "        \n",
    "    # Routine to load the data\n",
    "    def load_data(self, \n",
    "                  filename, \n",
    "                  file, \n",
    "                  is_stack, \n",
    "                  is_lazy,\n",
    "                  binning,\n",
    "                  RL_deconv_sigma,\n",
    "                  mkey\n",
    "                 ):\n",
    "        \"\"\"\n",
    "        load_data: This routine specifies the alignment of the space dimensions and\n",
    "                   the zero-loss alignment as well as poissonian noise estimation and\n",
    "                   optional model loading. Also it will consider a deconvolution by\n",
    "                   the fourier log method (fully automated - still needs testing).\n",
    "        ----------------------------------------------------------------------------------------------\n",
    "        Initialization parameters:\n",
    "                    filename: STRING - specify filename and directory to load the EELS-image generated \n",
    "                                       (e.g. in GATAN)\n",
    "                    file: Hyperspy-Signal - only use this when not using filename. Previously initia-\n",
    "                                            lized Hyperspy Signals object. Read more on the Signals \n",
    "                                            objects http://hyperspy.org/hyperspy-doc/\n",
    "                    is_stack: BOOLEAN - loading multiple files by a wildcard \"*\"\n",
    "                    \n",
    "                    is_lazy: BOOLEAN - to analyze big data (e.g. .dm4 - files) can be a problematic\n",
    "                                       thing to due high memory requirements, therefore instead of\n",
    "                                       using a numpy nd.array one can fall back to dask.dask_array\n",
    "                                       resulting in an object which consists of multiple numpy arrays.\n",
    "                                       This makes it possible to only work on parts of the datafile\n",
    "                                       and therefore requiring only a small part of the memory require-\n",
    "                                       ments.\n",
    "                                       \n",
    "                    binning: BOOLEAN - should always be set to TRUE for EELS analysis\n",
    "                                       as recommended by hyperspy's documentation.\n",
    "                                       \n",
    "                    deconv: BOOLEAN - specifies usage of the fourier log deconvolution\n",
    "                                      to estimate the single scattered spectrum, isolating\n",
    "                                      the plasmon peak without additional convolution.\n",
    "                                      This can lead to better results, depending on the \n",
    "                                      quality of the SI and robustness of the fourier log\n",
    "                                      method (worse results also possible).\n",
    "        \"\"\"\n",
    "        self.is_lazy      = is_lazy\n",
    "            \n",
    "        if (filename    != ''):\n",
    "            self.File     = hs.load(filename, stack = is_stack, lazy = is_lazy)\n",
    "\n",
    "        elif (file        != None):\n",
    "            if (is_lazy   == True):\n",
    "                self.File = file.as_lazy()\n",
    "            else:\n",
    "                self.File = file\n",
    "        \n",
    "        else:\n",
    "            Tk().withdraw() # we don't want a full GUI, so keep the root window from appearing\n",
    "            filename      = askopenfilename()\n",
    "            self.File     = hs.load(filename, stack = is_stack, lazy = is_lazy)\n",
    "\n",
    "        self.Filename          = self.File.metadata.General.title\n",
    "        \n",
    "        axes                   = self.File.axes_manager.as_dictionary()\n",
    "        for i in range(len(axes)):\n",
    "            axis = axes['axis-' + str(i)]\n",
    "            if (axis['units'] == 'eV'):\n",
    "                self.eels_axis = self.File.axes_manager[i]\n",
    "\n",
    "        including_fits = self.yes_or_no('Does the file include stored models from previous fitting?'\n",
    "                                       )\n",
    "        if (including_fits   == True):\n",
    "                \n",
    "            if (self.attr_deconv == True):\n",
    "                self.File_deconv = self.File\n",
    "                \n",
    "            self.load_model(mkey=mkey)\n",
    "        \n",
    "            \n",
    "            if (is_lazy == True):\n",
    "                if (self.attr_deconv == False):\n",
    "                    self.File.compute()\n",
    "                    \n",
    "                else:\n",
    "                    self.File_deconv.compute()\n",
    "                    \n",
    "            self.elastic_threshold = np.nanmean(\n",
    "                self.File.estimate_elastic_scattering_threshold().data\n",
    "            )\n",
    "            self.elastic_intensity = np.nanmean(\n",
    "                self.File.estimate_elastic_scattering_intensity(self.elastic_threshold).data\n",
    "            )\n",
    "            self.File.metadata.Signal.binned = binning\n",
    "            \n",
    "            print('Aligning datastructure successful. Estimate poissonian noise...')\n",
    "            self.File.estimate_poissonian_noise_variance()\n",
    "        \n",
    "        elif (including_fits == False):\n",
    "            channels_before                     = self.File.axes_manager.signal_size\n",
    "            self.File.data[self.File.data <= 0] = 1\n",
    "            \n",
    "            print('Setting up proper navigation space...')\n",
    "            self.align_dataset()\n",
    "            \n",
    "            if (RL_deconv_sigma != 0):\n",
    "                sigma = RL_deconv_sigma\n",
    "                print('Using Richardson-Lucy-deconvolution to estimate ' +\n",
    "                      'the unblurred spectrum using a standard deviation of ' +\n",
    "                      str(sigma)\n",
    "                     )\n",
    "                self.richard_lucy_deconv(sigma)\n",
    "            \n",
    "            print('Aligning Zero-Loss Peak...')\n",
    "            if (is_lazy == True):\n",
    "                self.File.compute()\n",
    "            \n",
    "            self.File.align_zero_loss_peak(subpixel = True, signal_range=[-5.,5.])\n",
    "        \n",
    "            self.elastic_threshold = np.nanmean(\n",
    "                self.File.estimate_elastic_scattering_threshold().data\n",
    "            )\n",
    "            self.elastic_intensity = np.nanmean(\n",
    "                self.File.estimate_elastic_scattering_intensity(self.elastic_threshold).data\n",
    "            )\n",
    "            self.File.metadata.Signal.binned = binning\n",
    "        \n",
    "            print('Aligning datastructure successful. Estimate poissonian noise...')\n",
    "            self.File.estimate_poissonian_noise_variance()\n",
    "            \n",
    "            if (self.attr_deconv == True):\n",
    "                print('Calculating deconvoluted spectrum...')\n",
    "                self.zlp_deconvolution()\n",
    "            \n",
    "            channels_after   = self.File.axes_manager.signal_size\n",
    "            cropped_channels = channels_before - channels_after\n",
    "            print('Loading process completed. Energy channels cropped by ZLP-Alignment: ' + \n",
    "                  str(cropped_channels) + '[' + str(cropped_channels/channels_before*100) + '%]' +\n",
    "                  '\\n' + 'Channels before: ' + str(channels_before) + '\\n' +\n",
    "                  'Channels after: ' + str(channels_after)\n",
    "                 )\n",
    "        \n",
    "        if (is_lazy == True):\n",
    "            self.File = self.File.as_lazy(copy_variance=True)\n",
    "                \n",
    "            if (self.attr_deconv == True):\n",
    "                self.File_deconv = self.File_deconv.as_lazy(copy_variance=True)\n",
    "            \n",
    "        darkfield = self.yes_or_no('Do you want to load the corresponding darkfield image?\\n' +\n",
    "                                   '(Warning: The dimensions should match exactly for correct functionality.)'\n",
    "                                  )\n",
    "        if (darkfield == True):\n",
    "            self.load_dfimage()\n",
    "        \n",
    "        \n",
    "        print('Please check microscope and detector parameters,\\n' + \n",
    "              'as the metadata from gatan might be incorrectly loaded\\n' +\n",
    "              'Hyperspy.'\n",
    "             )\n",
    "        \n",
    "        if (self.attr_deconv == False):\n",
    "            title      = self.File.metadata.General.title\n",
    "            title_corr = self.check_underscores_in_title(title)\n",
    "\n",
    "            self.File.metadata.General.title = title_corr\n",
    "        \n",
    "        else:\n",
    "            title      = self.File_deconv.metadata.General.title\n",
    "            title_corr = self.check_underscores_in_title(title)\n",
    "\n",
    "            self.File_deconv.metadata.General.title = title_corr\n",
    "        \n",
    "        self.detector_parameter_gui()\n",
    "        \n",
    "    \n",
    "    def load_dfimage(self, rotate=False):\n",
    "        \"\"\"\n",
    "        Loading a corresponding dark field image into class variable for\n",
    "        further processing (always using tk - file dialog)\n",
    "        \"\"\"\n",
    "        Tk().withdraw() # we don't want a full GUI, so keep the root window from appearing\n",
    "        filename_haadf = askopenfilename()\n",
    "        print('Loading ' + filename_haadf)\n",
    "        self.haadf = hs.load(filename_haadf)\n",
    "        if rotate == True:\n",
    "            self.haadf = hs.signals.Signal2D(np.transpose(self.haadf.data))\n",
    "    \n",
    "    \n",
    "    def align_dataset(self):\n",
    "        \"\"\"\n",
    "        align_dataset: By dimension the dataset will be devided into different objects as follows:\n",
    "                           EELS: 1D array specifying Counts/Intensity along the energy loss axis\n",
    "                                 given by offset and gain as defined in the metadata\n",
    "                           EELS-stack: 2D array specifying Counts/Intensity as above (see Object EELS)\n",
    "                                       and 1 navigation axis\n",
    "                           EELS-image: 3D array specifying Counts/Intensity as above (see Object EELS)\n",
    "                                       and 2 navigation axis - therefore the name... :)\n",
    "        ----------------------------------------------------------------------------------------------\n",
    "        Initialization parameters:\n",
    "                    None, all parameters should have been included in the metadata by GATAN or by\n",
    "                    defining the meta information in hyperspy yourself.\n",
    "        \"\"\"\n",
    "        self.File = self.File.as_signal1D(spectral_axis=self.eels_axis)\n",
    "        \n",
    "        self.File.set_signal_type(\"EELS\")\n",
    "        self.File.axes_manager.signal_axes[0].name = 'Energy loss'\n",
    "        \n",
    "        for axis in self.File.axes_manager.navigation_axes:\n",
    "            axis.offset = 0\n",
    "            axis.scale  = abs(axis.scale)\n",
    "\n",
    "    \n",
    "    def zlp_deconvolution(self, lazy):\n",
    "        \"\"\"\n",
    "        Uses Fourier-Log method for deconvolution and elastic scattering threshold to estimate ZLP.\n",
    "        \"\"\"\n",
    "        print(self.elastic_threshold)\n",
    "        zlp              = self.File.isig[:self.elastic_threshold]\n",
    "        self.File_deconv = self.File.fourier_log_deconvolution(zlp)\n",
    "        \n",
    "    \n",
    "    def init_func(self):\n",
    "        \"\"\"\n",
    "        Initialize distribution type for ZLP, FPP, SPP. Three types are currently supported:\n",
    "        func: {'VolumePlasmonDrude', 'Lorentzian', 'Gaussian', 'Voigt'}\n",
    "        \"\"\"\n",
    "        param_init = self.init_model_params()\n",
    "        \n",
    "        zlp_pos    = param_init[0]\n",
    "        zlp_fwhm   = param_init[1]\n",
    "        zlp_int    = param_init[2]\n",
    "        fpp_pos    = param_init[3]\n",
    "        fpp_fwhm   = param_init[4]\n",
    "        fpp_int    = param_init[5]\n",
    "        spp_pos    = param_init[6]\n",
    "        spp_fwhm   = param_init[7]\n",
    "        spp_int    = param_init[8]\n",
    "        \n",
    "        try:\n",
    "            if (self.function_set == 'VolumePlasmonDrude'):\n",
    "\n",
    "                func_1 = hs.model.components1D.Voigt()\n",
    "                func_1.area.value                = zlp_int\n",
    "                func_1.centre.value              = zlp_pos\n",
    "                func_1.FWHM.value                = zlp_fwhm / 2\n",
    "                func_1.gamma.value               = zlp_fwhm / 2\n",
    "                func_1.name = 'Zero_Loss_Peak'\n",
    "                \n",
    "                func_2 = hs.model.components1D.VolumePlasmonDrude(intensity      = fpp_int,\n",
    "                                                                  plasmon_energy = fpp_pos,\n",
    "                                                                  fwhm           = fpp_fwhm\n",
    "                                                                 )\n",
    "                func_2.name = 'First_Plasmon_Peak'\n",
    "\n",
    "                func_3 = hs.model.components1D.VolumePlasmonDrude(intensity      = spp_int,\n",
    "                                                                  plasmon_energy = spp_pos,\n",
    "                                                                  fwhm           = spp_fwhm\n",
    "                                                                 )\n",
    "                func_3.name = 'Second_Plasmon_Peak'\n",
    "                \n",
    "            elif (self.function_set == 'Lorentzian'):\n",
    "\n",
    "                func_1 = hs.model.components1D.Voigt()\n",
    "                func_1.area.value                = zlp_int\n",
    "                func_1.centre.value              = zlp_pos\n",
    "                func_1.FWHM.value                = zlp_fwhm / 2\n",
    "                func_1.gamma.value               = zlp_fwhm / 2\n",
    "                func_1.name = 'Zero_Loss_Peak'\n",
    "                \n",
    "                func_2 = hs.model.components1D.Lorentzian(A      = fpp_int, \n",
    "                                                          centre = fpp_pos,\n",
    "                                                          gamma  = fpp_fwhm / 2\n",
    "                                                         )\n",
    "                func_2.name = 'First_Plasmon_Peak'\n",
    "\n",
    "                func_3 = hs.model.components1D.Lorentzian(A      = spp_int, \n",
    "                                                          centre = spp_pos,\n",
    "                                                          gamma  = spp_fwhm / 2\n",
    "                                                         )\n",
    "                func_3.name = 'Second_Plasmon_Peak'\n",
    "                \n",
    "            elif (self.function_set == 'Gaussian'):\n",
    "\n",
    "                func_1 = hs.model.components1D.Voigt()\n",
    "                func_1.area.value                = zlp_int\n",
    "                func_1.centre.value              = zlp_pos\n",
    "                func_1.FWHM.value                = zlp_fwhm / 2\n",
    "                func_1.gamma.value               = zlp_fwhm / 2\n",
    "                func_1.name = 'Zero_Loss_Peak'\n",
    "\n",
    "                func_2 = hs.model.components1D.Gaussian(A      = fpp_int,\n",
    "                                                        centre = fpp_pos,\n",
    "                                                        sigma  = fpp_fwhm / (2 * np.sqrt( np.log(2) ))\n",
    "                                                       )\n",
    "                func_2.name = 'First_Plasmon_Peak'\n",
    "\n",
    "                func_3 = hs.model.components1D.Gaussian(A      = spp_int,\n",
    "                                                        centre = spp_pos,\n",
    "                                                        sigma  = spp_fwhm / (2 * np.sqrt( np.log(2) ))\n",
    "                                                       )\n",
    "                func_3.name = 'Second_Plasmon_Peak'\n",
    "\n",
    "            elif (self.function_set == 'Voigt'):\n",
    "\n",
    "                func_1 = hs.model.components1D.Voigt()\n",
    "                func_1.area.value                = zlp_int\n",
    "                func_1.centre.value              = zlp_pos\n",
    "                func_1.FWHM.value                = zlp_fwhm / 2\n",
    "                func_1.gamma.value               = zlp_fwhm / 2\n",
    "                func_1.name = 'Zero_Loss_Peak'\n",
    "                \n",
    "                func_2 = hs.model.components1D.Voigt()\n",
    "                func_2.area.value   = fpp_int\n",
    "                func_2.centre.value = fpp_pos\n",
    "                func_2.FWHM.value   = fpp_fwhm / 2\n",
    "                func_2.gamma.value  = fpp_fwhm / 2\n",
    "                func_2.name = 'First_Plasmon_Peak'\n",
    "                \n",
    "                func_3 = hs.model.components1D.Voigt()\n",
    "                func_2.area.value   = spp_int\n",
    "                func_2.centre.value = spp_pos\n",
    "                func_2.FWHM.value   = spp_fwhm / 2\n",
    "                func_2.gamma.value  = spp_fwhm / 2\n",
    "                func_3.name = 'Second_Plasmon_Peak'\n",
    "            \n",
    "            return func_1, func_2, func_3\n",
    "            \n",
    "        except:\n",
    "            print('No distributions initialized. Please try again. For more information, see docstring.')\n",
    "        \n",
    "\n",
    "    \n",
    "    # Function to fit EELS-Spectra with three gaussian\n",
    "    # Another option is to use code in 2nd cell to use extra class\n",
    "    def eels_fit_routine(self, \n",
    "                         function_set='VolumePlasmonDrude', \n",
    "                         fitter='leastsq', \n",
    "                         method='ls', \n",
    "                         samfire=False, \n",
    "                         multithreading=False, \n",
    "                         workers=4,\n",
    "                         auto=True\n",
    "                        ):         \n",
    "        \"\"\"\n",
    "        Routine to initialize fit routine. Storing the calculated model in the loaded file.\n",
    "        \n",
    "        Initialize distribution model for ZLP, FPP, SPP. Three types are currently supported:\n",
    "        function_Set: {'VolumePlasmonDrude', 'Lorentzian', 'Gaussian', 'Voigt'}\n",
    "        \"\"\"\n",
    "        # Initialize serial fitting routine\n",
    "        self.function_set = function_set\n",
    "        self.model_name = function_set + str('_') + fitter + str('_') + method\n",
    "        \n",
    "        if (samfire == False):\n",
    "\n",
    "            self.Fit_Model = self.fit_eels(fitter, \n",
    "                                           method,\n",
    "                                           auto,\n",
    "                                           self.is_lazy\n",
    "                                          )\n",
    "\n",
    "        # Initialize SAMFire (parallel) fitting routine\n",
    "        else:\n",
    "\n",
    "            self.Fit_Model = self.fit_eels_SAMF(fitter, \n",
    "                                                method, \n",
    "                                                multithreading, \n",
    "                                                workers,\n",
    "                                                auto,\n",
    "                                                self.is_lazy\n",
    "                                               )\n",
    "        \n",
    "        print('Model will be stored in file...')\n",
    "        self.Fit_Model.store(name = self.model_name)\n",
    "        self.update_models_dict()\n",
    "        \n",
    "        print('Stored models in file:')\n",
    "        if (self.attr_deconv == False):\n",
    "            print(self.File.models)\n",
    "\n",
    "        elif (self.attr_deconv == True):\n",
    "            print(self.File_deconv.models)\n",
    "            \n",
    "        self.generate_param_maps(method)\n",
    "    \n",
    "    \n",
    "    def init_model_params(self):\n",
    "        \"\"\"\n",
    "        Comments missing\n",
    "        \"\"\"\n",
    "        if (self.attr_deconv == False):\n",
    "            print('Estimate function parameters...')\n",
    "\n",
    "            mean            = self.File.mean()\n",
    "            \n",
    "            if (self.is_lazy == True):\n",
    "                mean.compute()\n",
    "\n",
    "            # estimate peak parameters for the zero loss peak\n",
    "            elastic         = mean.isig[:self.elastic_threshold]\n",
    "\n",
    "            # as ohaver implementation only looks for peaks in the positive energy \n",
    "            # range, the axis will be shifted forward for this calculation.\n",
    "            # the shift will be considered for the peak position afterwards,\n",
    "            # as it behaves linear.\n",
    "            offset          = elastic.axes_manager.signal_axes[0].offset\n",
    "            elastic.axes_manager.signal_axes[0].offset -= offset\n",
    "\n",
    "            axis_elastic    = elastic.axes_manager.signal_axes[0]\n",
    "            amp_zlp         = np.max(elastic, axis=axis_elastic).data[0]\n",
    "            param_elastic   = elastic.find_peaks1D_ohaver(amp_thresh = 0.1*amp_zlp,\n",
    "                                                          maxpeakn   = 1\n",
    "                                                         )\n",
    "\n",
    "            if (len(param_elastic) == 1):\n",
    "                zlp_pos     = param_elastic[0][0][0] + offset\n",
    "                zlp_fwhm    = param_elastic[0][0][2]\n",
    "\n",
    "                zlp_int     = self.elastic_intensity\n",
    "\n",
    "            else:\n",
    "                zlp_pos     = 0. # in eV\n",
    "                zlp_fwhm    = 1. # in eV\n",
    "                zlp_int     = self.elastic_intensity\n",
    "\n",
    "            inelastic       = mean.isig[self.elastic_threshold:]\n",
    "\n",
    "            axis_inelastic  = inelastic.axes_manager.signal_axes[0]\n",
    "            amp_pp          = np.max(inelastic, axis=axis_inelastic).data[0]\n",
    "\n",
    "            param_inelastic = inelastic.find_peaks1D_ohaver(amp_thresh = 0.1*amp_pp,\n",
    "                                                            maxpeakn   = 2\n",
    "                                                           )\n",
    "\n",
    "            if (len(param_inelastic) >= 1):\n",
    "                fpp_pos     = param_inelastic[0][0][0]\n",
    "                fpp_fwhm    = param_inelastic[0][0][2]\n",
    "\n",
    "                if (self.function_set == 'VolumePlasmonDrude'):\n",
    "                    fpp_int = amp_pp\n",
    "\n",
    "                else:\n",
    "                    FPP_signal  = inelastic.isig[fpp_pos - fpp_fwhm : fpp_pos + fpp_fwhm] \n",
    "                    fpp_axis    = FPP_signal.axes_manager.signal_axes[0]\n",
    "                    fpp_int     = (1 / scipy.special.erf( np.sqrt( np.log(4) ) ) * \n",
    "                                   FPP_signal.integrate1D(fpp_axis).data[0]\n",
    "                                  )\n",
    "\n",
    "            else:\n",
    "                print('Could not estimate initial parameters. Results could diverge!' +\n",
    "                      'It is highly recommended to adjust the parameters manually.'\n",
    "                     )\n",
    "                fpp_pos     = 15. # in eV\n",
    "                fpp_fwhm    = 2.  # in eV\n",
    "\n",
    "                if (self.function_set == 'VolumePlasmonDrude'):\n",
    "                    fpp_int = amp_pp\n",
    "\n",
    "                else:\n",
    "                    FPP_signal  = inelastic.isig[fpp_pos - fpp_fwhm : fpp_pos + fpp_fwhm] \n",
    "                    fpp_axis    = FPP_signal.axes_manager.signal_axes[0]\n",
    "                    fpp_int     = (1 / scipy.special.erf( np.sqrt( np.log(4) ) ) * \n",
    "                                   FPP_signal.integrate1D(fpp_axis).data[0]\n",
    "                              )\n",
    "\n",
    "            if (len(param_inelastic) == 2):\n",
    "                spp_pos     = param_inelastic[0][1][0]\n",
    "                spp_fwhm    = param_inelastic[0][1][2]\n",
    "\n",
    "                if (self.function_set == 'VolumePlasmonDrude'):\n",
    "                    spp_int = amp_pp * 0.3\n",
    "\n",
    "                else:\n",
    "                    SPP_signal  = inelastic.isig[spp_pos - spp_fwhm : spp_pos + spp_fwhm] \n",
    "                    spp_axis    = SPP_signal.axes_manager.signal_axes[0]\n",
    "                    spp_int     = (1 / scipy.special.erf( np.sqrt( np.log(4) ) ) * \n",
    "                                   SPP_signal.integrate1D(spp_axis).data[0]\n",
    "                                  )\n",
    "\n",
    "            else:\n",
    "                spp_pos     = 2 * fpp_pos\n",
    "                spp_fwhm    = 2 * fpp_fwhm\n",
    "\n",
    "                if (self.function_set == 'VolumePlasmonDrude'):\n",
    "                    spp_int = amp_pp * 0.3\n",
    "\n",
    "                else:\n",
    "                    SPP_signal  = inelastic.isig[spp_pos - spp_fwhm : spp_pos + spp_fwhm] \n",
    "                    spp_axis    = SPP_signal.axes_manager.signal_axes[0]\n",
    "                    spp_int     = (1 / scipy.special.erf( np.sqrt( np.log(4) ) ) * \n",
    "                                   SPP_signal.integrate1D(spp_axis).data[0]\n",
    "                                  )\n",
    "\n",
    "            if (fpp_int > zlp_int or spp_int > zlp_int):\n",
    "                print('Attention: The intensity of one of the Plasmon peaks is\\n' + \n",
    "                      '           higher than the Zero-loss intensity!\\n' + \n",
    "                      '           The model should be monitored carefully.\\n' +\n",
    "                      '           It is recommended to gather a new spectrum of\\n' +\n",
    "                      '           a sample with smaller thickness to minimize\\n' +\n",
    "                      '           the inelastically scattered part of the spectrum!'\n",
    "                     )\n",
    "\n",
    "            return zlp_pos, zlp_fwhm, zlp_int, fpp_pos, fpp_fwhm, fpp_int, spp_pos, spp_fwhm, spp_int\n",
    "        \n",
    "        else:\n",
    "            print('Estimate function parameters...')\n",
    "\n",
    "            mean            = self.File.mean()\n",
    "            if (self.is_lazy == True):\n",
    "                mean.compute()\n",
    "\n",
    "            # estimate peak parameters for the zero loss peak\n",
    "            elastic         = mean.isig[:a.elastic_threshold]\n",
    "\n",
    "            # as ohaver implementation only looks for peaks in the positive energy \n",
    "            # range, the axis will be shifted forward for this calculation.\n",
    "            # the shift will be considered for the peak position afterwards,\n",
    "            # as it behaves linear.\n",
    "            offset          = elastic.axes_manager.signal_axes[0].offset\n",
    "            elastic.axes_manager.signal_axes[0].offset -= offset\n",
    "\n",
    "            axis_elastic    = elastic.axes_manager.signal_axes[0]\n",
    "            amp_zlp         = 0\n",
    "            zlp_pos     = 0 + offset\n",
    "            zlp_fwhm    = 1\n",
    "\n",
    "            zlp_int     = 0\n",
    "\n",
    "            inelastic       = mean.isig[self.elastic_threshold:]\n",
    "\n",
    "            axis_inelastic  = inelastic.axes_manager.signal_axes[0]\n",
    "            amp_pp          = np.max(inelastic, axis=axis_inelastic).data[0]\n",
    "\n",
    "            param_inelastic = inelastic.find_peaks1D_ohaver(amp_thresh = 0.1*amp_pp,\n",
    "                                                            maxpeakn   = 2\n",
    "                                                           )\n",
    "            \n",
    "            if (len(param_inelastic) >= 1):\n",
    "                fpp_pos     = param_inelastic[0][0][0]\n",
    "                fpp_fwhm    = param_inelastic[0][0][2]\n",
    "                    \n",
    "                if (fpp_pos < self.elastic_threshold or fpp_pos > 50.):    \n",
    "                    fpp_pos     = 15.\n",
    "                    fpp_fwhm    = 2.\n",
    "\n",
    "                if (self.function_set == 'VolumePlasmonDrude'):\n",
    "                    fpp_int     = amp_pp\n",
    "\n",
    "                else:\n",
    "                    FPP_signal  = inelastic.isig[fpp_pos - fpp_fwhm : fpp_pos + fpp_fwhm] \n",
    "                    fpp_axis    = FPP_signal.axes_manager.signal_axes[0]\n",
    "                    fpp_int     = (1 / scipy.special.erf( np.sqrt( np.log(4) ) ) * \n",
    "                                   FPP_signal.integrate1D(fpp_axis).data[0]\n",
    "                                  )\n",
    "\n",
    "            else:\n",
    "                print('Could not estimate initial parameters. Results could diverge!' +\n",
    "                      'It is highly recommended to adjust the parameters manually.'\n",
    "                     )\n",
    "                fpp_pos     = 15. # in eV\n",
    "                fpp_fwhm    = 2.  # in eV\n",
    "\n",
    "                if (self.function_set == 'VolumePlasmonDrude'):\n",
    "                    fpp_int     = amp_pp\n",
    "\n",
    "                else:\n",
    "                    FPP_signal  = inelastic.isig[fpp_pos - fpp_fwhm : fpp_pos + fpp_fwhm] \n",
    "                    fpp_axis    = FPP_signal.axes_manager.signal_axes[0]\n",
    "                    fpp_int     = (1 / scipy.special.erf( np.sqrt( np.log(4) ) ) * \n",
    "                                   FPP_signal.integrate1D(fpp_axis).data[0]\n",
    "                              )\n",
    "\n",
    "            if (len(param_inelastic) == 2):\n",
    "                spp_pos     = param_inelastic[0][1][0]\n",
    "                spp_fwhm    = param_inelastic[0][1][2]\n",
    "                    \n",
    "                if (spp_pos <= fpp_pos or spp_pos > 75.):\n",
    "                    spp_pos     = 2 * fpp_pos\n",
    "                    spp_fwhm    = 2 * fpp_fwhm\n",
    "\n",
    "                if (self.function_set == 'VolumePlasmonDrude'):\n",
    "                    spp_int = amp_pp * 0.3\n",
    "\n",
    "                else:\n",
    "                    SPP_signal  = inelastic.isig[spp_pos - spp_fwhm : spp_pos + spp_fwhm] \n",
    "                    spp_axis    = SPP_signal.axes_manager.signal_axes[0]\n",
    "                    spp_int     = (1 / scipy.special.erf( np.sqrt( np.log(4) ) ) * \n",
    "                                   SPP_signal.integrate1D(spp_axis).data[0]\n",
    "                                  )\n",
    "\n",
    "            else:\n",
    "                spp_pos     = 2 * fpp_pos\n",
    "                spp_fwhm    = 2 * fpp_fwhm\n",
    "\n",
    "                if (self.function_set == 'VolumePlasmonDrude'):\n",
    "                    spp_int = 0\n",
    "\n",
    "                else:\n",
    "                    spp_int     = 0\n",
    "\n",
    "            return zlp_pos, zlp_fwhm, zlp_int, fpp_pos, fpp_fwhm, fpp_int, spp_pos, spp_fwhm, spp_int\n",
    "        \n",
    "        \n",
    "    def init_model(self, \n",
    "                   mean = False\n",
    "                  ):\n",
    "        \"\"\"\n",
    "        Comments missing\n",
    "        \"\"\"\n",
    "        if (self.attr_deconv == False):\n",
    "                \n",
    "            offset = self.File.axes_manager['Energy loss'].offset\n",
    "            scale  = self.File.axes_manager['Energy loss'].scale\n",
    "            size   = self.File.axes_manager['Energy loss'].size\n",
    "\n",
    "            e_max  = float(int(scale * size + offset))\n",
    "            \n",
    "            if (mean == True):\n",
    "                model               = self.File.mean().create_model(\n",
    "                    auto_background = False\n",
    "                )\n",
    "\n",
    "            elif (mean == False):\n",
    "                model               = self.File.create_model(\n",
    "                    auto_background = False\n",
    "                )\n",
    "                \n",
    "            func1, func2, func3 = self.init_func()\n",
    "            params              = self.init_model_params()\n",
    "\n",
    "            model.set_signal_range(-self.elastic_threshold, \n",
    "                                   e_max\n",
    "                                  )\n",
    "            model.extend([func1, func2, func3])\n",
    "\n",
    "            self.set_model_params(model, \n",
    "                                  params = params, \n",
    "                                  func   = 'Zero_Loss_Peak'\n",
    "                                 )\n",
    "            self.set_model_params(model, \n",
    "                                  params = params, \n",
    "                                  func   = 'First_Plasmon_Peak'\n",
    "                                 )\n",
    "            self.set_model_params(model, \n",
    "                                  params = params, \n",
    "                                  func   = 'Second_Plasmon_Peak'\n",
    "                                 )\n",
    "\n",
    "            self.set_second_plasmonenergy(model)\n",
    "\n",
    "            return model, params\n",
    "                \n",
    "        else:\n",
    "                \n",
    "            offset = self.File_deconv.axes_manager['Energy loss'].offset\n",
    "            scale  = self.File_deconv.axes_manager['Energy loss'].scale\n",
    "            size   = self.File_deconv.axes_manager['Energy loss'].size\n",
    "\n",
    "            e_max  = float(int(scale * size + offset))\n",
    "        \n",
    "            if (mean == True):\n",
    "                model               = self.File_deconv.mean().create_model(\n",
    "                    auto_background = False\n",
    "                )\n",
    "\n",
    "            elif (mean == False):\n",
    "                model               = self.File_deconv.create_model(\n",
    "                    auto_background = False\n",
    "                )\n",
    "\n",
    "            func1, func2, func3 = self.init_func()\n",
    "            params              = self.init_model_params()\n",
    "            \n",
    "            # disable n-th order scattering for n=2 (set SPP-parameters to 0), \n",
    "            # larger order scattering should not occur due to sample thickness\n",
    "            # recommended for TEM analysis\n",
    "            # as Tuples cannot be accessed by indexing, transformation for\n",
    "            # Tuple -> List -> Tuple is needed\n",
    "            params_SPP_contrib_0 = list(params)\n",
    "            params_SPP_contrib_0[6]          = 0\n",
    "            params_SPP_contrib_0[7]          = 0\n",
    "            params_SPP_contrib_0[8]          = 0\n",
    "            params                           = tuple(params_SPP_contrib_0)\n",
    "            \n",
    "            model.set_signal_range(self.elastic_threshold, \n",
    "                                   e_max\n",
    "                                  )\n",
    "            model.extend([func1, func2, func3])\n",
    "\n",
    "            self.set_model_params(model, \n",
    "                                  params = params, \n",
    "                                  func   = 'Zero_Loss_Peak'\n",
    "                                 )\n",
    "            self.set_model_params(model, \n",
    "                                  params = params, \n",
    "                                  func   = 'First_Plasmon_Peak'\n",
    "                                 )\n",
    "            self.set_model_params(model, \n",
    "                                  params = params, \n",
    "                                  func   = 'Second_Plasmon_Peak'\n",
    "                                 )\n",
    "\n",
    "            self.set_second_plasmonenergy(model)\n",
    "\n",
    "            return model, params\n",
    "    \n",
    "    \n",
    "    def set_second_plasmonenergy(self, model):\n",
    "        \"\"\"\n",
    "        Comments missing\n",
    "        \"\"\"\n",
    "        if (self.function_set != 'VolumePlasmonDrude'):\n",
    "            model.components.Second_Plasmon_Peak.centre.twin_function_expr         = '2*x'\n",
    "            model.components.Second_Plasmon_Peak.centre.inverse_twin_function_expr = 'x/2'\n",
    "            model.components.Second_Plasmon_Peak.centre.twin                       = model.components.First_Plasmon_Peak.centre\n",
    "\n",
    "        else:\n",
    "            model.components.Second_Plasmon_Peak.plasmon_energy.twin_function_expr          = '2*x'\n",
    "            model.components.Second_Plasmon_Peak.plasmon_energy.inverse_twin_function_expr  = 'x/2'\n",
    "            model.components.Second_Plasmon_Peak.plasmon_energy.twin                        = model.components.First_Plasmon_Peak.plasmon_energy\n",
    "    \n",
    "    \n",
    "    def fit_zlp_only(self, \n",
    "                     model, \n",
    "                     fitter, \n",
    "                     method,\n",
    "                     bounded\n",
    "                    ):\n",
    "        \"\"\"\n",
    "        Comments missing\n",
    "        \"\"\"\n",
    "        mean, params = self.init_model(mean = True)\n",
    "        \n",
    "        self.set_model_params(model, \n",
    "                              params = params, \n",
    "                              func   = 'Zero_Loss_Peak'\n",
    "                             )\n",
    "        \n",
    "        self.set_bounds(mean, \n",
    "                        bounded\n",
    "                       )\n",
    "        \n",
    "        mean.components.Zero_Loss_Peak.active      = True\n",
    "        mean.components.First_Plasmon_Peak.active  = False\n",
    "        mean.components.Second_Plasmon_Peak.active = False\n",
    "\n",
    "        zlp_pos             = params[0]\n",
    "        zlp_fwhm            = params[1]\n",
    "        \n",
    "        mean.set_signal_range(zlp_pos - zlp_fwhm, \n",
    "                              zlp_pos + zlp_fwhm\n",
    "                             )\n",
    "        \n",
    "        mean.fit(fitter  = fitter, \n",
    "                 method  = method,\n",
    "                 bounded = bounded\n",
    "                )\n",
    "        \n",
    "        self.set_model_params(model, \n",
    "                              mean = mean, \n",
    "                              func = 'Zero_Loss_Peak'\n",
    "                             )\n",
    "        \n",
    "        \n",
    "    def fit_pp_only(self,\n",
    "                    upper_bound,\n",
    "                    model, \n",
    "                    fitter, \n",
    "                    method,\n",
    "                    bounded\n",
    "                   ):\n",
    "        \"\"\"\n",
    "        Comments missing\n",
    "        \"\"\"\n",
    "        mean, params = self.init_model(mean = True)\n",
    "        \n",
    "        self.set_model_params(model, \n",
    "                              params = params, \n",
    "                              func   = 'First_Plasmon_Peak'\n",
    "                             )\n",
    "        \n",
    "        self.set_model_params(model, \n",
    "                              params = params, \n",
    "                              func   = 'Second_Plasmon_Peak'\n",
    "                             )\n",
    "        \n",
    "        self.set_bounds(mean, \n",
    "                        bounded\n",
    "                       )\n",
    "        \n",
    "        mean.components.Zero_Loss_Peak.active      = False\n",
    "        mean.components.First_Plasmon_Peak.active  = True\n",
    "        mean.components.Second_Plasmon_Peak.active = True\n",
    "\n",
    "        self.set_second_plasmonenergy(mean)\n",
    "        \n",
    "        # used for the signal range to exclude additional influence\n",
    "        fpp_pos  = params[3]\n",
    "        fpp_fwhm = params[4]\n",
    "        spp_pos  = params[6]\n",
    "        spp_fwhm = params[7]\n",
    "        \n",
    "        mean.set_signal_range(fpp_pos - fpp_fwhm, \n",
    "                              spp_pos + spp_fwhm\n",
    "                             )\n",
    "\n",
    "        mean.fit(fitter=fitter, \n",
    "                 method=method,\n",
    "                 bounded=bounded\n",
    "                )\n",
    "        \n",
    "        self.set_model_params(model, \n",
    "                              mean = mean, \n",
    "                              func = 'First_Plasmon_Peak'\n",
    "                             )\n",
    "        \n",
    "        self.set_model_params(model, \n",
    "                              mean = mean, \n",
    "                              func = 'Second_Plasmon_Peak'\n",
    "                             )\n",
    "        \n",
    "        return self.get_plasmonenergy(mean)\n",
    "        \n",
    "    \n",
    "    def fit_fpp_only(self, \n",
    "                     upper_bound,\n",
    "                     model, \n",
    "                     fitter, \n",
    "                     method,\n",
    "                     bounded\n",
    "                    ):\n",
    "        \"\"\"\n",
    "        Comments missing\n",
    "        \"\"\"\n",
    "        mean, params = self.init_model(mean = True)\n",
    "        \n",
    "        self.set_bounds(mean, \n",
    "                        bounded\n",
    "                       )\n",
    "        \n",
    "        mean.components.Zero_Loss_Peak.active      = False\n",
    "        mean.components.First_Plasmon_Peak.active  = True\n",
    "        mean.components.Second_Plasmon_Peak.active = False\n",
    "\n",
    "        mean.set_signal_range(self.elastic_threshold, #see above\n",
    "                              upper_bound #eV\n",
    "                             )\n",
    "        \n",
    "        mean.fit(fitter=fitter, \n",
    "                 method=method,\n",
    "                 bounded=bounded\n",
    "                )\n",
    "        \n",
    "        plasmonenergy = self.get_plasmonenergy(mean)\n",
    "        \n",
    "        mean.set_signal_range(self.elastic_threshold, #see above\n",
    "                              2.5 * plasmonenergy \n",
    "                              #using better estimate of plasmon energy range to increase accuracy \n",
    "                             )\n",
    "\n",
    "        mean.fit(fitter  = fitter, \n",
    "                 method  = method,\n",
    "                 bounded = bounded\n",
    "                )\n",
    "        \n",
    "        self.set_model_params(model, \n",
    "                              mean = mean, \n",
    "                              func = 'First_Plasmon_Peak'\n",
    "                             )\n",
    "        \n",
    "        return self.get_plasmonenergy(mean)\n",
    "        \n",
    "    \n",
    "    def get_plasmonenergy(self,\n",
    "                          mean\n",
    "                         ):\n",
    "        \"\"\"\n",
    "        Comments missing\n",
    "        \"\"\"\n",
    "        if (self.function_set == 'VolumePlasmonDrude'):\n",
    "            plasmonenergy = mean.components.First_Plasmon_Peak.plasmon_energy.value\n",
    "        \n",
    "        else:\n",
    "            plasmonenergy = mean.components.First_Plasmon_Peak.centre.value\n",
    "            \n",
    "        return plasmonenergy\n",
    "    \n",
    "    \n",
    "    def set_bounds(self, \n",
    "                   model, \n",
    "                   bounded\n",
    "                  ):\n",
    "        \"\"\"\n",
    "        Comments missing\n",
    "        \"\"\"\n",
    "        if (self.function_set == 'Voigt'):\n",
    "            \n",
    "            if (bounded):\n",
    "                model.components.Zero_Loss_Peak.area.bmin   = (self.elastic_intensity \n",
    "                                                               - self.elastic_intensity / 2\n",
    "                                                              )\n",
    "                model.components.Zero_Loss_Peak.area.bmax   = (self.elastic_intensity \n",
    "                                                               + self.elastic_intensity / 2\n",
    "                                                              )\n",
    "                model.components.Zero_Loss_Peak.centre.bmin = -self.elastic_threshold\n",
    "                model.components.Zero_Loss_Peak.centre.bmax = self.elastic_threshold\n",
    "                model.components.Zero_Loss_Peak.FWHM.bmin   = 0.\n",
    "                model.components.Zero_Loss_Peak.FWHM.bmax   = 2 * self.elastic_threshold\n",
    "                model.components.Zero_Loss_Peak.gamma.bmin  = 0.\n",
    "                model.components.Zero_Loss_Peak.gamma.bmax  = 2 * self.elastic_threshold\n",
    "\n",
    "\n",
    "                model.components.First_Plasmon_Peak.area.bmin   = 0.\n",
    "                model.components.First_Plasmon_Peak.area.bmax   = (self.elastic_intensity \n",
    "                                                                   + self.elastic_intensity / 2\n",
    "                                                                  )\n",
    "                model.components.First_Plasmon_Peak.centre.bmin = self.elastic_threshold\n",
    "                model.components.First_Plasmon_Peak.centre.bmax = 50.\n",
    "                model.components.First_Plasmon_Peak.FWHM.bmin   = 0.\n",
    "                model.components.First_Plasmon_Peak.FWHM.bmax   = 50.\n",
    "                model.components.First_Plasmon_Peak.gamma.bmin  = 0.\n",
    "                model.components.First_Plasmon_Peak.gamma.bmax  = 50.\n",
    "\n",
    "\n",
    "                model.components.Second_Plasmon_Peak.area.bmin   = 0.\n",
    "                model.components.Second_Plasmon_Peak.area.bmax   = (self.elastic_intensity \n",
    "                                                                    + self.elastic_intensity / 2\n",
    "                                                                   )\n",
    "                model.components.Second_Plasmon_Peak.centre.bmin = self.elastic_threshold\n",
    "                model.components.Second_Plasmon_Peak.centre.bmax = 100.\n",
    "                model.components.Second_Plasmon_Peak.FWHM.bmin   = 0.\n",
    "                model.components.Second_Plasmon_Peak.FWHM.bmax   = 100.\n",
    "                model.components.Second_Plasmon_Peak.gamma.bmin  = 0.\n",
    "                model.components.Second_Plasmon_Peak.gamma.bmax  = 100.\n",
    "                \n",
    "            \n",
    "            else:\n",
    "                model.components.Zero_Loss_Peak.area.ext_force_positive        = True\n",
    "                model.components.Zero_Loss_Peak.centre.ext_force_positive      = False\n",
    "                model.components.Zero_Loss_Peak.FWHM.ext_force_positive        = True\n",
    "                model.components.Zero_Loss_Peak.gamma.ext_force_positive       = True\n",
    "                model.components.First_Plasmon_Peak.area.ext_force_positive    = True\n",
    "                model.components.First_Plasmon_Peak.centre.ext_force_positive  = True\n",
    "                model.components.First_Plasmon_Peak.FWHM.ext_force_positive    = True\n",
    "                model.components.First_Plasmon_Peak.gamma.ext_force_positive   = True\n",
    "                model.components.Second_Plasmon_Peak.area.ext_force_positive   = True\n",
    "                model.components.Second_Plasmon_Peak.centre.ext_force_positive = True\n",
    "                model.components.Second_Plasmon_Peak.FWHM.ext_force_positive   = True\n",
    "                model.components.Second_Plasmon_Peak.gamma.ext_force_positive  = True\n",
    "        \n",
    "        \n",
    "        elif (self.function_set == 'Lorentzian'):\n",
    "            \n",
    "            if (bounded):\n",
    "                model.components.Zero_Loss_Peak.area.bmin   = (self.elastic_intensity \n",
    "                                                               - self.elastic_intensity / 2\n",
    "                                                              )\n",
    "                model.components.Zero_Loss_Peak.area.bmax   = (self.elastic_intensity \n",
    "                                                               + self.elastic_intensity / 2\n",
    "                                                              )\n",
    "                model.components.Zero_Loss_Peak.centre.bmin = -self.elastic_threshold\n",
    "                model.components.Zero_Loss_Peak.centre.bmax = self.elastic_threshold\n",
    "                model.components.Zero_Loss_Peak.FWHM.bmin   = 0.\n",
    "                model.components.Zero_Loss_Peak.FWHM.bmax   = 2 * self.elastic_threshold\n",
    "                model.components.Zero_Loss_Peak.gamma.bmin  = 0.\n",
    "                model.components.Zero_Loss_Peak.gamma.bmax  = 2 * self.elastic_threshold\n",
    "\n",
    "\n",
    "                model.components.First_Plasmon_Peak.A.bmin      = 0.\n",
    "                model.components.First_Plasmon_Peak.A.bmax      = (self.elastic_intensity \n",
    "                                                                   + self.elastic_intensity / 2\n",
    "                                                                  )\n",
    "                model.components.First_Plasmon_Peak.centre.bmin = self.elastic_threshold\n",
    "                model.components.First_Plasmon_Peak.centre.bmax = 50.\n",
    "                model.components.First_Plasmon_Peak.gamma.bmin  = 0.\n",
    "                model.components.First_Plasmon_Peak.gamma.bmax  = 50.\n",
    "\n",
    "\n",
    "                model.components.Second_Plasmon_Peak.A.bmin      = 0.\n",
    "                model.components.Second_Plasmon_Peak.A.bmax      = (self.elastic_intensity \n",
    "                                                                    + self.elastic_intensity / 2\n",
    "                                                                   )\n",
    "                model.components.Second_Plasmon_Peak.centre.bmin = self.elastic_threshold\n",
    "                model.components.Second_Plasmon_Peak.centre.bmax = 100.\n",
    "                model.components.Second_Plasmon_Peak.gamma.bmin  = 0.\n",
    "                model.components.Second_Plasmon_Peak.gamma.bmax  = 100.\n",
    "\n",
    "            \n",
    "            else:\n",
    "                model.components.Zero_Loss_Peak.area.ext_force_positive        = True\n",
    "                model.components.Zero_Loss_Peak.centre.ext_force_positive      = False\n",
    "                model.components.Zero_Loss_Peak.FWHM.ext_force_positive        = True\n",
    "                model.components.Zero_Loss_Peak.gamma.ext_force_positive       = True\n",
    "                model.components.First_Plasmon_Peak.A.ext_force_positive       = True\n",
    "                model.components.First_Plasmon_Peak.centre.ext_force_positive  = True\n",
    "                model.components.First_Plasmon_Peak.gamma.ext_force_positive   = True\n",
    "                model.components.Second_Plasmon_Peak.A.ext_force_positive      = True\n",
    "                model.components.Second_Plasmon_Peak.centre.ext_force_positive = True\n",
    "                model.components.Second_Plasmon_Peak.gamma.ext_force_positive  = True\n",
    "                \n",
    "                \n",
    "        elif (self.function_set == 'Gaussian'):\n",
    "            \n",
    "            if (bounded):\n",
    "                model.components.Zero_Loss_Peak.area.bmin   = (self.elastic_intensity \n",
    "                                                               - self.elastic_intensity / 2\n",
    "                                                              )\n",
    "                model.components.Zero_Loss_Peak.area.bmax   = (self.elastic_intensity \n",
    "                                                               + self.elastic_intensity / 2\n",
    "                                                              )\n",
    "                model.components.Zero_Loss_Peak.centre.bmin = -self.elastic_threshold\n",
    "                model.components.Zero_Loss_Peak.centre.bmax = self.elastic_threshold\n",
    "                model.components.Zero_Loss_Peak.FWHM.bmin   = 0.\n",
    "                model.components.Zero_Loss_Peak.FWHM.bmax   = 2 * self.elastic_threshold\n",
    "                model.components.Zero_Loss_Peak.gamma.bmin  = 0.\n",
    "                model.components.Zero_Loss_Peak.gamma.bmax  = 2 * self.elastic_threshold\n",
    "\n",
    "\n",
    "                model.components.First_Plasmon_Peak.A.bmin      = 0.\n",
    "                model.components.First_Plasmon_Peak.A.bmax      = (self.elastic_intensity \n",
    "                                                                   + self.elastic_intensity / 2\n",
    "                                                                  )\n",
    "                model.components.First_Plasmon_Peak.centre.bmin = self.elastic_threshold\n",
    "                model.components.First_Plasmon_Peak.centre.bmax = 50.\n",
    "                model.components.First_Plasmon_Peak.sigma.bmin  = 0.\n",
    "                model.components.First_Plasmon_Peak.sigma.bmax  = 50.\n",
    "\n",
    "\n",
    "                model.components.Second_Plasmon_Peak.A.bmin      = 0.\n",
    "                model.components.Second_Plasmon_Peak.A.bmax      = (self.elastic_intensity \n",
    "                                                                    + self.elastic_intensity / 2\n",
    "                                                                   )\n",
    "                model.components.Second_Plasmon_Peak.centre.bmin = self.elastic_threshold\n",
    "                model.components.Second_Plasmon_Peak.centre.bmax = 100.\n",
    "                model.components.Second_Plasmon_Peak.sigma.bmin  = 0.\n",
    "                model.components.Second_Plasmon_Peak.sigma.bmax  = 100.\n",
    "            \n",
    "\n",
    "            else:\n",
    "                model.components.Zero_Loss_Peak.area.ext_force_positive        = True\n",
    "                model.components.Zero_Loss_Peak.centre.ext_force_positive      = False\n",
    "                model.components.Zero_Loss_Peak.FWHM.ext_force_positive        = True\n",
    "                model.components.Zero_Loss_Peak.gamma.ext_force_positive       = True\n",
    "                model.components.First_Plasmon_Peak.A.ext_force_positive       = True\n",
    "                model.components.First_Plasmon_Peak.centre.ext_force_positive  = True\n",
    "                model.components.First_Plasmon_Peak.sigma.ext_force_positive   = True\n",
    "                model.components.Second_Plasmon_Peak.A.ext_force_positive      = True\n",
    "                model.components.Second_Plasmon_Peak.centre.ext_force_positive = True\n",
    "                model.components.Second_Plasmon_Peak.sigma.ext_force_positive  = True\n",
    "                \n",
    "            \n",
    "        elif (self.function_set == 'VolumePlasmonDrude'):\n",
    "            \n",
    "            if (bounded):\n",
    "                model.components.Zero_Loss_Peak.area.bmin   = (self.elastic_intensity \n",
    "                                                               - self.elastic_intensity / 2\n",
    "                                                              )\n",
    "                model.components.Zero_Loss_Peak.area.bmax   = (self.elastic_intensity \n",
    "                                                               + self.elastic_intensity / 2\n",
    "                                                              )\n",
    "                model.components.Zero_Loss_Peak.centre.bmin = -self.elastic_threshold\n",
    "                model.components.Zero_Loss_Peak.centre.bmax = self.elastic_threshold\n",
    "                model.components.Zero_Loss_Peak.FWHM.bmin   = 0.\n",
    "                model.components.Zero_Loss_Peak.FWHM.bmax   = 2 * self.elastic_threshold\n",
    "                model.components.Zero_Loss_Peak.gamma.bmin  = 0.\n",
    "                model.components.Zero_Loss_Peak.gamma.bmax  = 2 * self.elastic_threshold\n",
    "\n",
    "\n",
    "                model.components.First_Plasmon_Peak.intensity.bmin      = 0.\n",
    "                model.components.First_Plasmon_Peak.intensity.bmax      = (self.elastic_intensity \n",
    "                                                                           + self.elastic_intensity / 2\n",
    "                                                                          )\n",
    "                model.components.First_Plasmon_Peak.plasmon_energy.bmin = self.elastic_threshold\n",
    "                model.components.First_Plasmon_Peak.plasmon_energy.bmax = 50.\n",
    "                model.components.First_Plasmon_Peak.fwhm.bmin  = 0.\n",
    "                model.components.First_Plasmon_Peak.fwhm.bmax  = 50.\n",
    "\n",
    "\n",
    "                model.components.Second_Plasmon_Peak.intensity.bmin      = 0.\n",
    "                model.components.Second_Plasmon_Peak.intensity.bmax      = (self.elastic_intensity \n",
    "                                                                            + self.elastic_intensity / 2\n",
    "                                                                           )\n",
    "                model.components.Second_Plasmon_Peak.plasmon_energy.bmin = self.elastic_threshold\n",
    "                model.components.Second_Plasmon_Peak.plasmon_energy.bmax = 100.\n",
    "                model.components.Second_Plasmon_Peak.fwhm.bmin  = 0.\n",
    "                model.components.Second_Plasmon_Peak.fwhm.bmax  = 100.\n",
    "\n",
    "\n",
    "            else:\n",
    "                model.components.Zero_Loss_Peak.area.ext_force_positive                = True\n",
    "                model.components.Zero_Loss_Peak.centre.ext_force_positive              = False\n",
    "                model.components.Zero_Loss_Peak.FWHM.ext_force_positive                = True\n",
    "                model.components.Zero_Loss_Peak.gamma.ext_force_positive               = True\n",
    "                model.components.First_Plasmon_Peak.intensity.ext_force_positive       = True\n",
    "                model.components.First_Plasmon_Peak.plasmon_energy.ext_force_positive  = True\n",
    "                model.components.First_Plasmon_Peak.fwhm.ext_force_positive            = True\n",
    "                model.components.Second_Plasmon_Peak.intensity.ext_force_positive      = True\n",
    "                model.components.Second_Plasmon_Peak.plasmon_energy.ext_force_positive = True\n",
    "                model.components.Second_Plasmon_Peak.fwhm.ext_force_positive           = True\n",
    "                \n",
    "    \n",
    "    def set_by_params(self,\n",
    "                      model,\n",
    "                      params,\n",
    "                      func\n",
    "                     ):\n",
    "        \"\"\"\n",
    "        Comments missing\n",
    "        \"\"\"\n",
    "        func_dict = {'Zero_Loss_Peak'      : params[0:3],\n",
    "                     'First_Plasmon_Peak'  : params[3:6],\n",
    "                     'Second_Plasmon_Peak' : params[6:9]\n",
    "                    }\n",
    "\n",
    "        if (self.function_set == 'Voigt' or func == 'Zero_Loss_Peak'):\n",
    "            model.set_parameters_value('area',\n",
    "                                       func_dict[func][2],\n",
    "                                       component_list = [func]\n",
    "                                      )\n",
    "\n",
    "            model.set_parameters_value('gamma',\n",
    "                                       func_dict[func][1] / 2,\n",
    "                                       component_list = [func]\n",
    "                                      )\n",
    "\n",
    "            model.set_parameters_value('FWHM',\n",
    "                                       func_dict[func][1] / 2,\n",
    "                                       component_list = [func]\n",
    "                                      )\n",
    "\n",
    "            if (func != 'Second_Plasmon_Peak'):\n",
    "                model.set_parameters_value('centre',\n",
    "                                           func_dict[func][0],\n",
    "                                           component_list = [func]\n",
    "                                          )\n",
    "\n",
    "        if (self.function_set == 'Lorentzian' and func != 'Zero_Loss_Peak'):\n",
    "            model.set_parameters_value('A',\n",
    "                                       func_dict[func][2],\n",
    "                                       component_list = [func]\n",
    "                                      )\n",
    "\n",
    "            model.set_parameters_value('gamma',\n",
    "                                       func_dict[func][1] / 2,\n",
    "                                       component_list = [func]\n",
    "                                      )\n",
    "\n",
    "            if (func != 'Second_Plasmon_Peak'):\n",
    "                model.set_parameters_value('centre',\n",
    "                                           func_dict[func][0],\n",
    "                                           component_list = [func]\n",
    "                                          )\n",
    "\n",
    "        if (self.function_set == 'Gaussian' and func != 'Zero_Loss_Peak'):\n",
    "            model.set_parameters_value('A',\n",
    "                                       func_dict[func][2],\n",
    "                                       component_list = [func]\n",
    "                                      )\n",
    "\n",
    "            model.set_parameters_value('sigma',\n",
    "                                       func_dict[func][1] / (2 * np.sqrt( np.log(2) )),\n",
    "                                       component_list = [func]\n",
    "                                      )\n",
    "\n",
    "            if (func != 'Second_Plasmon_Peak'):\n",
    "                model.set_parameters_value('centre',\n",
    "                                           func_dict[func][0],\n",
    "                                           component_list = [func]\n",
    "                                          )\n",
    "\n",
    "        if (self.function_set == 'VolumePlasmonDrude' and func != 'Zero_Loss_Peak'):\n",
    "            model.set_parameters_value('intensity',\n",
    "                                       func_dict[func][2],\n",
    "                                       component_list = [func]\n",
    "                                      )\n",
    "\n",
    "            model.set_parameters_value('fwhm',\n",
    "                                       func_dict[func][1],\n",
    "                                       component_list = [func]\n",
    "                                      )\n",
    "\n",
    "            if (func != 'Second_Plasmon_Peak'):\n",
    "                model.set_parameters_value('plasmon_energy',\n",
    "                                           func_dict[func][0],\n",
    "                                           component_list = [func]\n",
    "                                          )\n",
    "    \n",
    "    \n",
    "    def set_by_mean(self,\n",
    "                    model,\n",
    "                    mean,\n",
    "                    func\n",
    "                   ):\n",
    "        \"\"\"\n",
    "        Initializing starting parameters by estimation of mean spectrum of the spectrum image\n",
    "        \"\"\"\n",
    "        func_dict = {'Zero_Loss_Peak'      : mean.components.Zero_Loss_Peak,\n",
    "                     'First_Plasmon_Peak'  : mean.components.First_Plasmon_Peak,\n",
    "                     'Second_Plasmon_Peak' : mean.components.Second_Plasmon_Peak\n",
    "                    }\n",
    "        \n",
    "        if (self.function_set == 'Voigt' or func == 'Zero_Loss_Peak'):\n",
    "            model.set_parameters_value('area',\n",
    "                                       func_dict[func].area.value,\n",
    "                                       component_list = [func]\n",
    "                                      )\n",
    "\n",
    "            model.set_parameters_value('gamma',\n",
    "                                       func_dict[func].gamma.value,\n",
    "                                       component_list = [func]\n",
    "                                      )\n",
    "\n",
    "            model.set_parameters_value('FWHM',\n",
    "                                       func_dict[func].FWHM.value,\n",
    "                                       component_list = [func]\n",
    "                                      )\n",
    "\n",
    "            if (func != 'Second_Plasmon_Peak'):\n",
    "                model.set_parameters_value('centre',\n",
    "                                           func_dict[func].centre.value,\n",
    "                                           component_list = [func]\n",
    "                                          )\n",
    "\n",
    "        if (self.function_set == 'Lorentzian' and func != 'Zero_Loss_Peak'):\n",
    "            model.set_parameters_value('A',\n",
    "                                       func_dict[func].A.value,\n",
    "                                       component_list = [func]\n",
    "                                      )\n",
    "\n",
    "            model.set_parameters_value('gamma',\n",
    "                                       func_dict[func].gamma.value,\n",
    "                                       component_list = [func]\n",
    "                                      )\n",
    "\n",
    "            if (func != 'Second_Plasmon_Peak'):\n",
    "                model.set_parameters_value('centre',\n",
    "                                           func_dict[func].centre.value,\n",
    "                                           component_list = [func]\n",
    "                                          )\n",
    "\n",
    "        if (self.function_set == 'Gaussian' and func != 'Zero_Loss_Peak'):\n",
    "            model.set_parameters_value('A',\n",
    "                                       func_dict[func].A.value,\n",
    "                                       component_list = [func]\n",
    "                                      )\n",
    "\n",
    "            model.set_parameters_value('sigma',\n",
    "                                       func_dict[func].sigma.value,\n",
    "                                       component_list = [func]\n",
    "                                      )\n",
    "\n",
    "            if (func != 'Second_Plasmon_Peak'):\n",
    "                model.set_parameters_value('centre',\n",
    "                                           func_dict[func].centre.value,\n",
    "                                           component_list = [func]\n",
    "                                          )\n",
    "\n",
    "        if (self.function_set == 'VolumePlasmonDrude' and func != 'Zero_Loss_Peak'):\n",
    "            model.set_parameters_value('intensity',\n",
    "                                       func_dict[func].intensity.value,\n",
    "                                       component_list = [func]\n",
    "                                      )\n",
    "\n",
    "            model.set_parameters_value('fwhm',\n",
    "                                       func_dict[func].fwhm.value,\n",
    "                                       component_list = [func]\n",
    "                                      )\n",
    "\n",
    "            if (func != 'Second_Plasmon_Peak'):\n",
    "                model.set_parameters_value('plasmon_energy',\n",
    "                                           func_dict[func].plasmon_energy.value,\n",
    "                                           component_list = [func]\n",
    "                                          )\n",
    "    \n",
    "            \n",
    "    def set_model_params(self, \n",
    "                         model, \n",
    "                         mean   = None,\n",
    "                         params = None,\n",
    "                         func='Zero_Loss_Peak'\n",
    "                        ):\n",
    "        \"\"\"\n",
    "        Comments missing\n",
    "        \"\"\"\n",
    "        if (params != None):\n",
    "            self.set_by_params(model, params, func)\n",
    "            \n",
    "        elif (mean != None):\n",
    "            self.set_by_mean(model, mean, func)\n",
    "    \n",
    "    \n",
    "    def fit_eels(self, \n",
    "                 fitter, \n",
    "                 method,\n",
    "                 auto,\n",
    "                 lazy\n",
    "                ):\n",
    "        \"\"\"\n",
    "        Serial model fitting calculation\n",
    "        \n",
    "            fitter: the optimizer chosen - see hyperspy documentation for \n",
    "                    supported optimizers\n",
    "\n",
    "            method: the minimization method (least squared - 'ls'\n",
    "                                             maximum likelyhood - 'ml'\n",
    "                                             optional: 'custom' - support for \n",
    "                                                       self written minimization method\n",
    "                                            )\n",
    "\n",
    "            auto:   If True: possible adjustments to the starting parameters are possible\n",
    "                             before start of fitting routine accessible by gui\n",
    "\n",
    "            lazy:   usage of dask-arrays instead of standard numpy-arrays to minimize\n",
    "                    memory demand for large datasets (> 4GB | e.g. '.dm4' - files)\n",
    "        \"\"\"\n",
    "        if (self.attr_deconv == False):\n",
    "            print('Reinitialising poissonian noise estimation...')\n",
    "            self.File.estimate_poissonian_noise_variance()\n",
    "            \n",
    "            if (lazy == True):\n",
    "                self.File.metadata.Signal.Noise_properties.variance.compute()\n",
    "            \n",
    "            model, params = self.init_model()\n",
    "\n",
    "            if (method == 'ls'):\n",
    "                bounded = True\n",
    "\n",
    "            else:\n",
    "                bounded = False\n",
    "\n",
    "            self.set_bounds(model, \n",
    "                            bounded\n",
    "                           )\n",
    "\n",
    "            offset = self.File.axes_manager['Energy loss'].offset\n",
    "            scale  = self.File.axes_manager['Energy loss'].scale\n",
    "            size   = self.File.axes_manager['Energy loss'].size\n",
    "\n",
    "            e_max  = float(int(scale * size + offset))\n",
    "\n",
    "            upper_bound = e_max\n",
    "\n",
    "            self.set_second_plasmonenergy(model)\n",
    "            \n",
    "            self.fit_zlp_only(model, \n",
    "                              fitter, \n",
    "                              method,\n",
    "                              bounded\n",
    "                             )\n",
    "            \n",
    "            plasmonenergy = self.fit_pp_only(upper_bound,\n",
    "                                             model, \n",
    "                                             fitter, \n",
    "                                             method,\n",
    "                                             bounded\n",
    "                                            )\n",
    "\n",
    "            model.components.Zero_Loss_Peak.active      = True\n",
    "            model.components.First_Plasmon_Peak.active  = True\n",
    "            model.components.Second_Plasmon_Peak.active = True\n",
    "            \n",
    "            model.set_signal_range(-self.elastic_threshold, \n",
    "                                   2.5 * plasmonenergy\n",
    "                                  )\n",
    "            \n",
    "            if (auto == False):\n",
    "                gui = self.yes_or_no('Do you want to adjust the starting parameters?')\n",
    "                if (gui == True):\n",
    "                    self.model_gui(model)\n",
    "            \n",
    "            print('Correcting poissonian noise for the gain factor of\\n' +\n",
    "                  'the EELS - detector by generating statistics on the\\n' +\n",
    "                  'reduced Chi-squared.'\n",
    "                 )\n",
    "            \n",
    "            mean_rchisq = self.poisson_noise_gain_correction(model,\n",
    "                                                             fitter,\n",
    "                                                             method,\n",
    "                                                             bounded,\n",
    "                                                             plasmonenergy\n",
    "                                                            )\n",
    "            \n",
    "            model.multifit(fitter  = fitter, \n",
    "                           method  = method,\n",
    "                           bounded = bounded\n",
    "                          )\n",
    "        \n",
    "        elif (self.attr_deconv == True):\n",
    "            print('Reinitialising poissonian noise estimation...')\n",
    "            self.File_deconv.estimate_poissonian_noise_variance()\n",
    "            \n",
    "            if (lazy == True):\n",
    "                self.File_deconv.metadata.Signal.Noise_properties.variance.compute()\n",
    "                \n",
    "            model, params = self.init_model()\n",
    "\n",
    "            if (method == 'ls'):\n",
    "                bounded = True\n",
    "\n",
    "            else:\n",
    "                bounded = False\n",
    "\n",
    "            self.set_bounds(model, \n",
    "                            bounded\n",
    "                           )\n",
    "\n",
    "            offset = self.File_deconv.axes_manager['Energy loss'].offset\n",
    "            scale  = self.File_deconv.axes_manager['Energy loss'].scale\n",
    "            size   = self.File_deconv.axes_manager['Energy loss'].size\n",
    "\n",
    "            e_max  = float(int(scale * size + offset))\n",
    "\n",
    "            upper_bound = e_max\n",
    "\n",
    "            model.components.Zero_Loss_Peak.active      = True\n",
    "            model.components.First_Plasmon_Peak.active  = True\n",
    "            model.components.Second_Plasmon_Peak.active = False\n",
    "            \n",
    "            plasmonenergy = self.fit_fpp_only(upper_bound,\n",
    "                                              model, \n",
    "                                              fitter, \n",
    "                                              method,\n",
    "                                              bounded\n",
    "                                             )\n",
    "            \n",
    "            model.set_signal_range(self.elastic_threshold, \n",
    "                                   1.5 * plasmonenergy\n",
    "                                  )\n",
    "            \n",
    "            if (auto == False):\n",
    "                gui = self.yes_or_no('Do you want to adjust the starting parameters?')\n",
    "                if (gui == True):\n",
    "                    self.model_gui(model)\n",
    "                    \n",
    "            print('Correcting poissonian noise for the gain factor of\\n' +\n",
    "                  'the EELS - detector by generating statistics on the\\n:' +\n",
    "                  'reduced Chi-squared.'\n",
    "                 )\n",
    "            \n",
    "            mean_rchisq = self.poisson_noise_gain_correction(model,\n",
    "                                                             fitter,\n",
    "                                                             method,\n",
    "                                                             bounded,\n",
    "                                                             plasmonenergy\n",
    "                                                            )\n",
    "            \n",
    "            model.multifit(fitter  = fitter, \n",
    "                           method  = method,\n",
    "                           bounded = bounded\n",
    "                          )\n",
    "        \n",
    "        self.Chisq       = model.chisq\n",
    "        self.red_Chisq   = model.red_chisq\n",
    "        self.rchisq_mean = np.mean(\n",
    "            self.red_Chisq.data[np.invert(np.isnan(self.red_Chisq.data))]\n",
    "        )\n",
    "        self.rchisq_std  = np.std(\n",
    "            self.red_Chisq.data[np.invert(np.isnan(self.red_Chisq.data))]\n",
    "        )\n",
    "\n",
    "        print('Adj. fit goodness (reduced Chi squared): ', self.rchisq_mean)\n",
    "        print('Standard deviation of adj. fit goodness: ', self.rchisq_std)\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    \n",
    "    def fit_eels_SAMF(self, \n",
    "                      fitter, \n",
    "                      method, \n",
    "                      multithreading, \n",
    "                      workers,\n",
    "                      auto,\n",
    "                      lazy\n",
    "                     ):\n",
    "        \"\"\"\n",
    "        SAMFire model fitting calculation \n",
    "        \n",
    "            fitter: the optimizer chosen - see hyperspy documentation for \n",
    "                    supported optimizers\n",
    "\n",
    "            method: the minimization method (least squared - 'ls'\n",
    "                                             maximum likelyhood - 'ml'\n",
    "                                             optional: 'custom' - support for \n",
    "                                                       self written minimization method\n",
    "                                            )\n",
    "\n",
    "            auto:   If True: possible adjustments to the starting parameters are possible\n",
    "                             before start of fitting routine accessible by gui\n",
    "\n",
    "            lazy:   usage of dask-arrays instead of standard numpy-arrays to minimize\n",
    "                    memory demand for large datasets (> 4GB | e.g. '.dm4' - files)\n",
    "        \"\"\"\n",
    "        if (self.attr_deconv == False):\n",
    "            print('Reinitialising poissonian noise estimation...')\n",
    "            self.File.estimate_poissonian_noise_variance()\n",
    "            \n",
    "            if (lazy == True):\n",
    "                self.File.metadata.Signal.Noise_properties.variance.compute()\n",
    "                \n",
    "            model, params = self.init_model()\n",
    "\n",
    "            if (method == 'ls'):\n",
    "                bounded = True\n",
    "\n",
    "            else:\n",
    "                bounded = False\n",
    "\n",
    "            self.set_bounds(model, bounded)\n",
    "\n",
    "            offset = self.File.axes_manager['Energy loss'].offset\n",
    "            scale  = self.File.axes_manager['Energy loss'].scale\n",
    "            size   = self.File.axes_manager['Energy loss'].size\n",
    "\n",
    "            e_max  = float(int(scale * size + offset))\n",
    "\n",
    "            upper_bound = e_max\n",
    "        \n",
    "            self.set_second_plasmonenergy(model)\n",
    "            \n",
    "            self.fit_zlp_only(model, \n",
    "                              fitter, \n",
    "                              method,\n",
    "                              bounded\n",
    "                             )\n",
    "            \n",
    "            self.fit_pp_only(upper_bound,\n",
    "                             model, \n",
    "                             fitter, \n",
    "                             method,\n",
    "                             bounded\n",
    "                            )\n",
    "            \n",
    "            if (self.function_set == 'VolumePlasmonDrude'):\n",
    "                plasmonenergy = np.nanmean(\n",
    "                    model.components.First_Plasmon_Peak.plasmon_energy.as_signal(\n",
    "                        field='values'\n",
    "                    ).data\n",
    "                )\n",
    "                \n",
    "            \n",
    "            else:\n",
    "                plasmonenergy = np.nanmean(\n",
    "                    model.components.First_Plasmon_Peak.centre.as_signal(\n",
    "                        field='values'\n",
    "                    ).data\n",
    "                )\n",
    "            \n",
    "            model.components.Zero_Loss_Peak.active      = True\n",
    "            model.components.First_Plasmon_Peak.active  = True\n",
    "            model.components.Second_Plasmon_Peak.active = True\n",
    "            \n",
    "            model.set_signal_range(-self.elastic_threshold, \n",
    "                                   2.5 * plasmonenergy\n",
    "                                  )\n",
    "            if (auto == False):\n",
    "                gui = self.yes_or_no('Do you want to adjust the starting parameters?')\n",
    "                if (gui == True):\n",
    "                    self.model_gui(model)\n",
    "            \n",
    "            print('Correcting poissonian noise for the gain factor of\\n' +\n",
    "                  'the EELS - detector by generating statistics on the\\n:' +\n",
    "                  'reduced Chi-squared.'\n",
    "                 )\n",
    "            \n",
    "            mean_rchisq = self.poisson_noise_gain_correction(model,\n",
    "                                                             fitter,\n",
    "                                                             method,\n",
    "                                                             bounded,\n",
    "                                                             plasmonenergy\n",
    "                                                            )\n",
    "            \n",
    "            print('Generating_seeds for SAMFire...')\n",
    "            \n",
    "            self.generate_seeds(model,\n",
    "                                fitter,\n",
    "                                method,\n",
    "                                bounded,\n",
    "                                plasmonenergy\n",
    "                               )\n",
    "            \n",
    "            samf = model.create_samfire(workers=workers, \n",
    "                                        ipyparallel=multithreading, \n",
    "                                        setup=True\n",
    "                                       )\n",
    "\n",
    "            samf.metadata.goodness_test.tolerance = mean_rchisq * 1.5\n",
    "            samf.remove(1)\n",
    "            samf.refresh_database()\n",
    "\n",
    "            samf.start(fitter=fitter, \n",
    "                       method=method,\n",
    "                       bounded=bounded\n",
    "                      )\n",
    "\n",
    "            plt.close()\n",
    "            \n",
    "        \n",
    "        elif (self.attr_deconv == True):\n",
    "            print('Reinitialising poissonian noise estimation...')\n",
    "            self.File_deconv.estimate_poissonian_noise_variance()\n",
    "\n",
    "            if (lazy == True):\n",
    "                self.File_deconv.metadata.Signal.Noise_properties.variance.compute()\n",
    "                \n",
    "            model, params = self.init_model()\n",
    "\n",
    "            if (method == 'ls'):\n",
    "                bounded = True\n",
    "\n",
    "            else:\n",
    "                bounded = False\n",
    "\n",
    "            self.set_bounds(model, bounded)\n",
    "\n",
    "            offset = self.File.axes_manager['Energy loss'].offset\n",
    "            scale  = self.File.axes_manager['Energy loss'].scale\n",
    "            size   = self.File.axes_manager['Energy loss'].size\n",
    "\n",
    "            e_max  = float(int(scale * size + offset))\n",
    "\n",
    "            upper_bound = e_max\n",
    "\n",
    "            model.components.Zero_Loss_Peak.active      = True\n",
    "            model.components.First_Plasmon_Peak.active  = True\n",
    "            model.components.Second_Plasmon_Peak.active = False\n",
    "            \n",
    "            plasmonenergy = self.fit_fpp_only(upper_bound,\n",
    "                                              model, \n",
    "                                              fitter,\n",
    "                                              method,\n",
    "                                              bounded\n",
    "                                             )\n",
    "            \n",
    "            model.set_signal_range(self.elastic_threshold, \n",
    "                                   1.5 * plasmonenergy\n",
    "                                  )\n",
    "            \n",
    "            if (auto == False):\n",
    "                gui = self.yes_or_no('Do you want to adjust the starting parameters?')\n",
    "                if (gui == True):\n",
    "                    self.model_gui(model)\n",
    "            \n",
    "            print('Correcting poissonian noise for the gain factor of\\n' +\n",
    "                  'the EELS - detector by generating statistics on the\\n' +\n",
    "                  'reduced Chi-squared.'\n",
    "                 )\n",
    "            \n",
    "            mean_rchisq = self.poisson_noise_gain_correction(model,\n",
    "                                                             fitter,\n",
    "                                                             method,\n",
    "                                                             bounded,\n",
    "                                                             plasmonenergy\n",
    "                                                            )\n",
    "            \n",
    "            print('Generating_seeds for SAMFire...')\n",
    "            \n",
    "            self.generate_seeds(model,\n",
    "                                fitter,\n",
    "                                method,\n",
    "                                bounded,\n",
    "                                plasmonenergy\n",
    "                               )\n",
    "            \n",
    "            samf = model.create_samfire(workers=workers, \n",
    "                                        ipyparallel=multithreading, \n",
    "                                        setup=True\n",
    "                                       )\n",
    "\n",
    "            samf.metadata.goodness_test.tolerance = mean_rchisq * 1.5\n",
    "            samf.remove(1)\n",
    "            samf.refresh_database()\n",
    "\n",
    "            samf.start(fitter=fitter, \n",
    "                       method=method,\n",
    "                       bounded=bounded\n",
    "                      )\n",
    "        \n",
    "        try:\n",
    "            self.Chisq       = model.chisq\n",
    "            self.red_Chisq   = model.red_chisq\n",
    "            self.rchisq_mean = np.mean(\n",
    "                self.red_Chisq.data[np.invert(np.isnan(self.red_Chisq.data))]\n",
    "            )\n",
    "            self.rchisq_std  = np.std(\n",
    "                self.red_Chisq.data[np.invert(np.isnan(self.red_Chisq.data))]\n",
    "            )\n",
    "\n",
    "            print('Adj. fit goodness (reduced Chi squared): ', self.rchisq_mean)\n",
    "            print('Standard deviation of adj. fit goodness: ', self.rchisq_std)\n",
    "        except:\n",
    "            print('\\nAttention: Reduced Chi squared calculation failed. ')\n",
    "        return model\n",
    "    \n",
    "    \n",
    "    def generate_seeds(self,\n",
    "                       model,\n",
    "                       fitter,\n",
    "                       method,\n",
    "                       bounded,\n",
    "                       plasmonenergy\n",
    "                      ):\n",
    "        \"\"\"\n",
    "        Calling serial fit routine for a #number of pixels to gather statistics\n",
    "        on the reduced chi squared.\n",
    "        (#number = steps|steps^2, dependence of navigation dimension) \n",
    "        \n",
    "        The pixel selection is homogenously distributed over the navigation space,\n",
    "        to estimate local deviations of the mean parameter solutions.\n",
    "        This way, SAMFire will have optimally close solutions for the parameter\n",
    "        space to estimate neighbouring pixels and propagate fast.\n",
    "        \n",
    "        It is a requirement for SAMFire.\n",
    "        For multifit routine: functionality is only needed for gain correction!\n",
    "        \"\"\"\n",
    "        steps = 10\n",
    "        \n",
    "        if (self.attr_deconv == True):\n",
    "            model.components.Zero_Loss_Peak.active      = True\n",
    "            model.components.First_Plasmon_Peak.active  = True\n",
    "            model.components.Second_Plasmon_Peak.active = False\n",
    "            model.set_signal_range(self.elastic_threshold, \n",
    "                                   1.5 * plasmonenergy\n",
    "                                  )\n",
    "        \n",
    "        else:\n",
    "            model.components.Zero_Loss_Peak.active      = True\n",
    "            model.components.First_Plasmon_Peak.active  = True\n",
    "            model.components.Second_Plasmon_Peak.active = True \n",
    "            model.set_signal_range(-self.elastic_threshold, \n",
    "                                   2.5 * plasmonenergy\n",
    "                                  )\n",
    "        \n",
    "        if (model.axes_manager.navigation_dimension == 1):\n",
    "            \n",
    "            for i in range(steps):\n",
    "                step_x = int(self.File.axes_manager.navigation_shape[0]/steps)\n",
    "\n",
    "                model.axes_manager.indices = (int(step_x/2+i*step_x),)\n",
    "\n",
    "                model.fit(fitter=fitter, \n",
    "                          method=method,\n",
    "                          bounded=bounded\n",
    "                         )\n",
    "\n",
    "\n",
    "        elif (model.axes_manager.navigation_dimension == 2):\n",
    "\n",
    "            for i in range(steps):\n",
    "                for j in range(steps):\n",
    "                    step_x = int(self.File.axes_manager.navigation_shape[0]/steps)\n",
    "                    step_y = int(self.File.axes_manager.navigation_shape[1]/steps)\n",
    "\n",
    "                    model.axes_manager.indices = (int(step_x/2 + i*step_x), \n",
    "                                                  int(step_y/2 + j*step_y))\n",
    "                    model.fit(fitter=fitter, \n",
    "                              method=method,\n",
    "                              bounded=bounded\n",
    "                             )\n",
    "                        \n",
    "        \n",
    "    def poisson_noise_gain_correction(self,\n",
    "                                      model,\n",
    "                                      fitter,\n",
    "                                      method,\n",
    "                                      bounded,\n",
    "                                      plasmonenergy\n",
    "                                     ):\n",
    "        \"\"\"\n",
    "        Adjusting the poissonian noise by considering the influence of the \n",
    "        gain factor, as it is a multiplier attached to the poissonian noise.\n",
    "        \n",
    "        This will use the reduced chi squared to estimate the gain factor by\n",
    "        assuming a optimal model, setting the mean chi squared to 1.\n",
    "        \n",
    "        Therefore all information on the fit goodness of the model is adjusted.\n",
    "        \"\"\"\n",
    "        if (self.attr_deconv == True):\n",
    "            model.components.Zero_Loss_Peak.active      = True\n",
    "            model.components.First_Plasmon_Peak.active  = True\n",
    "            model.components.Second_Plasmon_Peak.active = False\n",
    "            model.set_signal_range(self.elastic_threshold, \n",
    "                                   1.5 * plasmonenergy\n",
    "                                  )\n",
    "        \n",
    "        else:\n",
    "            model.components.Zero_Loss_Peak.active      = True\n",
    "            model.components.First_Plasmon_Peak.active  = True\n",
    "            model.components.Second_Plasmon_Peak.active = True \n",
    "            model.set_signal_range(-self.elastic_threshold, \n",
    "                                   2.5 * plasmonenergy\n",
    "                                  )\n",
    "        \n",
    "        self.generate_seeds(model,\n",
    "                            fitter,\n",
    "                            method,\n",
    "                            bounded,\n",
    "                            plasmonenergy\n",
    "                           )\n",
    "\n",
    "        red_chisq = model.red_chisq.data\n",
    "        mean_rchisq = np.mean(red_chisq[np.invert(np.isnan(red_chisq))])\n",
    "        \n",
    "        if (self.attr_deconv == False):\n",
    "            print('Including gain factor of detector in poissonian noise. Rescaling...')\n",
    "            self.File.estimate_poissonian_noise_variance(gain_factor=mean_rchisq)\n",
    "            \n",
    "            if (self.is_lazy == True):\n",
    "                self.File.metadata.Signal.Noise_properties.variance.compute()\n",
    "        \n",
    "        else:\n",
    "            print('Including gain factor of detector in poissonian noise. Rescaling...')\n",
    "            self.File_deconv.estimate_poissonian_noise_variance(gain_factor=mean_rchisq)\n",
    "            \n",
    "            if (self.is_lazy == True):\n",
    "                self.File_deconv.metadata.Signal.Noise_properties.variance.compute()\n",
    "            \n",
    "        return mean_rchisq\n",
    "    \n",
    "    \n",
    "    def save_models_to_file(self, \n",
    "                            filename=''\n",
    "                           ):\n",
    "        \"\"\"\n",
    "        Saving all the currently calculated models for the working file to a new file\n",
    "        #filename#\n",
    "        \"\"\"\n",
    "        if (filename == ''):\n",
    "            filename = asksaveasfile(mode='w', defaultextension=\".hspy\")\n",
    "        if (self.attr_deconv == False):\n",
    "            self.File.save(filename)\n",
    "        \n",
    "        else:\n",
    "            self.File_deconv.save(filename)\n",
    "\n",
    "    \n",
    "    def load_model(self, mkey=None):\n",
    "        \"\"\"\n",
    "        Loading a model picked by the user from file by firstly recovering all models\n",
    "        and then loading the picked #model_name# to the class variable #Fit_Model#\n",
    "        \"\"\"\n",
    "        if (self.is_lazy == True):\n",
    "            try:\n",
    "                if (self.attr_deconv == False):\n",
    "                    self.File.compute()\n",
    "\n",
    "                else:\n",
    "                    self.File_deconv.compute()\n",
    "                    \n",
    "            except:\n",
    "                pass\n",
    "                \n",
    "        available = np.empty((len(self.all_models)), \n",
    "                             dtype=bool\n",
    "                            )\n",
    "        \n",
    "        available = self.restore_models_to_dict(available)\n",
    "        print('Available models: \\n')\n",
    "        for key in self.all_models:\n",
    "            if (self.all_models[key] in self.models_dict):\n",
    "                print('\"' + \n",
    "                      str(key) + \n",
    "                      '\" : ', \n",
    "                      self.all_models[key], \n",
    "                      '\\n'\n",
    "                     )\n",
    "        \n",
    "        if (available[available].size == 0):\n",
    "            print('No model is available. Exiting.')\n",
    "            return None\n",
    "        \n",
    "        if (mkey == None):\n",
    "            print('\\nIf you want to exit the model loading process,' + \n",
    "                  'please type: (\"exit\"/\"cancel\")'\n",
    "                 )\n",
    "            mkey = input(\"Which model should be loaded? \")\n",
    "\n",
    "            if (mkey == 'exit' or mkey == 'cancel'):\n",
    "                print('Loading process is interrupted by user input.')\n",
    "                if (self.is_lazy == True):\n",
    "                    if (self.attr_deconv == False):\n",
    "                        self.File = self.File.as_lazy()\n",
    "\n",
    "                    else:\n",
    "                        self.File_deconv = self.File_deconv.as_lazy()\n",
    "                return None\n",
    "        \n",
    "        \n",
    "            elif (mkey in self.all_models.keys() and available[int(mkey)] == True):\n",
    "                print('Loading parameter maps for: ' + \n",
    "                      str(self.all_models[mkey])\n",
    "                     )\n",
    "                self.model_name   = self.all_models[mkey]\n",
    "\n",
    "                self.get_model()\n",
    "                name = self.split(self.all_models[mkey], ('_'))\n",
    "                \n",
    "                self.function_set = name[0]\n",
    "                self.optimizer    = name[1]\n",
    "                self.method       = name[2]\n",
    "                self.generate_param_maps(self.method)\n",
    "                self.Chisq        = self.Fit_Model.chisq\n",
    "                self.red_Chisq    = self.Fit_Model.red_chisq\n",
    "\n",
    "            else:\n",
    "                try:\n",
    "                    print('Loading parameter maps for: ' + str(mkey))\n",
    "                    self.model_name   = mkey\n",
    "\n",
    "                    self.get_model()\n",
    "                    name = self.split(self.model_name, ('_'))\n",
    "\n",
    "                    self.function_set = name[0]\n",
    "                    self.optimizer    = name[1]\n",
    "                    self.method       = name[2]\n",
    "                    self.generate_param_maps(self.method)\n",
    "                    \n",
    "                    self.Chisq        = self.Fit_Model.chisq\n",
    "                    self.red_Chisq    = self.Fit_Model.red_chisq\n",
    "\n",
    "                except:\n",
    "                    print('Your input did not match with any existing model of the' +\n",
    "                          'loaded file, please try again.')\n",
    "                    self.load_model()\n",
    "\n",
    "            method = self.split(self.all_models[mkey], ('_'))[-1]\n",
    "            self.generate_param_maps(method)\n",
    "        \n",
    "        else:\n",
    "            if (str(mkey) in self.all_models.keys() and available[int(mkey)] == True):\n",
    "                print('Loading parameter maps for: ' + \n",
    "                      str(self.all_models[str(mkey)])\n",
    "                     )\n",
    "                self.model_name   = self.all_models[str(mkey)]\n",
    "\n",
    "                self.get_model()\n",
    "                name = self.split(self.all_models[mkey], ('_'))\n",
    "                \n",
    "                self.function_set = name[0]\n",
    "                self.optimizer    = name[1]\n",
    "                self.method       = name[2]\n",
    "                self.generate_param_maps(self.method)\n",
    "                \n",
    "                self.function_set = self.split(self.all_models[str(mkey)], ('_'))[0]\n",
    "                self.Chisq        = self.Fit_Model.chisq\n",
    "                self.red_Chisq    = self.Fit_Model.red_chisq\n",
    "            \n",
    "            else:\n",
    "                try:\n",
    "                    print('Loading parameter maps for: ' + str(mkey))\n",
    "                    self.model_name   = mkey\n",
    "\n",
    "                    self.get_model()\n",
    "                    name = self.split(self.model_name, ('_'))\n",
    "\n",
    "                    self.function_set = name[0]\n",
    "                    self.optimizer    = name[1]\n",
    "                    self.method       = name[2]\n",
    "                    self.generate_param_maps(self.method)\n",
    "                    \n",
    "                    self.Chisq        = self.Fit_Model.chisq\n",
    "                    self.red_Chisq    = self.Fit_Model.red_chisq\n",
    "\n",
    "                except:\n",
    "                    print('Your input did not match with any existing model of the' +\n",
    "                          'loaded file, please try again.')\n",
    "                    self.load_model()\n",
    "        \n",
    "        if (self.is_lazy == True):\n",
    "            if (self.attr_deconv == False):\n",
    "                self.File = self.File.as_lazy()\n",
    "\n",
    "            else:\n",
    "                self.File_deconv = self.File_deconv.as_lazy()\n",
    "        \n",
    "        print('Finished loading process.')\n",
    "            \n",
    "        \n",
    "    def restore_models_to_dict(self,\n",
    "                               available\n",
    "                              ):\n",
    "        \"\"\"\n",
    "        Adding all accessible models of loaded file to the model dictionary #models_dict#\n",
    "        \"\"\"\n",
    "        for key in range(len(available)):\n",
    "            \n",
    "            try:\n",
    "                if (self.all_models[str(key)] in self.models_dict):\n",
    "                    available[key] = True\n",
    "                    \n",
    "                elif (self.attr_deconv == False):\n",
    "                    self.model_name                   = self.all_models[str(key)]\n",
    "                    self.models_dict[self.model_name] = self.File.models.restore(\n",
    "                        self.model_name\n",
    "                    )\n",
    "                    available[key] = True\n",
    "                    \n",
    "                else:\n",
    "                    self.model_name                   = self.all_models[str(key)]\n",
    "                    self.models_dict[self.model_name] = self.File_deconv.models.restore(\n",
    "                        self.model_name\n",
    "                    )\n",
    "                    available[key] = True\n",
    "                    \n",
    "            except:\n",
    "                available[key] = False\n",
    "        \n",
    "        return available\n",
    "    \n",
    "    \n",
    "    def update_models_dict(self):\n",
    "        \"\"\"\n",
    "        Updating #models_dict# by adding the currently picked model chosen by #model_name#\n",
    "        \"\"\"\n",
    "        if (self.attr_deconv == False):\n",
    "            self.models_dict[self.model_name] = self.File.models.restore(\n",
    "                self.model_name\n",
    "            )\n",
    "            \n",
    "        else:\n",
    "            self.models_dict[self.model_name] = self.File_deconv.models.restore(\n",
    "                self.model_name\n",
    "            )\n",
    "        \n",
    "    \n",
    "    def get_model(self):\n",
    "        \"\"\"\n",
    "        Add the selected model to the class variable #Fit_Model#\n",
    "        \"\"\"\n",
    "        self.Fit_Model  = self.models_dict[self.model_name]\n",
    "    \n",
    "    \n",
    "    #####################################################################################\n",
    "    #   The following functions are used to transform parameters, calculate E_p(q=0)    #\n",
    "    # and calculate the gaussian error propagation for each corresponding parameter map #\n",
    "    #####################################################################################\n",
    "    \n",
    "    def voigt_fwhm_gauss_propagation(self,\n",
    "                                     func\n",
    "                                    ):\n",
    "        func_dict = {'Zero_Loss_Peak'      : self.Fit_Model.components.Zero_Loss_Peak,\n",
    "                     'First_Plasmon_Peak'  : self.Fit_Model.components.First_Plasmon_Peak,\n",
    "                     'Second_Plasmon_Peak' : self.Fit_Model.components.Second_Plasmon_Peak\n",
    "                    }\n",
    "\n",
    "        gamma_zlp = func_dict[func].gamma.as_signal(\n",
    "            field = 'values'\n",
    "        )\n",
    "\n",
    "        L_fwhm    = np.add(gamma_zlp, \n",
    "                           gamma_zlp\n",
    "                          )\n",
    "\n",
    "        G_fwhm    = func_dict[func].FWHM.as_signal(\n",
    "            field = 'values'\n",
    "        )\n",
    "\n",
    "        gamma_zlp = func_dict[func].gamma.as_signal(\n",
    "            field = 'std'\n",
    "        )\n",
    "\n",
    "        L_fwhm_std = np.add(gamma_zlp, \n",
    "                            gamma_zlp\n",
    "                           )\n",
    "\n",
    "        G_fwhm_std = func_dict[func].FWHM.as_signal(\n",
    "            field = 'std'\n",
    "        )\n",
    "\n",
    "        dfwhm_dl = (L_fwhm * 0.2166 / ( L_fwhm**2 * 0.2166 + \n",
    "                                       G_fwhm**2 )**(1/2) + \n",
    "                    0.5346\n",
    "                   )\n",
    "\n",
    "        dfwhm_dg = (G_fwhm / ( L_fwhm ** 2 * 0.2166 + \n",
    "                              G_fwhm ** 2 )**(1/2)          \n",
    "                   )\n",
    "\n",
    "        error = np.sqrt((G_fwhm_std * dfwhm_dg) ** 2 + \n",
    "                        (L_fwhm_std * dfwhm_dl) ** 2 \n",
    "                       )\n",
    "\n",
    "        return error\n",
    "    \n",
    "    \n",
    "    def Ep_q0_gauss_propagation(self):\n",
    "        emax  = self.FPP_Emax \n",
    "        fwhm  = self.FPP_FWHM\n",
    "        \n",
    "        Ep_q0 = ( emax ** 2 - (fwhm / 2) ** 2 ) ** 0.5\n",
    "        \n",
    "        dEp_demax = emax * 2 / ( emax ** 2 * 4 + \n",
    "                                fwhm ** 2 \n",
    "                               ) ** (1/2)\n",
    "        dEp_dfwhm = fwhm * (1/2) / ( emax ** 2 * 4 + \n",
    "                                  fwhm ** 2 \n",
    "                                 ) ** (1/2)\n",
    "        \n",
    "        emax_std = self.FPP_Emax.metadata.Signal.Noise_properties.variance ** (1/2)\n",
    "        fwhm_std = self.FPP_FWHM.metadata.Signal.Noise_properties.variance ** (1/2)\n",
    "        \n",
    "        Ep_q0_std = ( ( dEp_demax * emax_std ) ** 2 + ( dEp_dfwhm * fwhm_std ) ** 2 ) ** (1/2)\n",
    "        \n",
    "        return Ep_q0_std\n",
    "        \n",
    "    \n",
    "    def param_maps_drude(self):\n",
    "        self.FPP_FWHM   = self.Fit_Model.components.First_Plasmon_Peak.fwhm.as_signal(\n",
    "            field = 'values'\n",
    "        )\n",
    "        \n",
    "        self.FPP_Emax   = self.Fit_Model.components.First_Plasmon_Peak.plasmon_energy.as_signal(\n",
    "            field = 'values'\n",
    "        )\n",
    "        \n",
    "        self.FPP_Int    = self.Fit_Model.components.First_Plasmon_Peak.intensity.as_signal(\n",
    "            field = 'values'\n",
    "        )\n",
    "\n",
    "        if (self.attr_deconv == False):\n",
    "            gamma_zlp = self.Fit_Model.components.Zero_Loss_Peak.gamma.as_signal(\n",
    "                field = 'values'\n",
    "            )\n",
    "            \n",
    "            ZLP_L_fwhm      = np.add(gamma_zlp, \n",
    "                                     gamma_zlp\n",
    "                                    )\n",
    "            \n",
    "            ZLP_G_fwhm      = self.Fit_Model.components.Zero_Loss_Peak.FWHM.as_signal(\n",
    "                field = 'values'\n",
    "            )\n",
    "            \n",
    "            self.ZLP_FWHM   = (ZLP_L_fwhm*0.5346 + \n",
    "                               np.sqrt(ZLP_G_fwhm**2 + ZLP_L_fwhm**2*0.2166)\n",
    "                              )\n",
    "            \n",
    "            self.ZLP_Emax   = self.Fit_Model.components.Zero_Loss_Peak.centre.as_signal(\n",
    "                field = 'values'\n",
    "            )\n",
    "            \n",
    "            self.ZLP_Int    = self.Fit_Model.components.Zero_Loss_Peak.area.as_signal(\n",
    "                field = 'values'\n",
    "            )\n",
    "            \n",
    "\n",
    "            self.SPP_FWHM   = self.Fit_Model.components.Second_Plasmon_Peak.fwhm.as_signal(\n",
    "                field = 'values'\n",
    "            )\n",
    "            \n",
    "            self.SPP_Emax   = self.Fit_Model.components.Second_Plasmon_Peak.plasmon_energy.as_signal(\n",
    "                field = 'values'\n",
    "            )\n",
    "            \n",
    "            self.SPP_Int    = self.Fit_Model.components.Second_Plasmon_Peak.intensity.as_signal(\n",
    "                field = 'values'\n",
    "            )\n",
    "\n",
    "        self.Ep_q0      = ( self.FPP_Emax**2 - (self.FPP_FWHM / 2)**2 )**0.5\n",
    "        \n",
    "    \n",
    "    def std_maps_drude(self):\n",
    "        self.FPP_FWHM.metadata.Signal.set_item(\n",
    "            \"Noise_properties.variance\", \n",
    "            self.Fit_Model.components.First_Plasmon_Peak.fwhm.as_signal(\n",
    "                field = 'std'\n",
    "            ) ** 2\n",
    "        )\n",
    "        \n",
    "        self.FPP_Emax.metadata.Signal.set_item(\n",
    "            \"Noise_properties.variance\", \n",
    "            self.Fit_Model.components.First_Plasmon_Peak.plasmon_energy.as_signal(\n",
    "                field = 'std'\n",
    "            ) ** 2\n",
    "        )\n",
    "        \n",
    "        self.FPP_Int.metadata.Signal.set_item(\n",
    "            \"Noise_properties.variance\", \n",
    "            self.Fit_Model.components.First_Plasmon_Peak.intensity.as_signal(\n",
    "                field = 'std'\n",
    "            ) ** 2\n",
    "        )\n",
    "\n",
    "        if (self.attr_deconv == False):\n",
    "            error = self.voigt_fwhm_gauss_propagation('Zero_Loss_Peak')\n",
    "            \n",
    "            self.ZLP_FWHM.metadata.Signal.set_item(\n",
    "                \"Noise_properties.variance\", \n",
    "                error ** 2\n",
    "            )\n",
    "            \n",
    "            self.ZLP_Emax.metadata.Signal.set_item(\n",
    "                \"Noise_properties.variance\", \n",
    "                self.Fit_Model.components.Zero_Loss_Peak.centre.as_signal(\n",
    "                    field = 'std'\n",
    "                ) ** 2\n",
    "            )\n",
    "            \n",
    "            self.ZLP_Int.metadata.Signal.set_item(\n",
    "                \"Noise_properties.variance\", \n",
    "                self.Fit_Model.components.Zero_Loss_Peak.area.as_signal(\n",
    "                    field = 'std'\n",
    "                ) ** 2\n",
    "            )\n",
    "\n",
    "            self.SPP_FWHM.metadata.Signal.set_item(\n",
    "                \"Noise_properties.variance\", \n",
    "                self.Fit_Model.components.Second_Plasmon_Peak.fwhm.as_signal(\n",
    "                    field = 'std'\n",
    "                ) ** 2\n",
    "            )\n",
    "            \n",
    "            self.SPP_Emax.metadata.Signal.set_item(\n",
    "                \"Noise_properties.variance\", \n",
    "                self.Fit_Model.components.Second_Plasmon_Peak.plasmon_energy.as_signal(\n",
    "                    field = 'std'\n",
    "                ) ** 2\n",
    "            )\n",
    "            \n",
    "            self.SPP_Int.metadata.Signal.set_item(\n",
    "                \"Noise_properties.variance\", \n",
    "                self.Fit_Model.components.Second_Plasmon_Peak.intensity.as_signal(\n",
    "                    field = 'std'\n",
    "                ) ** 2\n",
    "            )\n",
    "        \n",
    "\n",
    "        Ep_q0_std = self.Ep_q0_gauss_propagation()\n",
    "        \n",
    "        self.Ep_q0.metadata.Signal.set_item(\n",
    "            \"Noise_properties.variance\", \n",
    "            Ep_q0_std ** 2\n",
    "        )\n",
    "        \n",
    "    \n",
    "    def param_maps_lorentzian(self):\n",
    "        gamma_fpp = self.Fit_Model.components.First_Plasmon_Peak.gamma.as_signal(\n",
    "            field = 'values'\n",
    "        )\n",
    "        \n",
    "        self.FPP_FWHM   = np.add(gamma_fpp, gamma_fpp)\n",
    "        \n",
    "        self.FPP_Emax   = self.Fit_Model.components.First_Plasmon_Peak.centre.as_signal(\n",
    "            field = 'values'\n",
    "        )\n",
    "        \n",
    "        self.FPP_Int    = self.Fit_Model.components.First_Plasmon_Peak.A.as_signal(\n",
    "            field = 'values'\n",
    "        )\n",
    "\n",
    "        if (self.attr_deconv == False):\n",
    "            gamma_zlp = self.Fit_Model.components.Zero_Loss_Peak.gamma.as_signal(\n",
    "                field = 'values'\n",
    "            )\n",
    "            \n",
    "            ZLP_L_fwhm      = np.add(gamma_zlp, \n",
    "                                     gamma_zlp\n",
    "                                    )\n",
    "            \n",
    "            ZLP_G_fwhm      = self.Fit_Model.components.Zero_Loss_Peak.FWHM.as_signal(\n",
    "                field = 'values'\n",
    "            )\n",
    "            \n",
    "            self.ZLP_FWHM   = (ZLP_L_fwhm*0.5346 + \n",
    "                               np.sqrt(ZLP_G_fwhm**2 + \n",
    "                                       ZLP_L_fwhm**2*0.2166\n",
    "                                      )\n",
    "                              )\n",
    "            \n",
    "            self.ZLP_Emax   = self.Fit_Model.components.Zero_Loss_Peak.centre.as_signal(\n",
    "                field = 'values'\n",
    "            )\n",
    "            \n",
    "            self.ZLP_Int    = self.Fit_Model.components.Zero_Loss_Peak.area.as_signal(\n",
    "                field = 'values'\n",
    "            )\n",
    "            \n",
    "\n",
    "            gamma_spp = self.Fit_Model.components.Second_Plasmon_Peak.gamma.as_signal(\n",
    "                field = 'values'\n",
    "            )\n",
    "            \n",
    "            self.SPP_FWHM   = np.add(gamma_spp, \n",
    "                                     gamma_spp\n",
    "                                    )\n",
    "            \n",
    "            self.SPP_Emax   = self.Fit_Model.components.Second_Plasmon_Peak.centre.as_signal(\n",
    "                field = 'values'\n",
    "            )\n",
    "            \n",
    "            self.SPP_Int    = self.Fit_Model.components.Second_Plasmon_Peak.A.as_signal(\n",
    "                field = 'values'\n",
    "            )\n",
    "        \n",
    "\n",
    "        self.Ep_q0      = ( self.FPP_Emax**2 - (self.FPP_FWHM / 2)**2 )**0.5\n",
    "    \n",
    "    \n",
    "    def std_maps_lorentzian(self):\n",
    "        self.FPP_FWHM.metadata.Signal.set_item(\n",
    "            \"Noise_properties.variance\", \n",
    "            self.Fit_Model.components.First_Plasmon_Peak.gamma.as_signal(\n",
    "                field = 'std'\n",
    "            ) ** 2\n",
    "        )\n",
    "        \n",
    "        self.FPP_Emax.metadata.Signal.set_item(\n",
    "            \"Noise_properties.variance\", \n",
    "            self.Fit_Model.components.First_Plasmon_Peak.centre.as_signal(\n",
    "                field = 'std'\n",
    "            ) ** 2\n",
    "        )\n",
    "        \n",
    "        self.FPP_Int.metadata.Signal.set_item(\n",
    "            \"Noise_properties.variance\", \n",
    "            self.Fit_Model.components.First_Plasmon_Peak.A.as_signal(\n",
    "                field = 'std'\n",
    "            ) ** 2\n",
    "        )\n",
    "\n",
    "        if (self.attr_deconv == False):\n",
    "            error = self.voigt_fwhm_gauss_propagation('Zero_Loss_Peak')\n",
    "            \n",
    "            self.ZLP_FWHM.metadata.Signal.set_item(\n",
    "                \"Noise_properties.variance\", \n",
    "                error ** 2\n",
    "            )\n",
    "            \n",
    "            self.ZLP_Emax.metadata.Signal.set_item(\n",
    "                \"Noise_properties.variance\", \n",
    "                self.Fit_Model.components.Zero_Loss_Peak.centre.as_signal(\n",
    "                    field = 'std'\n",
    "                ) ** 2\n",
    "            )\n",
    "            \n",
    "            self.ZLP_Int.metadata.Signal.set_item(\n",
    "                \"Noise_properties.variance\", \n",
    "                self.Fit_Model.components.Zero_Loss_Peak.area.as_signal(\n",
    "                    field = 'std'\n",
    "                ) ** 2\n",
    "            )\n",
    "            \n",
    "            \n",
    "            self.SPP_FWHM.metadata.Signal.set_item(\n",
    "                \"Noise_properties.variance\", \n",
    "                self.Fit_Model.components.Second_Plasmon_Peak.gamma.as_signal(\n",
    "                    field = 'std'\n",
    "                ) ** 2\n",
    "            )\n",
    "            \n",
    "            self.SPP_Emax.metadata.Signal.set_item(\n",
    "                \"Noise_properties.variance\", \n",
    "                self.Fit_Model.components.Second_Plasmon_Peak.centre.as_signal(\n",
    "                    field = 'std'\n",
    "                ) ** 2\n",
    "            )\n",
    "            \n",
    "            self.SPP_Int.metadata.Signal.set_item(\n",
    "                \"Noise_properties.variance\", \n",
    "                self.Fit_Model.components.Second_Plasmon_Peak.A.as_signal(\n",
    "                    field = 'std'\n",
    "                ) ** 2\n",
    "            )\n",
    "        \n",
    "\n",
    "        Ep_q0_std = self.Ep_q0_gauss_propagation()\n",
    "        \n",
    "        self.Ep_q0.metadata.Signal.set_item(\n",
    "            \"Noise_properties.variance\", \n",
    "            Ep_q0_std ** 2\n",
    "        )\n",
    "        \n",
    "    \n",
    "    def param_maps_gaussian(self):\n",
    "        self.FPP_FWHM   = self.Fit_Model.components.First_Plasmon_Peak.sigma.as_signal(\n",
    "                field = 'values'\n",
    "        )*2*np.sqrt(np.log(2))\n",
    "        \n",
    "        self.FPP_Emax   = self.Fit_Model.components.First_Plasmon_Peak.centre.as_signal(\n",
    "            field = 'values'\n",
    "        )\n",
    "        \n",
    "        self.FPP_Int    = self.Fit_Model.components.First_Plasmon_Peak.A.as_signal(\n",
    "            field = 'values'\n",
    "        )\n",
    "\n",
    "        if (self.attr_deconv == False):\n",
    "            gamma_zlp = self.Fit_Model.components.Zero_Loss_Peak.gamma.as_signal(\n",
    "                field = 'values'\n",
    "            )\n",
    "            \n",
    "            ZLP_L_fwhm      = np.add(gamma_zlp, \n",
    "                                     gamma_zlp\n",
    "                                    )\n",
    "            \n",
    "            ZLP_G_fwhm      = self.Fit_Model.components.Zero_Loss_Peak.FWHM.as_signal(\n",
    "                field = 'values'\n",
    "            )\n",
    "            \n",
    "            self.ZLP_FWHM   = (ZLP_L_fwhm*0.5346 + \n",
    "                               np.sqrt(ZLP_G_fwhm**2 + ZLP_L_fwhm**2*0.2166)\n",
    "                              )\n",
    "            \n",
    "            self.ZLP_Emax   = self.Fit_Model.components.Zero_Loss_Peak.centre.as_signal(\n",
    "                field = 'values'\n",
    "            )\n",
    "            \n",
    "            self.ZLP_Int    = self.Fit_Model.components.Zero_Loss_Peak.area.as_signal(\n",
    "                field = 'values'\n",
    "            )\n",
    "\n",
    "            \n",
    "            self.SPP_FWHM   = self.Fit_Model.components.Second_Plasmon_Peak.sigma.as_signal(\n",
    "                field = 'values'\n",
    "            )*2*np.sqrt(np.log(2))\n",
    "            \n",
    "            self.SPP_Emax   = self.Fit_Model.components.Second_Plasmon_Peak.centre.as_signal(\n",
    "                field = 'values'\n",
    "            )\n",
    "            \n",
    "            self.SPP_Int    = self.Fit_Model.components.Second_Plasmon_Peak.A.as_signal(\n",
    "                field = 'values'\n",
    "            )\n",
    "        \n",
    "\n",
    "        self.Ep_q0      = ( self.FPP_Emax**2 - (self.FPP_FWHM / 2)**2 )**0.5\n",
    "        \n",
    "    \n",
    "    def std_maps_gaussian(self):\n",
    "        self.FPP_FWHM.metadata.Signal.set_item(\n",
    "            \"Noise_properties.variance\",\n",
    "            self.Fit_Model.components.First_Plasmon_Peak.sigma.as_signal(\n",
    "                field = 'std'\n",
    "            ) ** 2\n",
    "        )\n",
    "        \n",
    "        self.FPP_Emax.metadata.Signal.set_item(\n",
    "            \"Noise_properties.variance\", \n",
    "            self.Fit_Model.components.First_Plasmon_Peak.centre.as_signal(\n",
    "                field = 'std'\n",
    "            ) ** 2\n",
    "        )\n",
    "        \n",
    "        self.FPP_Int.metadata.Signal.set_item(\n",
    "            \"Noise_properties.variance\", \n",
    "            self.Fit_Model.components.First_Plasmon_Peak.A.as_signal(\n",
    "                field = 'std'\n",
    "            ) ** 2\n",
    "        )\n",
    "\n",
    "        if (self.attr_deconv == False):\n",
    "            error = self.voigt_fwhm_gauss_propagation('Zero_Loss_Peak')\n",
    "            \n",
    "            self.ZLP_FWHM.metadata.Signal.set_item(\n",
    "                \"Noise_properties.variance\", \n",
    "                error ** 2\n",
    "            )\n",
    "            \n",
    "            self.ZLP_Emax.metadata.Signal.set_item(\n",
    "                \"Noise_properties.variance\", \n",
    "                self.Fit_Model.components.Zero_Loss_Peak.centre.as_signal(\n",
    "                    field = 'std'\n",
    "                ) ** 2\n",
    "            )\n",
    "            \n",
    "            self.ZLP_Int.metadata.Signal.set_item(\n",
    "                \"Noise_properties.variance\", \n",
    "                self.Fit_Model.components.Zero_Loss_Peak.area.as_signal(\n",
    "                    field = 'std'\n",
    "                ) ** 2\n",
    "            )\n",
    "\n",
    "            \n",
    "            self.SPP_FWHM.metadata.Signal.set_item(\n",
    "                \"Noise_properties.variance\", \n",
    "                self.Fit_Model.components.Second_Plasmon_Peak.sigma.as_signal(\n",
    "                    field = 'std'\n",
    "                ) ** 2\n",
    "            )\n",
    "            \n",
    "            self.SPP_Emax.metadata.Signal.set_item(\n",
    "                \"Noise_properties.variance\", \n",
    "                self.Fit_Model.components.Second_Plasmon_Peak.centre.as_signal(\n",
    "                    field = 'std'\n",
    "                ) ** 2\n",
    "            )\n",
    "            \n",
    "            self.SPP_Int.metadata.Signal.set_item(\n",
    "                \"Noise_properties.variance\", \n",
    "                self.Fit_Model.components.Second_Plasmon_Peak.A.as_signal(\n",
    "                    field = 'std'\n",
    "                ) ** 2\n",
    "            )\n",
    "\n",
    "        Ep_q0_std = self.Ep_q0_gauss_propagation()\n",
    "        \n",
    "        self.Ep_q0.metadata.Signal.set_item(\n",
    "            \"Noise_properties.variance\", \n",
    "            Ep_q0_std ** 2\n",
    "        )\n",
    "    \n",
    "    \n",
    "    def param_maps_voigt(self):\n",
    "        gamma_fpp = self.Fit_Model.components.First_Plasmon_Peak.gamma.as_signal(\n",
    "                    field = 'values'\n",
    "        )\n",
    "        FPP_L_fwhm      = np.add(gamma_fpp, \n",
    "                                 gamma_fpp\n",
    "                                )\n",
    "        FPP_G_fwhm      = self.Fit_Model.components.First_Plasmon_Peak.FWHM.as_signal(\n",
    "            field = 'values'\n",
    "        )\n",
    "        self.FPP_FWHM   = (FPP_L_fwhm*0.5346 + \n",
    "                           np.sqrt(FPP_G_fwhm**2 + \n",
    "                                   FPP_L_fwhm**2*0.2166\n",
    "                                  )\n",
    "                          )\n",
    "        self.FPP_Emax   = self.Fit_Model.components.First_Plasmon_Peak.centre.as_signal(\n",
    "            field = 'values'\n",
    "        )\n",
    "        self.FPP_Int    = self.Fit_Model.components.First_Plasmon_Peak.area.as_signal(\n",
    "            field = 'values'\n",
    "        )\n",
    "\n",
    "        if (self.attr_deconv == False):\n",
    "            gamma_zlp = self.Fit_Model.components.Zero_Loss_Peak.gamma.as_signal(\n",
    "                field = 'values'\n",
    "            )\n",
    "            ZLP_L_fwhm      = np.add(gamma_zlp, \n",
    "                                     gamma_zlp\n",
    "                                    )\n",
    "            ZLP_G_fwhm      = self.Fit_Model.components.Zero_Loss_Peak.FWHM.as_signal(\n",
    "                field = 'values'\n",
    "            )\n",
    "            self.ZLP_FWHM   = (ZLP_L_fwhm*0.5346 + \n",
    "                               np.sqrt(ZLP_G_fwhm**2 + \n",
    "                                       ZLP_L_fwhm**2*0.2166\n",
    "                                      )\n",
    "                              )\n",
    "            self.ZLP_Emax   = self.Fit_Model.components.Zero_Loss_Peak.centre.as_signal(\n",
    "                field = 'values'\n",
    "            )\n",
    "            self.ZLP_Int    = self.Fit_Model.components.Zero_Loss_Peak.area.as_signal(\n",
    "                field = 'values'\n",
    "            )\n",
    "\n",
    "            gamma_spp = self.Fit_Model.components.Second_Plasmon_Peak.gamma.as_signal(\n",
    "                field = 'values'\n",
    "            )\n",
    "            SPP_L_fwhm      = np.add(gamma_spp, \n",
    "                                     gamma_spp\n",
    "                                    )\n",
    "            SPP_G_fwhm      = self.Fit_Model.components.Second_Plasmon_Peak.FWHM.as_signal(\n",
    "                field = 'values'\n",
    "            )\n",
    "            self.SPP_FWHM   = (SPP_L_fwhm*0.5346 + \n",
    "                               np.sqrt(SPP_G_fwhm**2 + \n",
    "                                       SPP_L_fwhm**2*0.2166\n",
    "                                      )\n",
    "                              )\n",
    "            self.SPP_Emax   = self.Fit_Model.components.Second_Plasmon_Peak.centre.as_signal(\n",
    "                field = 'values'\n",
    "            )\n",
    "            self.SPP_Int    = self.Fit_Model.components.Second_Plasmon_Peak.area.as_signal(\n",
    "                field = 'values'\n",
    "            )\n",
    "\n",
    "        self.Ep_q0      = ( self.FPP_Emax**2 - (self.FPP_FWHM / 2)**2 )**0.5\n",
    "        \n",
    "    \n",
    "    def std_maps_voigt(self):\n",
    "        error = self.voigt_fwhm_gauss_propagation('First_Plasmon_Peak')\n",
    "        \n",
    "        self.FPP_FWHM.metadata.Signal.set_item(\n",
    "            \"Noise_properties.variance\", \n",
    "            error ** 2\n",
    "        )\n",
    "        \n",
    "        self.FPP_Emax.metadata.Signal.set_item(\n",
    "            \"Noise_properties.variance\", \n",
    "            self.Fit_Model.components.First_Plasmon_Peak.centre.as_signal(\n",
    "                field = 'std'\n",
    "            ) ** 2\n",
    "        )\n",
    "        \n",
    "        self.FPP_Int.metadata.Signal.set_item(\n",
    "            \"Noise_properties.variance\", \n",
    "            self.Fit_Model.components.First_Plasmon_Peak.area.as_signal(\n",
    "                field = 'std'\n",
    "            ) ** 2\n",
    "        )\n",
    "\n",
    "        if (self.attr_deconv == False):\n",
    "            error = self.voigt_fwhm_gauss_propagation('Zero_Loss_Peak')\n",
    "            \n",
    "            self.ZLP_FWHM.metadata.Signal.set_item(\n",
    "                \"Noise_properties.variance\", \n",
    "                error ** 2\n",
    "            )\n",
    "            \n",
    "            self.ZLP_Emax.metadata.Signal.set_item(\n",
    "                \"Noise_properties.variance\", \n",
    "                self.Fit_Model.components.Zero_Loss_Peak.centre.as_signal(\n",
    "                    field = 'std'\n",
    "                ) ** 2\n",
    "            )\n",
    "            \n",
    "            self.ZLP_Int.metadata.Signal.set_item(\n",
    "                \"Noise_properties.variance\", \n",
    "                self.Fit_Model.components.Zero_Loss_Peak.area.as_signal(\n",
    "                    field = 'std'\n",
    "                ) ** 2\n",
    "            )\n",
    "\n",
    "            \n",
    "            error = self.voigt_fwhm_gauss_propagation('Second_Plasmon_Peak')\n",
    "            \n",
    "            self.ZLP_FWHM.metadata.Signal.set_item(\n",
    "                \"Noise_properties.variance\", \n",
    "                error ** 2\n",
    "            )\n",
    "            \n",
    "            self.SPP_Emax.metadata.Signal.set_item(\n",
    "                \"Noise_properties.variance\", \n",
    "                self.Fit_Model.components.Second_Plasmon_Peak.centre.as_signal(\n",
    "                    field = 'std'\n",
    "                ) ** 2\n",
    "            )\n",
    "            \n",
    "            self.SPP_Int.metadata.Signal.set_item(\n",
    "                \"Noise_properties.variance\", \n",
    "                self.Fit_Model.components.Second_Plasmon_Peak.area.as_signal(\n",
    "                    field = 'std'\n",
    "                ) ** 2\n",
    "            )\n",
    "\n",
    "        Ep_q0_std = self.Ep_q0_gauss_propagation()\n",
    "        \n",
    "        self.Ep_q0.metadata.Signal.set_item(\n",
    "            \"Noise_properties.variance\", \n",
    "            Ep_q0_std ** 2\n",
    "        )\n",
    "\n",
    "\n",
    "    def generate_param_maps(self, \n",
    "                            method\n",
    "                           ):\n",
    "        \"\"\"\n",
    "        Generating parameter maps to estimate the plasmonic peakshift,\n",
    "        which is calculated by [Egerton] as follows:  \n",
    "                        \n",
    "            $E_p (q=0) = \\sqrt{ (E_max)^2 + (\\frac{\\hbar \\Gamma}{2}) }$\n",
    "        \n",
    "        \n",
    "         Standard deviation estimation of parameters by fitting is only\n",
    "         supported by weighted least square method.\n",
    "         It uses gaussian error propagation for some functional dependencies.\n",
    "         E.g.: The uncertainty for $E_p (q=0)$ is calculated by gaussian\n",
    "                error propagation (the standard deviations of the variables\n",
    "                                   are propagated)\n",
    "        \"\"\"\n",
    "        if (self.function_set == 'VolumePlasmonDrude'):\n",
    "            self.param_maps_drude()\n",
    "            \n",
    "            if (method == 'ls'):\n",
    "                self.std_maps_drude()\n",
    "            \n",
    "        elif (self.function_set == 'Lorentzian'):\n",
    "            self.param_maps_lorentzian()\n",
    "            if (method == 'ls'):\n",
    "                self.std_maps_lorentzian()\n",
    "        \n",
    "        elif (self.function_set == 'Gaussian'):\n",
    "            self.param_maps_gaussian()\n",
    "            if (method == 'ls'):\n",
    "                self.std_maps_gaussian()\n",
    "            \n",
    "        elif (self.function_set == 'Voigt'):\n",
    "            self.param_maps_voigt()\n",
    "            if (method == 'ls'):\n",
    "                self.std_maps_voigt()\n",
    "        \n",
    "        else:\n",
    "            print('No valid function set specified. Please look into docstring for further information.')\n",
    "        \n",
    "        print('Parameter images loaded. Setting properties...')\n",
    "        \n",
    "        units  = {r'Plasmon peak - $E_{\\max}$'          : r'eV', \n",
    "                  r'Plasmon peak - $\\Gamma$'            : r'eV', \n",
    "                  r'Plasmon peak - intensity'           : r'counts', \n",
    "\n",
    "                  r'Zero Loss peak - $E_{\\max}$'        : r'eV', \n",
    "                  r'Zero Loss peak - $\\Gamma$'          : r'eV',\n",
    "                  r'Zero Loss peak - intensity'         : r'counts',\n",
    "\n",
    "                  r'second Plasmon peak - $E_{\\max}$'   : r'eV', \n",
    "                  r'second Plasmon peak - $\\Gamma$'     : r'eV', \n",
    "                  r'second Plasmon peak - intensity'    : r'counts',\n",
    "\n",
    "                  r'Plasmon energy - $E_{p}(q=0)$'      : r'eV', \n",
    "                  r'intensity ratio - $I_{pp}/I_{zlp}$' : r'perc.'\n",
    "                 }\n",
    "        if (self.attr_deconv == False):\n",
    "            self.param_dict        = { r'Plasmon peak - $E_{\\max}$'          : self.FPP_Emax,\n",
    "                                       r'Plasmon peak - $\\Gamma$'            : self.FPP_FWHM,\n",
    "                                       r'Plasmon peak - intensity'           : self.FPP_Int,\n",
    "\n",
    "                                       r'Zero Loss peak - $E_{\\max}$'        : self.ZLP_Emax,\n",
    "                                       r'Zero Loss peak - $\\Gamma$'          : self.ZLP_FWHM,\n",
    "                                       r'Zero Loss peak - intensity'         : self.ZLP_Int,\n",
    "\n",
    "                                       r'second Plasmon peak - $E_{\\max}$'   : self.SPP_Emax,\n",
    "                                       r'second Plasmon peak - $\\Gamma$'     : self.SPP_FWHM,\n",
    "                                       r'second Plasmon peak - intensity'    : self.SPP_Int,\n",
    "\n",
    "                                       r'Plasmon energy - $E_{p}(q=0)$'      : self.Ep_q0,\n",
    "                                       r'intensity ratio - $I_{pp}/I_{zlp}$' : self.FPP_Int / self.ZLP_Int\n",
    "                                     }\n",
    "            for title in self.param_dict:\n",
    "                self.param_dict[title].metadata.General.title = title\n",
    "                self.param_dict[title].metadata.Signal.quantity = units[title]\n",
    "            \n",
    "        else:\n",
    "            self.param_dict        = { r'Plasmon peak - $E_{\\max}$'          : self.FPP_Emax,\n",
    "                                       r'Plasmon peak - $\\Gamma$'            : self.FPP_FWHM,\n",
    "                                       r'Intensity - Plasmon peak'           : self.FPP_Int,\n",
    "\n",
    "                                       r'Plasmon energy - $E_{p}(q=0)$'      : self.Ep_q0\n",
    "                                     }\n",
    "            for title in self.param_dict:\n",
    "                self.param_dict[title].metadata.General.title = title\n",
    "                self.param_dict[title].metadata.Signal.quantity = units[title]\n",
    "    \n",
    "        print('Finished loading parameter images.')\n",
    "    \n",
    "    \n",
    "    def plot_file(self, \n",
    "                  darkfield = False,\n",
    "                  slider    = False,\n",
    "                  cmap      ='coolwarm'\n",
    "                 ):\n",
    "        \"\"\"\n",
    "        Plotting the spectrum image itself, seperating in a signal and \n",
    "        a navigation space where the navigation space corresponds to the\n",
    "        probe spot.\n",
    "        \n",
    "            darkfield: If True - plotting the darkfield image as the\n",
    "                                 navigation space instead of the total spectrum intensity\n",
    "                                 \n",
    "            slider:    If True - a slider is provided for the navigation\n",
    "                                 space instead of the total spectrum intensity\n",
    "        \"\"\"\n",
    "        if (self.attr_deconv == False):\n",
    "            if (self.is_lazy == True):\n",
    "                self.File.compute()\n",
    "\n",
    "            title      = self.File.metadata.General.title\n",
    "            title_corr = self.check_underscores_in_title(title)\n",
    "\n",
    "            self.File.metadata.General.title = title_corr\n",
    "\n",
    "            if (self.haadf != None and darkfield == True):\n",
    "                self.File.plot(navigator = self.haadf, \n",
    "                               navigator_kwds=dict(colorbar=True, \n",
    "                                                   scalebar_color='black',\n",
    "                                                   cmap=cmap,\n",
    "                                                   axes_ticks=True\n",
    "                                                  )\n",
    "                              )\n",
    "\n",
    "            elif (slider == True):\n",
    "                self.File.plot(navigator = 'slider',\n",
    "                               navigator_kwds=dict(colorbar=True, \n",
    "                                                   scalebar_color='black',\n",
    "                                                   cmap=cmap,\n",
    "                                                   axes_ticks=True\n",
    "                                                  )\n",
    "                              )\n",
    "\n",
    "            else:\n",
    "                self.File.plot(navigator='auto', \n",
    "                               navigator_kwds=dict(colorbar=True, \n",
    "                                                   scalebar_color='black',\n",
    "                                                   cmap=cmap,\n",
    "                                                   axes_ticks=True\n",
    "                                                  )\n",
    "                              )\n",
    "        \n",
    "        else:\n",
    "            if (self.is_lazy == True):\n",
    "                self.File_deconv.compute()\n",
    "\n",
    "            title      = self.File_deconv.metadata.General.title\n",
    "            title_corr = self.check_underscores_in_title(title)\n",
    "\n",
    "            self.File_deconv.metadata.General.title = title_corr\n",
    "\n",
    "            if (self.haadf != None and darkfield == True):\n",
    "                self.File_deconv.plot(navigator = self.haadf, \n",
    "                                      navigator_kwds=dict(colorbar=True, \n",
    "                                                          scalebar_color='black',\n",
    "                                                          cmap=cmap,\n",
    "                                                          axes_ticks=True\n",
    "                                                         )\n",
    "                                     )\n",
    "\n",
    "            elif (slider == True):\n",
    "                self.File_deconv.plot(navigator = 'slider',\n",
    "                                      navigator_kwds=dict(colorbar=True, \n",
    "                                                          scalebar_color='black',\n",
    "                                                          cmap=cmap,\n",
    "                                                          axes_ticks=True\n",
    "                                                         )\n",
    "                                     )\n",
    "\n",
    "            else:\n",
    "                self.File_deconv.plot(navigator='auto', \n",
    "                                      navigator_kwds=dict(colorbar=True, \n",
    "                                                          scalebar_color='black',\n",
    "                                                          cmap=cmap,\n",
    "                                                          axes_ticks=True\n",
    "                                                         )\n",
    "                                     )\n",
    "        \n",
    "    \n",
    "    def plot_histogramm(self):\n",
    "        \"\"\"\n",
    "        Plotting the histogram of the spectrum image.\n",
    "        \"\"\"\n",
    "        if (self.deconv == True):\n",
    "            title      = self.File.metadata.General.title\n",
    "            title_corr = self.check_underscores_in_title(title)\n",
    "\n",
    "            self.File.metadata.General.title = title_corr\n",
    "            self.File.get_histogram().plot()\n",
    "        else:\n",
    "            title      = self.File_deconv.metadata.General.title\n",
    "            title_corr = self.check_underscores_in_title(title)\n",
    "\n",
    "            self.File_deconv.metadata.General.title = title_corr\n",
    "            self.File_deconv.get_histogram().plot()\n",
    "            \n",
    "    \n",
    "    def plot_model(self,\n",
    "                   navigator       = 'auto',\n",
    "                   show_components = False,\n",
    "                   cmap            = 'coolwarm'\n",
    "                  ):\n",
    "        \"\"\"\n",
    "        Plotting the fitting model of the spectrum image.\n",
    "        \n",
    "            navigator:       If True - adding a navigator instead of the navigation\n",
    "                                       image\n",
    "            \n",
    "            show_components: If True - additionally plot each component of the model\n",
    "                                       seperately\n",
    "        \"\"\"\n",
    "        self.Fit_Model.plot(navigator       = navigator,\n",
    "                            plot_components = show_components,\n",
    "                            navigator_kwds=dict(colorbar=True, \n",
    "                                                scalebar_color='black',\n",
    "                                                cmap=cmap,\n",
    "                                                axes_ticks=True\n",
    "                                               )\n",
    "                           )\n",
    "        \n",
    "\n",
    "    def plot_parameter_maps(self,\n",
    "                            marker_width       = 3.,\n",
    "                            rotate             = False,\n",
    "                            first_plasmon_only = False,\n",
    "                            cmap               = 'coolwarm',\n",
    "                            overview           = True\n",
    "                           ):\n",
    "        \"\"\"\n",
    "        Visualize all parameter maps that were previously generated.\n",
    "        \n",
    "            first_plasmon_only: If True - only the first Plasmon peak component \n",
    "                                          is plotted\n",
    "                                          \n",
    "            cmap: Changing the style of the colorbar by following matplotlibs styles\n",
    "            \n",
    "            overview:           If True - Plot every parameter map in a single\n",
    "                                          figure as an overview instead of plotting\n",
    "                                          each parameter map seperately\n",
    "        \"\"\"\n",
    "        if (self.attr_deconv == False and first_plasmon_only == False):\n",
    "            \n",
    "            if (overview == True):\n",
    "                \n",
    "                if (rotate == True):\n",
    "                    images = hs.stack([hs.signals.Signal2D(np.transpose(self.param_dict[title].data)\n",
    "                                                          )\n",
    "                                       for title in self.param_dict]\n",
    "                                     ) \n",
    "                else:\n",
    "                    images = hs.stack([self.param_dict[title] \n",
    "                                       for title in self.param_dict])\n",
    "                \n",
    "                \n",
    "                vmin, vmax = [], []\n",
    "                for image in images:\n",
    "                    self.delete_marker(image)\n",
    "                    \n",
    "                    vmin.append(np.nanmean(image.data)\n",
    "                                -np.nanstd(image.data)\n",
    "                               )\n",
    "                    vmax.append(np.nanmean(image.data)\n",
    "                                +np.nanstd(image.data)\n",
    "                               )\n",
    "                \n",
    "                hs.plot.plot_images(images, \n",
    "                                    cmap=cmap,\n",
    "                                    colorbar='multi',\n",
    "                                    centre_colormap=False,\n",
    "                                    suptitle='Overview',\n",
    "                                    suptitle_fontsize=16,\n",
    "                                    label=[r'{} {}'.format(title.encode('unicode-escape').decode().replace('\\\\\\\\','\\\\'), \n",
    "                                                           'in '+self.param_dict[title].metadata.Signal.quantity\n",
    "                                                          ) \n",
    "                                           for title in self.param_dict\n",
    "                                          ],\n",
    "                                    axes_decor='off',\n",
    "                                    tight_layout=True,\n",
    "                                    labelwrap=25,\n",
    "                                    scalebar_color='black',\n",
    "                                    vmin=vmin,\n",
    "                                    vmax=vmax\n",
    "                                   )\n",
    "                \n",
    "            else:\n",
    "                for title in self.param_dict:\n",
    "                    self.delete_marker(self.param_dict[title])\n",
    "                    \n",
    "                    vmin = (np.nanmean(self.param_dict[title].data)\n",
    "                            -np.nanstd(self.param_dict[title].data)\n",
    "                           )\n",
    "                    vmax = (np.nanmean(self.param_dict[title].data)\n",
    "                            +np.nanstd(self.param_dict[title].data)\n",
    "                           )\n",
    "                    \n",
    "                    self.param_dict[title].plot(cmap = cmap,\n",
    "                                                centre_colormap=False,\n",
    "                                                label=('{} {}'.format(title.encode('unicode-escape').decode().replace('\\\\\\\\','\\\\'), \n",
    "                                                                      'in '+self.param_dict[title].metadata.Signal.quantity\n",
    "                                                                     )\n",
    "                                                      ),\n",
    "                                                axes_ticks=True,\n",
    "                                                scalebar_color='black',\n",
    "                                                vmin=vmin,\n",
    "                                                vmax=vmax\n",
    "                                               )\n",
    "                    \n",
    "                    if (self.line != None):\n",
    "                        self.draw_line_marker(self.param_dict[title], marker_width)\n",
    "            \n",
    "            if (self.linescan_plots != {}):\n",
    "                for key in self.linescan_plots:\n",
    "                    self.linescan_plots[key].show()\n",
    "                    \n",
    "                \n",
    "        else:\n",
    "            \n",
    "            \n",
    "            if (overview == True):\n",
    "                \n",
    "                if (rotate == True):\n",
    "                    images = hs.stack([hs.signals.Signal2D(np.transpose(self.param_dict[title].data)\n",
    "                                                          )\n",
    "                                       for title in self.param_dict]\n",
    "                                     ) \n",
    "                else:\n",
    "                    images = hs.stack([self.param_dict[title] \n",
    "                                       for title in self.param_dict])\n",
    "                \n",
    "                vmin, vmax = [], []\n",
    "                for image in images:\n",
    "                    \n",
    "                    vmin.append(np.nanmean(image.data)\n",
    "                                -np.nanstd(image.data)\n",
    "                               )\n",
    "                    vmax.append(np.nanmean(image.data)\n",
    "                                +np.nanstd(image.data)\n",
    "                               )\n",
    "                \n",
    "                hs.plot.plot_images(images, \n",
    "                                    cmap=cmap,\n",
    "                                    colorbar='multi',\n",
    "                                    centre_colormap=False,\n",
    "                                    suptitle='Overview',\n",
    "                                    suptitle_fontsize=16,\n",
    "                                    label=[r'{} {}'.format(title.encode('unicode-escape').decode().replace('\\\\\\\\','\\\\'), \n",
    "                                                           'in '+self.param_dict[title].metadata.Signal.quantity\n",
    "                                                          ) \n",
    "                                           for title in self.param_dict\n",
    "                                          ],\n",
    "                                    axes_decor='off',\n",
    "                                    tight_layout=True,\n",
    "                                    labelwrap=25, \n",
    "                                    scalebar_color='black',\n",
    "                                    vmin=vmin,\n",
    "                                    vmax=vmax\n",
    "                                   )\n",
    "                \n",
    "                \n",
    "            else:\n",
    "                for title in self.param_dict:\n",
    "                    self.delete_marker(self.param_dict[title])\n",
    "                    \n",
    "                    vmin = (np.nanmean(self.param_dict[title].data)\n",
    "                            -np.nanstd(self.param_dict[title].data)\n",
    "                           )\n",
    "                    vmax = (np.nanmean(self.param_dict[title].data)\n",
    "                            +np.nanstd(self.param_dict[title].data)\n",
    "                           )\n",
    "                    \n",
    "                    self.param_dict[title].plot(cmap = cmap,\n",
    "                                                centre_colormap=False,\n",
    "                                                label=('{} {}'.format(title.encode('unicode-escape').decode().replace('\\\\\\\\','\\\\'), \n",
    "                                                                      'in '+self.param_dict[title].metadata.Signal.quantity\n",
    "                                                                     )\n",
    "                                                      ),\n",
    "                                                axes_ticks=True,\n",
    "                                                scalebar_color='black',\n",
    "                                                vmin=vmin,\n",
    "                                                vmax=vmax\n",
    "                                               )\n",
    "                    \n",
    "                    if (self.line != None):\n",
    "                        self.draw_line_marker(self.param_dict[title], marker_width)\n",
    "                    \n",
    "                    self.delete_marker(self.param_dict[title])\n",
    "                    \n",
    "            if (self.linescan_plots != {}):\n",
    "                for key in self.linescan_plots:\n",
    "                    self.linescan_plots[key].show()\n",
    "    \n",
    "    \n",
    "    def print_stats(self):\n",
    "        \"\"\"\n",
    "        Printing standard file information.\n",
    "        \"\"\"\n",
    "        print('Statistics of loaded spectrum image:')\n",
    "        self.File.print_summary_statistics()\n",
    "        print('Statistics of deconvolved spectrum image:')\n",
    "        self.File_deconv.print_summary_statistics()\n",
    "    \n",
    "    \n",
    "    def print_param_stats(self):\n",
    "        \"\"\"\n",
    "        Printing standard parameter information\n",
    "        \"\"\"\n",
    "        for title in self.param_dict:\n",
    "            print(title)\n",
    "            self.param_dict[title].print_summary_statistics()\n",
    "    \n",
    "    \n",
    "    \n",
    "    def create_dirs(self):\n",
    "        \"\"\"\n",
    "        Creating directories and sub-directories for evaluation storage.\n",
    "        \"\"\"\n",
    "        for directory in self.dir_list:\n",
    "            self.mk_dir(os.getcwd() + os.sep + directory)\n",
    "    \n",
    "    def mk_dir(self, directory):\n",
    "        \"\"\"\n",
    "        creating a directory and intermediate missing directories\n",
    "        \"\"\"\n",
    "        if not os.path.exists(directory):\n",
    "            \n",
    "            print('Creating:', os.getcwd() + os.sep + directory)\n",
    "            if (directory.endswith(os.sep)):\n",
    "                os.makedirs(directory)\n",
    "            else:\n",
    "                os.makedirs(directory + os.sep)\n",
    "        \n",
    "    \n",
    "    def select_directory(self):\n",
    "        \"\"\"\n",
    "        select a directory and make it the current working directory\n",
    "        \"\"\"\n",
    "        dir_name = askdirectory() # asks user to choose a directory\n",
    "        self.mk_dir(dir_name)\n",
    "        \n",
    "        if (dir_name.endswith(os.sep)):\n",
    "            os.chdir(dir_name) # changes your current directory\n",
    "        else:\n",
    "            os.chdir(dir_name + os.sep) # changes your current directory ending with seperator\n",
    "    \n",
    "    \n",
    "    def delete_marker(self, im):\n",
    "        try:\n",
    "            del im.metadata.Markers.line_segment\n",
    "            del im.metadata.Markers.line_segment1\n",
    "            del im.metadata.Markers.line_segment2\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    def draw_line_marker(self, im, marker_width):\n",
    "        \"\"\"\n",
    "        function marking a linescan region in image by drawing\n",
    "        a main line and two additional smaller lines for the indication\n",
    "        of the linewidth\n",
    "        \"\"\"\n",
    "        scale  = im.axes_manager.signal_axes[0].scale\n",
    "        offset = im.axes_manager.signal_axes[0].offset\n",
    "\n",
    "        string=str(self.line)\n",
    "        line_params=string.split('(')[1].split(')')[0].split(',',-1)\n",
    "        coords=[float(line_params[i].split('=')[1]) for i in range(len(line_params))]\n",
    "\n",
    "        offset_x=coords[4]/2*np.sin(np.pi*self.line.angle()/180)\n",
    "        offset_y=-coords[4]/2*np.cos(np.pi*self.line.angle()/180)\n",
    "\n",
    "        marker    = hs.plot.markers.line_segment(\n",
    "            x1=coords[0], x2=coords[2], \n",
    "            y1=coords[1], y2=coords[3],\n",
    "            linewidth=marker_width*scale, color='black', linestyle='-'\n",
    "        )\n",
    "        marker_l  = hs.plot.markers.line_segment(\n",
    "            x1=coords[0]-offset_x, x2=coords[2]-offset_x, \n",
    "            y1=coords[1]-offset_y, y2=coords[3]-offset_y,\n",
    "            linewidth=marker_width/2*scale, color='black', linestyle='--'\n",
    "        )\n",
    "        marker_r  = hs.plot.markers.line_segment(\n",
    "            x1=coords[0]+offset_x, x2=coords[2]+offset_x, \n",
    "            y1=coords[1]+offset_y, y2=coords[3]+offset_y,\n",
    "            linewidth=marker_width/2*scale, color='black', linestyle='--'\n",
    "        )\n",
    "        \n",
    "        im.add_marker(marker, permanent=True)\n",
    "        im.add_marker(marker_l, permanent=True)\n",
    "        im.add_marker(marker_r, permanent=True)\n",
    "        \n",
    "        return\n",
    "    \n",
    "    \n",
    "    def save_evaluation(self,\n",
    "                        dpi=300, \n",
    "                        fileformat='png',\n",
    "                        marker_width=3.,\n",
    "                        cmap='coolwarm',\n",
    "                        rotate=False\n",
    "                       ):\n",
    "        \n",
    "        \"\"\"\n",
    "        Saving function to save all generated parameter maps that were previously generated.\n",
    "            \n",
    "            dpi: Resolution with which the parameters are saved\n",
    "            \n",
    "            fileformat: Choose the file format (take a look at hyperspy's documentation for\n",
    "                                                supported file formats)\n",
    "            \n",
    "            cmap: Changing the style of the colorbar by following matplotlibs styles \n",
    "        \"\"\"\n",
    "        self.select_directory()\n",
    "        self.create_dirs()\n",
    "        \n",
    "        dir_fname = {r'Plasmon peak - $E_{\\max}$'          : 'FPP_Emax',\n",
    "                     r'Plasmon peak - $\\Gamma$'            : 'FPP_FWHM',\n",
    "                     r'Plasmon peak - intensity'           : 'FPP_Int' ,\n",
    "            \n",
    "                     r'Zero Loss peak - $E_{\\max}$'        : 'ZLP_Emax',\n",
    "                     r'Zero Loss peak - $\\Gamma$'          : 'ZLP_FWHM',\n",
    "                     r'Zero Loss peak - intensity'         : 'ZLP_Int' ,\n",
    "                     \n",
    "                     r'second Plasmon peak - $E_{\\max}$'   : 'SPP_Emax',\n",
    "                     r'second Plasmon peak - $\\Gamma$'     : 'SPP_FWHM',\n",
    "                     r'second Plasmon peak - intensity'    : 'SPP_Int' ,\n",
    "                     \n",
    "                     r'Plasmon energy - $E_{p}(q=0)$'      : 'Ep_q0',\n",
    "                     r'intensity ratio - $I_{pp}/I_{zlp}$' : 'Intensity_Ratio',\n",
    "                     r'thickness by log-ratio'             : 'thickness'\n",
    "                    }\n",
    "        \n",
    "        print('Writing parameter maps to disk...')\n",
    "        \n",
    "        if (rotate == True):\n",
    "            images = hs.stack([hs.signals.Signal2D(np.transpose(self.param_dict[title].data)\n",
    "                                                  )\n",
    "                              for title in self.param_dict]\n",
    "                             ) \n",
    "        else:\n",
    "            images = hs.stack([self.param_dict[title] \n",
    "                               for title in self.param_dict])\n",
    "\n",
    "        vmin, vmax = [], []\n",
    "        for image in images:\n",
    "            vmin.append(np.nanmean(image.data)\n",
    "                        -np.nanstd(image.data)\n",
    "                       )\n",
    "            vmax.append(np.nanmean(image.data)\n",
    "                        +np.nanstd(image.data)\n",
    "                       )\n",
    "            \n",
    "        hs.plot.plot_images(images, \n",
    "                            no_nans = True,\n",
    "                            cmap = cmap,\n",
    "                            colorbar='multi',\n",
    "                            centre_colormap=False,\n",
    "                            suptitle = 'Parameter Overview',\n",
    "                            suptitle_fontsize = 16,\n",
    "                            label = [r'{} {}'.format(title, \n",
    "                                                     'in '+self.param_dict[title].metadata.Signal.quantity\n",
    "                                                    )\n",
    "                                     for title in self.param_dict\n",
    "                                    ],\n",
    "                            axes_decor = 'off',\n",
    "                            tight_layout = True,\n",
    "                            labelwrap = 25,\n",
    "                            vmin=vmin,\n",
    "                            vmax=vmax\n",
    "                           )\n",
    "        fname = os.getcwd() + os.sep + 'overview'\n",
    "        plt.savefig('overview', dpi=dpi, extension=fileformat)\n",
    "        plt.close()\n",
    "\n",
    "        for title in self.param_dict:\n",
    "            self.delete_marker(self.param_dict[title])\n",
    "            \n",
    "            vmin = (np.nanmean(self.param_dict[title].data)\n",
    "                    -np.nanstd(self.param_dict[title].data)\n",
    "                   )\n",
    "            vmax = (np.nanmean(self.param_dict[title].data)\n",
    "                    +np.nanstd(self.param_dict[title].data)\n",
    "                   )\n",
    "            \n",
    "            fname = os.getcwd() + os.sep + self.dir_list[0] + os.sep + dir_fname[title]\n",
    "            self.param_dict[title].metadata.General.title = title\n",
    "            self.param_dict[title].plot(scalebar_color='black', \n",
    "                                        cmap=cmap, \n",
    "                                        centre_colormap=False,\n",
    "                                        vmin=vmin,\n",
    "                                        vmax=vmax\n",
    "                                       )\n",
    "            if (self.line != None):\n",
    "                self.draw_line_marker(self.param_dict[title], marker_width)\n",
    "                    \n",
    "            plt.savefig(fname, dpi=dpi, extension=fileformat)\n",
    "            plt.close()\n",
    "            self.delete_marker(self.param_dict[title])\n",
    "        \n",
    "        if (self.linescan_plots != {}):\n",
    "            print('Writing line scans to disk...')\n",
    "        \n",
    "            for key in self.linescan_plots:\n",
    "                if ('thickness' in key):\n",
    "                    fname = os.getcwd() + os.sep + self.dir_list[1] + os.sep + key\n",
    "                    self.linescan_plots[key].savefig(fname, dpi=dpi, extension=fileformat)\n",
    "                    plt.close(self.linescan_plots[key].number)\n",
    "                else:\n",
    "                    if ('intensity ratio - $I_{pp}/I_{zlp}$' in key):\n",
    "                        key_adj = key.split('-',-1)[0] + key.split('-',-1)[2]\n",
    "                        fname = os.getcwd() + os.sep + self.dir_list[0] + os.sep + key_adj\n",
    "                        self.linescan_plots[key].savefig(fname, dpi=dpi, extension=fileformat)\n",
    "                        plt.close(self.linescan_plots[key].number)\n",
    "                    else:\n",
    "                        fname = os.getcwd() + os.sep + self.dir_list[0] + os.sep + key\n",
    "                        self.linescan_plots[key].savefig(fname, dpi=dpi, extension=fileformat)\n",
    "                        plt.close(self.linescan_plots[key].number)\n",
    "        \n",
    "        else:\n",
    "            print('No line scans were found. Please remember to use the\\n'\n",
    "                  +'generate_linescans() attribute previous to save_evaluation()'\n",
    "                  +'attribute, if line scans are demanded. Continue...'\n",
    "                 )\n",
    "        \n",
    "        print('Writing goodness to disk...')\n",
    "        title      = self.red_Chisq.metadata.General.title\n",
    "        title_corr = self.check_underscores_in_title(title)\n",
    "        self.red_Chisq.metadata.General.title = title_corr\n",
    "        \n",
    "        fname = os.getcwd() + os.sep + 'Model_red_Chisq'\n",
    "        self.red_Chisq.metadata.General.title = r'adj. $\\chi_{\\nu}^2$ - Goodness'\n",
    "        self.red_Chisq.plot(scalebar_color='black', cmap=cmap, centre_colormap=False)\n",
    "        plt.savefig(fname, dpi=dpi, extension=fileformat)\n",
    "        plt.close()\n",
    "        \n",
    "        print('Trying to access thickness signal...')\n",
    "        if (self.thickness_map != None):\n",
    "            print('Writing thickness estimation to disk...')\n",
    "            title      = self.thickness_map.metadata.General.title\n",
    "            title_corr = self.check_underscores_in_title(title)\n",
    "            self.thickness_map.metadata.General.title = title_corr\n",
    "            \n",
    "            fname = os.getcwd() + os.sep + self.dir_list[1] + os.sep + 'thickness_logratio'\n",
    "            self.thickness_map.plot(scalebar_color='black', cmap=cmap, centre_colormap=False)\n",
    "            plt.savefig(fname, dpi=dpi, extension=fileformat)\n",
    "            plt.close()\n",
    "        \n",
    "        else:\n",
    "            print('No thickness signal was found. Please calculate the thickness'\n",
    "                  +'by log-ratio if demanded.')\n",
    "        \n",
    "        print('Finished!')\n",
    "        \n",
    "    \n",
    "    # Calculate thickness by log ratio of ZLP-Area to Total Area of EELS-data\n",
    "    def calc_thickness(self, elements, concentrations):\n",
    "        \"\"\"\n",
    "        Estimation of the sample thickness by the Log-Ratio method\n",
    "                \n",
    "            LATEX Formula:\n",
    "                t = \\lambda \\ln{ \\frac{I_t}{I_0} }\n",
    "                \n",
    "                with:\n",
    "                         I_t = total intensity\n",
    "                    and  I_0 = elastically scattered intensity (0-fold intensity)\n",
    "        \n",
    "        absolute accuracy at +- 20% for inorganic specimen \n",
    "        \n",
    "        For more information see:\n",
    "            EELS Log-Ratio Technique for Specimen-Thickness\n",
    "            Measurement in the TEM                    \n",
    "        \n",
    "            MALIS, S.C. CHENG, AND R.F. EGERTON\n",
    "            JOURNAL OF ELECTRON MICROSCOPY TECHNIQUE 8:193-200 11988)\n",
    "        \n",
    "        Mean Free Path (\\lambda) estimation is automated for a given elemental \n",
    "        composition.\n",
    "        \n",
    "        IMPORTANT:\n",
    "            MFP-Automation takes metadata of file as input. Please verify that \n",
    "            values for beam energy and collection angle specified in .dm3/.dm4 \n",
    "            files are correct before using this function.\n",
    "        \n",
    "        Currently supported elements: \n",
    "        (\n",
    "         Ag, Al, Au, Be, Ca, Ce, Cu, Dy, Er, Eu, Fe, Gd, Ho, La, Lu, Mg, Nb, \n",
    "         Nd, Ni, P, Pd, Pm, Pr, Sm, Sn, Tb, Ti, Y, Yb, Zn, Zr\n",
    "        )\n",
    "        \"\"\"\n",
    "        if (self.is_lazy == True):\n",
    "            self.File.compute()\n",
    "            t_lambda = self.File.estimate_thickness(threshold=self.elastic_threshold).T\n",
    "            \n",
    "        mfp                = self.estimate_MFP(elements, concentrations)\n",
    "        print('Estimated mean free path: %.2E nm' % (mfp,))\n",
    "        self.thickness_map = t_lambda * mfp\n",
    "        \n",
    "        self.thickness_map.metadata.General.title = r'thickness by log-ratio' \n",
    "        self.thickness_map.metadata.Signal.quantity = 'nm'\n",
    "        \n",
    "        #as the absolute error is about 20 % following Malis et. al\n",
    "        #we assume this to be the gain factor\n",
    "        var = self.thickness_map.estimate_poissonian_noise_variance(gain_factor=0.20)\n",
    "        self.thickness_map.metadata.Signal.Noise_properties.variance = var\n",
    "        \n",
    "        self.param_dict.update( {self.thickness_map.metadata.General.title : self.thickness_map} )\n",
    "        \n",
    "        if (self.is_lazy == True):\n",
    "            self.File = self.File.as_lazy()\n",
    "    \n",
    "    \n",
    "    def estimate_MFP(self, elements, concentrations):#, elements, concentration):\n",
    "        \"\"\"\n",
    "        Estimation of the Mean Free Path for a given elemental composition (in nm).\n",
    "        \n",
    "        IMPORTANT:\n",
    "            MFP-Automation takes metadata of file as input. Please verify that \n",
    "            values for beam energy and collection angle specified in .dm3/.dm4 \n",
    "            files are correct before using this function.\n",
    "            Default values (if not specified in metadata):\n",
    "                E0   = 300 keV\n",
    "                beta =  10 mrad\n",
    "        \n",
    "        Currently supported elements: \n",
    "        (\n",
    "         Ag, Al, Au, Be, Ca, Ce, Cu, Dy, Er, Eu, Fe, Gd, Ho, La, Lu, Mg, Nb, \n",
    "         Nd, Ni, P, Pd, Pm, Pr, Sm, Sn, Tb, Ti, Y, Yb, Zn, Zr\n",
    "        )\n",
    "        \"\"\"\n",
    "        \n",
    "        element_dict = {'Ag' : mend.Ag,\n",
    "                        'Al' : mend.Au,\n",
    "                        'Au' : mend.Au,\n",
    "                        'Be' : mend.Be,\n",
    "                        'Ca' : mend.Ca,\n",
    "                        'Ce' : mend.Ce,\n",
    "                        'Cu' : mend.Cu,\n",
    "                        'Dy' : mend.Dy,\n",
    "                        'Er' : mend.Er,\n",
    "                        'Eu' : mend.Eu,\n",
    "                        'Fe' : mend.Fe,\n",
    "                        'Gd' : mend.Gd,\n",
    "                        'Ho' : mend.Ho,\n",
    "                        'La' : mend.La,\n",
    "                        'Lu' : mend.Lu,\n",
    "                        'Mg' : mend.Mg,\n",
    "                        'Nb' : mend.Nb,\n",
    "                        'Nd' : mend.Nd,\n",
    "                        'Ni' : mend.Ni,\n",
    "                        'P'  : mend.P,\n",
    "                        'Pd' : mend.Pd,\n",
    "                        'Pm' : mend.Pm,\n",
    "                        'Pr' : mend.Pr,\n",
    "                        'Pt' : mend.Pt,\n",
    "                        'Sm' : mend.Sm,\n",
    "                        'Sn' : mend.Sn,\n",
    "                        'Tb' : mend.Tb,\n",
    "                        'Ti' : mend.Ti,\n",
    "                        'Tm' : mend.Tm,\n",
    "                        'Y'  : mend.Y,\n",
    "                        'Yb' : mend.Yb,\n",
    "                        'Zn' : mend.Zn,\n",
    "                        'Zr' : mend.Zr\n",
    "                       }\n",
    "        \n",
    "        const              = 0.3 # Malis et. al - konstante r nach eq.(4)\n",
    "        number_of_elements = len(elements)\n",
    "        fi_Zi_numerator    = 0\n",
    "        fi_Zi_denominator  = 0\n",
    "\n",
    "        for i in range(number_of_elements):\n",
    "            \n",
    "            Z                  = element_dict[elements[i]].atomic_number\n",
    "            fi_Zi_numerator   += concentrations[i] * Z**(1+const)\n",
    "        \n",
    "        \n",
    "        for i in range(number_of_elements):\n",
    "            \n",
    "            Z                  = element_dict[elements[i]].atomic_number\n",
    "            fi_Zi_denominator += concentrations[i] * Z**(const)\n",
    "\n",
    "        Z_eff = fi_Zi_numerator/fi_Zi_denominator\n",
    "\n",
    "        m    = 0.36 # Malis EELS paper - exponent m nach eq.(8)\n",
    "        E_m  = 7.6*Z_eff**m # eq.(8): 7.6 eV\n",
    "        \n",
    "        E_0  = self.File.metadata.Acquisition_instrument.TEM.beam_energy\n",
    "        beta = self.File.metadata.Acquisition_instrument.TEM.Detector.EELS.collection_angle\n",
    "\n",
    "        F = (1 + E_0/1022)/(1 + E_0/511)**2 # Malis EELS paper - E_0 in keV nach eq.(6) \n",
    "\n",
    "        mean_free_path = 106 * F * E_0 / (E_m * np.log(2 * beta * E_0 / E_m))\n",
    "        \n",
    "        return mean_free_path\n",
    "    \n",
    "        \n",
    "    def line_roi(self, \n",
    "                 param_map,\n",
    "                 order,\n",
    "                 width,\n",
    "                 interactive=False,\n",
    "                 cmap='coolwarm'\n",
    "                ):\n",
    "        \"\"\"\n",
    "        Comments missing\n",
    "        \"\"\"\n",
    "        if (self.line == None):\n",
    "            x1 = 0 \n",
    "            y1 = 0 \n",
    "            x2 = 15 \n",
    "            y2 = 15\n",
    "            \n",
    "            self.line = hs.roi.Line2DROI(x1 * param_map.axes_manager[0].scale + \n",
    "                                         param_map.axes_manager[0].offset,\n",
    "                                         y1 * param_map.axes_manager[1].scale + \n",
    "                                         param_map.axes_manager[1].offset,\n",
    "                                         x2 * param_map.axes_manager[0].scale + \n",
    "                                         param_map.axes_manager[0].offset,\n",
    "                                         y2 * param_map.axes_manager[1].scale + \n",
    "                                         param_map.axes_manager[1].offset,\n",
    "                                         linewidth = width \n",
    "                                        )\n",
    "        \n",
    "        if (interactive == True):\n",
    "            param_map.plot(scalebar_color='black', cmap=cmap, centre_colormap=False)\n",
    "            \n",
    "            time = self.time\n",
    "            answer = False\n",
    "            print('Waiting %d seconds for adjustment. ' % (time,))\n",
    "            while (answer == False):\n",
    "                plt.ion()\n",
    "                line = self.line.interactive(param_map, order=order)\n",
    "                plt.show()\n",
    "                plt.draw()\n",
    "                plt.pause(time)\n",
    "                answer = self.yes_or_no('\\nTo exit adjustment, please type (y).'\n",
    "                                        + 'To continue adjustment for %d, please type (n)' % (time,)\n",
    "                                       )\n",
    "            \n",
    "            return line\n",
    "            \n",
    "        else:\n",
    "            return self.line(param_map, order=order)\n",
    "\n",
    "            \n",
    "    def line_variance(self, \n",
    "                      param_map,\n",
    "                      order,\n",
    "                      line_scan\n",
    "                     ):\n",
    "        \"\"\"\n",
    "        larger image test\n",
    "        angle test\n",
    "        scaling of elipse effect\n",
    "        interpolation\n",
    "        \"\"\"\n",
    "        if (self.line == None):\n",
    "            print('No line is defined. No calculation of standard deviation is possible.')\n",
    "            return\n",
    "        \n",
    "        angle = self.line.angle()\n",
    "        width = self.line.linewidth\n",
    "        \n",
    "        line_std      = line_scan.deepcopy()\n",
    "        line_fstd     = line_scan.deepcopy()\n",
    "        scale         = line_scan.axes_manager.signal_axes[0].scale\n",
    "        size          = line_scan.axes_manager.signal_axes[0].size\n",
    "\n",
    "        properties  = str(self.line).split('=',-1)[1::]\n",
    "        line_coords = []\n",
    "        for ele in properties:\n",
    "            line_coords.append(ele.split(',')[::2])\n",
    "\n",
    "        line_coords[-1][0]=line_coords[-1][0].strip(')')\n",
    "        np.array(line_coords, dtype=float).ravel()\n",
    "\n",
    "        src=np.array([line_coords[0], line_coords[1]], dtype=float)\n",
    "        dst=np.array([line_coords[2], line_coords[3]], dtype=float)\n",
    "\n",
    "        #scalar product for length if needed\n",
    "        def getLength(src,dst):\n",
    "            length_vec = dst-src\n",
    "            length=0\n",
    "            for num in length_vec:\n",
    "                length+=num[0]*num[0]\n",
    "            return np.sqrt(length)\n",
    "\n",
    "        #center of src and destination as well as director by vector calculation\n",
    "        length = abs(getLength(src, dst))\n",
    "        \n",
    "        CoM = src + (dst-src) / 2\n",
    "        director = (dst-src)\n",
    "        director_scaled = scale * director / length\n",
    "\n",
    "        #rotate around CoM\n",
    "        def rotatePoint(point, center, angle):\n",
    "            angle = angle * (np.pi/180)#convert to radians\n",
    "\n",
    "            rotatedX = (np.cos(angle) * (point[0]-center[0]) \n",
    "                        - np.sin(angle) * (point[1]-center[1]) + center[0])\n",
    "            rotatedY = (np.sin(angle) * (point[0]-center[0]) \n",
    "                        + np.cos(angle) * (point[1]-center[1]) + center[1])\n",
    "\n",
    "            return np.array([rotatedX,rotatedY], dtype=float)\n",
    "\n",
    "        \n",
    "        #points rotated orthogonaly and scaled corresponding to width of linescan\n",
    "        src_rotate = rotatePoint(src, CoM, 90)\n",
    "        dst_rotate = rotatePoint(dst, CoM, 90)\n",
    "        \n",
    "        length_rot = abs(getLength(src_rotate, dst_rotate))\n",
    "        \n",
    "        director_rot        = (dst_rotate-src_rotate) \n",
    "        director_rot_scaled = scale * director_rot / length_rot\n",
    "        \n",
    "        src_rotate_scaled   = CoM - director_rot_scaled * width / 2\n",
    "        dst_rotate_scaled   = CoM + director_rot_scaled * width / 2\n",
    "        \n",
    "        \n",
    "        for step in range(size):\n",
    "            #Stepping over line scan positions orthogonaly to estimate each variance\n",
    "            #of the linewidth line scan data point (CoM and scaled director\n",
    "            #shift the coordinates correspondingly\n",
    "            offset = director / 2\n",
    "            x1 = src_rotate_scaled[0] + director_scaled[0] * step - offset[0]\n",
    "            y1 = src_rotate_scaled[1] + director_scaled[1] * step - offset[1]\n",
    "            x2 = dst_rotate_scaled[0] + director_scaled[0] * step - offset[0]\n",
    "            y2 = dst_rotate_scaled[1] + director_scaled[1] * step - offset[1]\n",
    "            \n",
    "            line_rot = hs.roi.Line2DROI(x1=x1, \n",
    "                                        y1=y1, \n",
    "                                        x2=x2, \n",
    "                                        y2=y2, \n",
    "                                        linewidth=scale\n",
    "                                       )\n",
    "\n",
    "            #filter zeros and set zero std values to mean std by spatial std analysis\n",
    "            rotated_line = line_rot(param_map, order=order)\n",
    "\n",
    "            line_nozeros = np.where(rotated_line.data != 0,\n",
    "                                    rotated_line.data,\n",
    "                                    np.nan\n",
    "                                   )\n",
    "            std = np.nanstd(line_nozeros.data)\n",
    "            \n",
    "            line_std.isig[step] = std\n",
    "\n",
    "        \n",
    "        mean_line = np.nanmean(line_std.data)\n",
    "        \n",
    "        line_var  = hs.signals.Signal1D(np.where(line_std.data != 0., \n",
    "                                                 line_std.data**2,\n",
    "                                                 mean_line**2\n",
    "                                                )\n",
    "                                       )\n",
    "\n",
    "        print('Variance estimation for:', param_map.metadata.General.title)\n",
    "        print('mean variance: ',np.nanmean(line_var.data))\n",
    "        \n",
    "        try:\n",
    "            #Alternatively: take param_map-variance property using fitting error estimation by:\n",
    "            \n",
    "            for step in range(size):\n",
    "                #Stepping over line scan positions orthogonaly to estimate each variance\n",
    "                #of the linewidth line scan data point (CoM and scaled director\n",
    "                #shift the coordinates correspondingly)\n",
    "                offset = director / 2\n",
    "                x1 = src_rotate_scaled[0] + director_scaled[0] * step - offset[0]\n",
    "                y1 = src_rotate_scaled[1] + director_scaled[1] * step - offset[1]\n",
    "                x2 = dst_rotate_scaled[0] + director_scaled[0] * step - offset[0]\n",
    "                y2 = dst_rotate_scaled[1] + director_scaled[1] * step - offset[1]\n",
    "\n",
    "                line_rot = hs.roi.Line2DROI(x1=x1, \n",
    "                                            y1=y1, \n",
    "                                            x2=x2, \n",
    "                                            y2=y2, \n",
    "                                            linewidth=scale\n",
    "                                           )\n",
    "\n",
    "                #filter zeros and set zero std values to mean std by spatial std analysis\n",
    "                rotated_line_fstd = line_rot(np.sqrt(param_map.metadata.Signal.Noise_properties.variance),\n",
    "                                             order=order\n",
    "                                            )\n",
    "\n",
    "                rotated_line_nonzero_fstd = np.where(rotated_line_fstd.data == 0.,\n",
    "                                                     np.nan,\n",
    "                                                     rotated_line_fstd.data\n",
    "                                                    )\n",
    "\n",
    "                mean_fstd = np.nanstd(rotated_line_nonzero_fstd)\n",
    "\n",
    "                line_fstd.isig[step] = mean_fstd\n",
    "\n",
    "\n",
    "            mean_line_fstd = np.nanmean(line_fstd.data)\n",
    "\n",
    "            line_var_fstd  = hs.signals.Signal1D(np.where(line_fstd.data != 0, \n",
    "                                                          line_fstd.data**2,\n",
    "                                                          mean_line_fstd**2\n",
    "                                                         )\n",
    "                                                )\n",
    "            print('mean variance of fitted parameters: ',np.nanmean(line_var_fstd.data))\n",
    "            \n",
    "        except AttributeError as err:\n",
    "            print(line_scan.metadata.General.title + ': \\n')\n",
    "            print(err)\n",
    "            print('\\nFalling back using spatial error estimation.')\n",
    "            line_var_fstd = hs.signals.Signal1D(np.full(np.shape(line_scan.data),\n",
    "                                                        np.nan\n",
    "                                                       )\n",
    "                                               )\n",
    "        \n",
    "        return line_var, line_var_fstd\n",
    "            \n",
    "    \n",
    "    def rect_roi(self, \n",
    "                 param_map,\n",
    "                 interactive=False,\n",
    "                 width=15,\n",
    "                 height=15,\n",
    "                 cmap='coolwarm'\n",
    "                ):\n",
    "        \"\"\"\n",
    "        rectangle roi to evaluate regions of interest by simple statistical analysis\n",
    "        investigating the mean and the standard deviation of the region.\n",
    "        \n",
    "        can also be used to investigate the variance property of a parameter map\n",
    "        to further investigate the region of interest correspondingly.\n",
    "        \n",
    "        returns a full image of the region of investigation, which can also be analyzed\n",
    "        further by e.g. using generate_linescan() in combination with estimate_pshif()\n",
    "        attributes to generate parameter shifts of larger images in more detail.\n",
    "        \"\"\"\n",
    "        if (self.roi == None):\n",
    "            left   = 0 \n",
    "            top    = 0 \n",
    "            right  = left+width\n",
    "            bottom = top+height\n",
    "            \n",
    "            self.roi = hs.roi.RectangularROI(param_map.axes_manager.signal_axes[0].offset +\n",
    "                                             left   * param_map.axes_manager.signal_axes[0].scale,\n",
    "                                             param_map.axes_manager.signal_axes[1].offset +\n",
    "                                             top    * param_map.axes_manager.signal_axes[1].scale,\n",
    "                                             param_map.axes_manager.signal_axes[0].offset +\n",
    "                                             right  * param_map.axes_manager.signal_axes[0].scale,\n",
    "                                             param_map.axes_manager.signal_axes[1].offset +\n",
    "                                             bottom * param_map.axes_manager.signal_axes[1].scale\n",
    "                                            )\n",
    "        \n",
    "        if (interactive == True):\n",
    "            param_map.plot(scalebar_color='black', cmap=cmap)\n",
    "            answer = False\n",
    "            while (answer == False):\n",
    "                plt.ion()\n",
    "                roi = self.roi.interactive(param_map)\n",
    "                plt.show()\n",
    "                plt.draw()\n",
    "                plt.pause(30)\n",
    "                answer = self.yes_or_no('If finished: please type (y)' + '\\n' + \n",
    "                                        'To continue adjustment: pleas type (n).'\n",
    "                                       )\n",
    "                \n",
    "            print('Mean: ', roi.mean(axis=(0,1)).data)\n",
    "            print('Std: ', roi.std(axis=(0,1)).data)\n",
    "            \n",
    "            return roi\n",
    "            \n",
    "        else:\n",
    "            print('Mean: ', roi.mean(axis=(0,1)).data)\n",
    "            print('Std: ', roi.std(axis=(0,1)).data)\n",
    "            \n",
    "            return self.roi(param_map)\n",
    "            \n",
    "            \n",
    "    def generate_linescan(self,\n",
    "                          param_map,\n",
    "                          order,\n",
    "                          number,\n",
    "                          width,\n",
    "                          interactive = False,\n",
    "                          cmap        = 'coolwarm',\n",
    "                          std_by_fitting = False\n",
    "                         ):\n",
    "        \"\"\"\n",
    "        Generat\n",
    "        \"\"\"\n",
    "        line_scan = self.line_roi(param_map, \n",
    "                                  order,\n",
    "                                  interactive = interactive, \n",
    "                                  width       = width,\n",
    "                                  cmap        = cmap\n",
    "                                 )\n",
    "        \n",
    "        line_var, line_var_fstd  = self.line_variance(param_map, order, line_scan)\n",
    "        if (std_by_fitting == True and np.isfinite(line_var_fstd.data).all()):\n",
    "            line_scan.metadata.Signal.set_item(\"Noise_properties.variance\", \n",
    "                                               line_var_fstd\n",
    "                                              )\n",
    "        else:\n",
    "            line_scan.metadata.Signal.set_item(\"Noise_properties.variance\", \n",
    "                                               line_var\n",
    "                                              )\n",
    "        if (number == None):\n",
    "            line_scan.metadata.General.title = (param_map.metadata.General.title + \n",
    "                                                str(' - line scan')\n",
    "                                               )\n",
    "        else:\n",
    "            line_scan.metadata.General.title = (param_map.metadata.General.title + \n",
    "                                                str(' - line scan' + str(number))\n",
    "                                               )\n",
    "        \n",
    "        self.linescans[param_map.metadata.General.title] = line_scan\n",
    "        \n",
    "    \n",
    "    \n",
    "    # Calculate parametershifts by gausfitting\n",
    "    def generate_linescans(self,\n",
    "                           order              = 0,\n",
    "                           parameter_shifts   = False,\n",
    "                           polygradn          = 2,\n",
    "                           try_force_positive = False,\n",
    "                           try_force_negative = False,\n",
    "                           slope_th           = 0.,\n",
    "                           cmap             = 'coolwarm',\n",
    "                           interactive      = True,\n",
    "                           show             = False,\n",
    "                           position         = 1.,\n",
    "                           sensitivity      = 3,\n",
    "                           maxpeakn         = 10,\n",
    "                           medfilt_radius   = 3,\n",
    "                           peakgroup        = 5,\n",
    "                           number           = None,\n",
    "                           std_by_fitting   = False\n",
    "                          ):\n",
    "        \"\"\"\n",
    "        generating line scans and if demanded try estimating the parameter shifts\n",
    "        by using a simple gaussian in addition to a polynomial fit for estimation\n",
    "        of background influences like thickness variations in the specimen\n",
    "        \n",
    "        order - Interpolation type used for generating linescan (0: nearest,\n",
    "                1: linear, 2:cubic)\n",
    "        \n",
    "        parameter_shifts - if True automatic parameter shift estimation is applied\n",
    "                           using O'Haver's gaussian peak parameter estimation for\n",
    "                           parameter initialization and fitting the polynom using\n",
    "                           numpy.polyfit as well as scipy.optimize.curve_fit with\n",
    "                           underlying weighted least squared minimization for the\n",
    "                           polynomial fit in addition to the gaus fit. \n",
    "                           Strong bounds are applied to the fitting routine to \n",
    "                           stabilize the estimation. The weights for the polynomial\n",
    "                           fit are chosen to slightly enhance the contribution of \n",
    "                           the data points on the edges of a linescan. \n",
    "                           Standard weights are used afterwards for the \n",
    "                           gaussian fit on the substracted data as the initial\n",
    "                           parameters will fit the data quite well. The superposition\n",
    "                           of both function will then be optimized by a weighted\n",
    "                           least squared minimization adjusting polynomial and\n",
    "                           gaussian parameters accordingly.\n",
    "        \n",
    "        \n",
    "        polygradn - Polynomial degree (P(x)= a+b*x+c*x**2+...)\n",
    "          \n",
    "        try_force_positive/negative - Try forcing only positive or negative parameter\n",
    "                                      shift estimations by disabling the O'Haver\n",
    "                                      estimation for the inverse peak estimation\n",
    "                                      and setting bounds for peak height accordingly\n",
    "                                      positive or negative.\n",
    "        \n",
    "        interactive - If True the first parameter map 'E_p(q=0)' will be set\n",
    "                      to adjust the line scan. Default is set to True as the\n",
    "                      starting class parameter self.line is not initialized\n",
    "                      at the first attempt. Only recommended to set to False\n",
    "                      if line scan parameters are already set to the class\n",
    "                      attribute self.line (see Line2DROI in hyperspy doc for\n",
    "                                           further information)\n",
    "                                           \n",
    "        show - If True plotting the resulting optimized function to the linescan.\n",
    "               Recommended to be False as results are saved in self.linescan_plots\n",
    "               dictionary and plotting all line scans to seperate figures takes\n",
    "               some time for matplotlib\n",
    "               \n",
    "        position - Does nothing yet\n",
    "        \n",
    "        sensitivity - Scaling factor of minimum sigma condition of bounds for\n",
    "                      least squared minimization\n",
    "                      \n",
    "        maxpeakn,medfilt_radius,peakgroup\n",
    "          maxpeakn  - Maximum peaks that are estimated O'Haver algorythm,\n",
    "          medfilter - median filter for smoothing line scan (scipy medfilter),\n",
    "          peakgroup - Maximum neighbouring points taken for peak height est.\n",
    "                      See hyperspy documentation for further information on \n",
    "                      O'Haver peak estimation\n",
    "        \n",
    "        number - if specified the number will be written to the figure title\n",
    "                 of the corresponding line scan to enumerate the line scans\n",
    "                 for on SI evaluation. Attention: not supported fully yet!\n",
    "                 \n",
    "        std_by_fitting - If True taking parameter uncertainties by fitting\n",
    "                         estimation of the calculated Fit_Model to estimate\n",
    "                         line scan standard deviation property instead of \n",
    "                         spatial standard deviation\n",
    "        \"\"\"\n",
    "        res = [param_map for param_map in list(self.param_dict.keys()) \n",
    "               if 'Plasmon energy - $E_{p}(q=0)$' in param_map\n",
    "              ]\n",
    "        \n",
    "        width = 5 * abs(self.param_dict[res[0]].axes_manager[0].scale)\n",
    "        estimate_shift  = [r'thickness by log-ratio',\n",
    "                           r'Plasmon peak - $E_{\\max}$', \n",
    "                           r'Plasmon peak - $\\Gamma$',\n",
    "                           r'Plasmon peak - intensity', \n",
    "                           r'Zero Loss peak - intensity',\n",
    "                           r'Plasmon energy - $E_{p}(q=0)$', \n",
    "                           r'intensity ratio - $I_{pp}/I_{zlp}$'\n",
    "                          ]\n",
    "        \n",
    "        thickness = estimate_shift[0]\n",
    "        \n",
    "        if (parameter_shifts == True):\n",
    "            if (self.line == None):\n",
    "                self.generate_linescan(self.param_dict[res[0]],\n",
    "                                       order,\n",
    "                                       number,\n",
    "                                       width,\n",
    "                                       interactive = True,\n",
    "                                       cmap = cmap,\n",
    "                                       std_by_fitting = std_by_fitting\n",
    "                                      )\n",
    "                \n",
    "            else:\n",
    "                self.generate_linescan(self.param_dict[res[0]],\n",
    "                                       order,\n",
    "                                       number,\n",
    "                                       width,\n",
    "                                       interactive = False,\n",
    "                                       cmap = cmap,\n",
    "                                       std_by_fitting = std_by_fitting\n",
    "                                      )\n",
    "                \n",
    "            \n",
    "                \n",
    "            self.estimate_parametershift(\n",
    "                self.linescans[res[0]],\n",
    "                show,\n",
    "                force_positive = try_force_positive,\n",
    "                force_negative = try_force_negative,\n",
    "                slope_th       = slope_th,\n",
    "                position    = position,\n",
    "                sensitivity = sensitivity,\n",
    "                maxpeakn    = maxpeakn,\n",
    "                medfilt     = medfilt_radius,\n",
    "                peakgroup   = peakgroup,\n",
    "                poly_gradn  = polygradn\n",
    "            )\n",
    "            \n",
    "            if (self.thickness_map != None):\n",
    "                self.generate_linescan(self.param_dict[thickness],\n",
    "                                       order,\n",
    "                                       number,\n",
    "                                       width,\n",
    "                                       interactive = False,\n",
    "                                       cmap = cmap,\n",
    "                                       std_by_fitting = std_by_fitting\n",
    "                                      )\n",
    "\n",
    "                self.estimate_parametershift(\n",
    "                    self.linescans[thickness],\n",
    "                    show,\n",
    "                    force_positive = try_force_positive,\n",
    "                    force_negative = try_force_negative,\n",
    "                    slope_th       = slope_th,\n",
    "                    position    = position,\n",
    "                    sensitivity = sensitivity,\n",
    "                    maxpeakn    = maxpeakn,\n",
    "                    medfilt     = medfilt_radius,\n",
    "                    peakgroup   = peakgroup,\n",
    "                    poly_gradn  = polygradn,\n",
    "                    only_poly   = True\n",
    "                )\n",
    "\n",
    "            for param_title in self.param_dict:\n",
    "                if (param_title not in res and param_title != thickness):\n",
    "                    self.generate_linescan(self.param_dict[param_title],\n",
    "                                           order,\n",
    "                                           number,\n",
    "                                           self.line.linewidth,\n",
    "                                           interactive = False,\n",
    "                                           std_by_fitting = std_by_fitting\n",
    "                                          )\n",
    "\n",
    "                    if (param_title in estimate_shift):\n",
    "                        self.estimate_parametershift(\n",
    "                            self.linescans[param_title],\n",
    "                            show,\n",
    "                            force_positive = try_force_positive,\n",
    "                            force_negative = try_force_negative,\n",
    "                            slope_th       = slope_th,\n",
    "                            position    = position,\n",
    "                            sensitivity = sensitivity,\n",
    "                            maxpeakn    = maxpeakn,\n",
    "                            medfilt     = medfilt_radius,\n",
    "                            peakgroup   = peakgroup,\n",
    "                            poly_gradn  = polygradn\n",
    "                        )\n",
    "                        \n",
    "                    else:\n",
    "                        offset = self.linescans[param_title].axes_manager.signal_axes[0].offset\n",
    "                        size = self.linescans[param_title].axes_manager.signal_axes[0].size \n",
    "                        scale = self.linescans[param_title].axes_manager.signal_axes[0].scale\n",
    "                        max_pos = offset + scale * size\n",
    "\n",
    "                        linescan_pos         = np.linspace(offset, max_pos, size)\n",
    "                        linescan_func_pos    = np.linspace(offset, max_pos, size*100)\n",
    "                        \n",
    "                        fig=self.plot_pshift(self.linescans[param_title],\n",
    "                                             linescan_pos,\n",
    "                                             linescan_func_pos,\n",
    "                                             np.full(3, 0.),\n",
    "                                             None,\n",
    "                                             np.full(polygradn, 0.),\n",
    "                                             None,\n",
    "                                             show=show\n",
    "                                            ) \n",
    "\n",
    "                        key_scan = {self.linescans[param_title].metadata.General.title : fig}\n",
    "                        \n",
    "                        self.linescan_plots.update(key_scan)\n",
    "            \n",
    "                \n",
    "        if (parameter_shifts == False):\n",
    "            if (self.line == None):\n",
    "                self.generate_linescan(self.param_dict[res[0]],\n",
    "                                       order,\n",
    "                                       number,\n",
    "                                       width,\n",
    "                                       interactive = True,\n",
    "                                       cmap = cmap\n",
    "                                      )\n",
    "                \n",
    "            else:\n",
    "                self.generate_linescan(self.param_dict[res[0]],\n",
    "                                       order,\n",
    "                                       number,\n",
    "                                       width,\n",
    "                                       interactive = False,\n",
    "                                       cmap = cmap\n",
    "                                      )\n",
    "                \n",
    "            fig=self.plot_pshift(self.linescans[res[0]],\n",
    "                                 linescan_pos,\n",
    "                                 linescan_func_pos,\n",
    "                                 np.full(3, 0.),\n",
    "                                 None,\n",
    "                                 np.full(polygradn, 0.),\n",
    "                                 None,\n",
    "                                 show=show\n",
    "                                ) \n",
    "\n",
    "            key_scan = {self.linescans[res[0]].metadata.General.title : fig}\n",
    "            \n",
    "            self.linescan_plots.update(key_fig)\n",
    "            \n",
    "            if (self.thickness_map != None):\n",
    "                self.generate_linescan(self.param_dict[thickness],\n",
    "                                       order,\n",
    "                                       number,\n",
    "                                       width,\n",
    "                                       interactive = False,\n",
    "                                       cmap = cmap,\n",
    "                                       std_by_fitting = std_by_fitting\n",
    "                                      )\n",
    "            \n",
    "            fig=self.plot_pshift(self.param_dict[thickness],\n",
    "                                 linescan_pos,\n",
    "                                 linescan_func_pos,\n",
    "                                 np.full(3, 0.),\n",
    "                                 None,\n",
    "                                 np.full(polygradn, 0.),\n",
    "                                 None,\n",
    "                                 show=show\n",
    "                                ) \n",
    "\n",
    "            key_scan = {self.linescans[thickness].metadata.General.title : fig}\n",
    "            \n",
    "            self.linescan_plots.update(key_fig)\n",
    "            \n",
    "            for param_title in self.param_dict:\n",
    "                if (param_title not in res and param_title != thickness):\n",
    "                    self.generate_linescan(self.param_dict[param_title],\n",
    "                                           order,\n",
    "                                           number,\n",
    "                                           self.line.linewidth,\n",
    "                                           interactive = False\n",
    "                                          )\n",
    "                    \n",
    "                    offset = self.linescans[param_title].axes_manager.signal_axes[0].offset\n",
    "                    size = self.linescans[param_title].axes_manager.signal_axes[0].size \n",
    "                    scale = self.linescans[param_title].axes_manager.signal_axes[0].scale\n",
    "                    max_pos = offset + scale * size\n",
    "\n",
    "                    linescan_pos         = np.linspace(offset, max_pos, size)\n",
    "                    linescan_func_pos    = np.linspace(offset, max_pos, size*100)\n",
    "\n",
    "                    fig=self.plot_pshift(self.linescans[param_title],\n",
    "                                         linescan_pos,\n",
    "                                         linescan_func_pos,\n",
    "                                         np.full(3, 0.),\n",
    "                                         None,\n",
    "                                         np.full(polygradn, 0.),\n",
    "                                         None,\n",
    "                                         show=show\n",
    "                                        ) \n",
    "\n",
    "                    key_scan = {self.linescans[param_title].metadata.General.title : fig}\n",
    "                    self.linescan_plots.update(key_scan)\n",
    "\n",
    "        return\n",
    "    \n",
    "    \n",
    "    def plot_pshift(self,\n",
    "                    linescan,\n",
    "                    linescan_pos,\n",
    "                    linescan_func_pos,\n",
    "                    popt_gaus,\n",
    "                    std_gaus,\n",
    "                    popt_poly,\n",
    "                    std_poly,\n",
    "                    enable_fit=False,\n",
    "                    show=True\n",
    "                   ):\n",
    "        \"\"\"\n",
    "        Plotting the estimated paramter shift in a figure object of matplotlib\n",
    "        Adding a 2-sigma estimation of the parameter-shift location corresponding\n",
    "        to the sheared region\n",
    "        \"\"\"\n",
    "        quantity = {r'Plasmon peak - $E_{\\max}$ '          : 'peak center', \n",
    "                    r'Plasmon peak - $\\Gamma$ '            : 'FWHM', \n",
    "                    r'Plasmon peak - intensity '           : 'intensity', \n",
    "\n",
    "                    r'Zero Loss peak - $E_{\\max}$ '        : 'peak center', \n",
    "                    r'Zero Loss peak - $\\Gamma$ '          : 'FWHM',\n",
    "                    r'Zero Loss peak - intensity '         : 'intensity',\n",
    "\n",
    "                    r'second Plasmon peak - $E_{\\max}$ '   : 'peak center', \n",
    "                    r'second Plasmon peak - $\\Gamma$ '     : 'FWHM', \n",
    "                    r'second Plasmon peak - intensity '    : 'intensity',\n",
    "\n",
    "                    r'Plasmon energy - $E_{p}(q=0)$ '      : 'plasmon energy', \n",
    "                    r'intensity ratio - $I_{pp}/I_{zlp}$ ' : 'intensity ratio',\n",
    "                  \n",
    "                    r'thickness by log-ratio '             : 'thickness'\n",
    "                 }\n",
    "\n",
    "        #estimate parameter shifts due to shear band influence\n",
    "        def func_gaus(x, x0, height, sigma):\n",
    "            return height * np.exp(- 1/(2 * sigma**2) * (x - x0)**2)\n",
    "\n",
    "        def std_decimals(std_all, num):\n",
    "            for i in range(len(std_all)):\n",
    "                std = std_all[i]\n",
    "                rounding = 10**(-num)\n",
    "                \n",
    "                if (round(std, num) == 0.0):\n",
    "                    std_all[i] = std + rounding\n",
    "\n",
    "            return np.round(std_all, num)\n",
    "        \n",
    "        title      = linescan.metadata.General.title.encode('unicode-escape').decode().replace('\\\\\\\\', '\\\\')\n",
    "        linescan.axes_manager.signal_axes[0].name = 'Position'\n",
    "        #title_corr = self.check_underscores_in_title(title)\n",
    "        #linescan.metadata.General.title = title_corr\n",
    "\n",
    "        \n",
    "        if (not linescan.metadata.General.title.split('-',-1)[2].endswith('n')):\n",
    "            number = linescan.metadata.General.title.split('-',-1)[2][-1:]\n",
    "\n",
    "            fig = plt.figure(num = title + ' ' + number)\n",
    "            plt.title(title + ' ' + number)\n",
    "        else:\n",
    "\n",
    "            fig = plt.figure(num = title)\n",
    "            plt.title(title)\n",
    "        \n",
    "        name_x = linescan.axes_manager.signal_axes[0].name\n",
    "        unit_x = linescan.axes_manager.signal_axes[0].units\n",
    "        \n",
    "        component = linescan.metadata.General.title.split('-',-1)[0]\n",
    "        parameter = linescan.metadata.General.title.split('-',-1)[1]\n",
    "        \n",
    "        component.encode('unicode-escape').decode().replace('\\\\\\\\', '\\\\')\n",
    "        parameter.encode('unicode-escape').decode().replace('\\\\\\\\', '\\\\')\n",
    "        #if (component in list(quantity.keys())[-1]):\n",
    "        #    name_y = quantity[component]\n",
    "            \n",
    "        #else:\n",
    "        dict_entry = component + '-' + parameter\n",
    "        \n",
    "        name_y = quantity[dict_entry]\n",
    "        \n",
    "        unit_y = linescan.metadata.Signal.quantity\n",
    "\n",
    "        plt.xlabel(name_x + ' in ' + unit_x)\n",
    "        plt.ylabel(name_y + ' in ' + unit_y)\n",
    "\n",
    "        #plt.plot(linescan_pos, \n",
    "        #         linescan.data,\n",
    "        #         'rx',\n",
    "        #         label=parameter\n",
    "        #        )\n",
    "        sigma = self.sigma_calc(linescan)\n",
    "        plt.errorbar(linescan_pos, \n",
    "                     linescan.data,\n",
    "                     yerr=sigma,\n",
    "                     fmt='rx',\n",
    "                     label=parameter\n",
    "                    )\n",
    "        \n",
    "        plt.ylim(np.nanmin(linescan.data)-2*np.nanmax(sigma),\n",
    "                 np.nanmax(linescan.data)+2*np.nanmax(sigma)\n",
    "                )\n",
    "\n",
    "        if ((np.isfinite(np.array(std_gaus,dtype=float)).all() \n",
    "            or np.isfinite(np.array(std_poly,dtype=float)).all()) \n",
    "            and enable_fit==True):\n",
    "            \n",
    "            if (std_gaus != None and std_poly != None):\n",
    "                popt_gaus_r = np.round(popt_gaus,5)\n",
    "                popt_poly_r = np.round(popt_poly,5)\n",
    "                popt_all_r  = np.append(popt_gaus, popt_poly)\n",
    "\n",
    "                std_gaus_r  = std_decimals(std_gaus, 3)\n",
    "                std_poly_r  = std_poly\n",
    "\n",
    "                mean        = np.mean(linescan.data)\n",
    "\n",
    "                label_poly  = ''\n",
    "                for i in range(len(popt_poly)):\n",
    "                    values_str   = '$P_{%s}=%.3E \\pm %.3E$ in ' % tuple((str(i), \n",
    "                                                                         popt_poly_r[i], \n",
    "                                                                         std_poly_r[i]\n",
    "                                                                        )\n",
    "                                                                       )\n",
    "\n",
    "                    if (i == 0):\n",
    "                        units_str    = ('$\\mathrm{%s}$') % tuple((unit_y,))\n",
    "                    else:\n",
    "                        units_str    = ('$\\mathrm{%s}/\\mathrm{%s}^%s$') % tuple((unit_y,unit_x,str(i)))\n",
    "\n",
    "                    p_string     = values_str+units_str\n",
    "                    label_poly  += '\\n'+p_string\n",
    "\n",
    "                label_str1          = ('polynomial fit: '\n",
    "                                       +label_poly\n",
    "                                      )\n",
    "                label_str2          = ('gaussian fit (+ mean of linescan):\\n'\n",
    "                                       +r'$x_0=%5.3f \\pm %5.3f$ in '+unit_x+',\\n'\n",
    "                                       +r'$A_\\mathrm{gauß}=%5.3f \\pm %5.3f$ in '+unit_y+',\\n'\n",
    "                                       +r'$\\sigma=%5.3f \\pm %5.3f$ in '+unit_x\n",
    "                                      )\n",
    "                \n",
    "                func_poly = poly.Polynomial(popt_poly)\n",
    "\n",
    "                val_gaus  = func_gaus(linescan_func_pos, *popt_gaus)\n",
    "                val_poly  = func_poly(linescan_func_pos)\n",
    "\n",
    "                std_2 = popt_gaus[-1] * 2\n",
    "                x0    = popt_gaus[0]\n",
    "\n",
    "                ax_min   = linescan.axes_manager.signal_axes[0].offset\n",
    "                ax_scale = linescan.axes_manager.signal_axes[0].scale\n",
    "                ax_size  = linescan.axes_manager.signal_axes[0].size\n",
    "\n",
    "                ax_max = ax_min + ax_scale * ax_size\n",
    "                \n",
    "                plt.plot(linescan_func_pos, \n",
    "                         val_poly, \n",
    "                         'g--', \n",
    "                         label=(label_str1)\n",
    "                        )\n",
    "                \n",
    "                if ((abs(popt_gaus) > np.full(len(popt_gaus),0.0)).any()):\n",
    "\n",
    "                    if (x0-std_2 < ax_min or x0+std_2 > ax_max):\n",
    "                        label_all = ('Sum of polynomial and gaussian function\\n'\n",
    "                                     +' [Peak out of bounds]'\n",
    "                                    )\n",
    "                        \n",
    "\n",
    "                    else:\n",
    "                        plt.axvspan(x0-std_2, x0+std_2, color='red', alpha=0.2)\n",
    "                        label_all = 'Sum of polynomial and gaussian function'\n",
    "                    \n",
    "                    tup_gaus       = [None]*(len(popt_gaus)+len(std_gaus))\n",
    "                    tup_gaus[::2]  = popt_gaus_r\n",
    "                    tup_gaus[1::2] = std_gaus_r\n",
    "\n",
    "                    plt.plot(linescan_func_pos, \n",
    "                             val_gaus + mean, \n",
    "                             'b--', \n",
    "                             label=(label_str2 % tuple(tup_gaus))\n",
    "                            )\n",
    "\n",
    "                    plt.plot(linescan_func_pos, \n",
    "                             val_gaus + val_poly, \n",
    "                             'r-', \n",
    "                             label='Sum of linear and gaussian function'\n",
    "                            )\n",
    "\n",
    "        plt.legend(prop={'size': 9})\n",
    "\n",
    "\n",
    "        if (show == True):\n",
    "            fig.show()\n",
    "\n",
    "        else:\n",
    "            plt.close()\n",
    "\n",
    "        return fig\n",
    "        \n",
    "        \n",
    "    def sigma_calc(self, linescan):\n",
    "        sigma         = np.sqrt(linescan.metadata.Signal.Noise_properties.variance.data)\n",
    "        sigma_fin     = np.where(np.isfinite(sigma))[0]\n",
    "        sigma_nonzero = np.where(np.nonzero(sigma))[0]\n",
    "        \n",
    "        sigma_def     = np.where(sigma_fin != sigma_nonzero)[0]\n",
    "        \n",
    "        sigma_nan     = np.where(np.isnan(sigma))[0]\n",
    "        sigma_inf     = np.where(np.isinf(sigma))[0]\n",
    "        \n",
    "        sigma_undef   = np.concatenate((sigma_nonzero, sigma_nan, sigma_inf), axis=0)\n",
    "        \n",
    "        sigma_calc  = np.empty(len(sigma))\n",
    "        \n",
    "        for idx in range(len(sigma)):\n",
    "            if (idx in sigma_def):\n",
    "                sigma_calc[idx] = sigma[idx]\n",
    "            else:\n",
    "                sigma_calc[idx] = np.mean(sigma[sigma_nonzero])\n",
    "        \n",
    "        return sigma_calc\n",
    "        \n",
    "        \n",
    "    def polynomial_fitting(self,\n",
    "                           linescan,\n",
    "                           poly_gradn\n",
    "                          ):\n",
    "        size                 = linescan.axes_manager.signal_axes[0].size\n",
    "        scale                = linescan.axes_manager.signal_axes[0].scale\n",
    "        offset               = linescan.axes_manager.signal_axes[0].offset\n",
    "        max_pos              = offset + size * scale\n",
    "\n",
    "        linescan_pos         = np.linspace(offset, max_pos, size)\n",
    "        linescan_func_pos    = np.linspace(offset, max_pos, size*100)\n",
    "        \n",
    "        #estimate weights using gaussian distribution to weight points near \n",
    "        #linescan axis limits more strongly\n",
    "        def func_gaus_distribution(x, x0, height, sigma):\n",
    "            return height/(sigma*np.sqrt(2*np.pi)) * np.exp(- 1/(2 * sigma**2) * (x - x0)**2)\n",
    "        \n",
    "        border_bounds = np.full(size, 1.)\n",
    "        for i in range(len(border_bounds)):\n",
    "            border_bounds[i] = ((1-func_gaus_distribution(scale*i+offset, \n",
    "                                                          (max_pos - offset)/2, \n",
    "                                                          1., \n",
    "                                                          (max_pos - offset)*2\n",
    "                                                         )\n",
    "                                )\n",
    "                               )\n",
    "            \n",
    "        print('weight factors: ', border_bounds)\n",
    "        \n",
    "        sigma_finite = self.sigma_calc(linescan)\n",
    "        \n",
    "        weights = np.full(size, np.sqrt(size)) / border_bounds\n",
    "        popt_poly, pcov_poly = poly.polyfit(linescan_pos, linescan.data, poly_gradn, full=True, w=weights)\n",
    "        print('\\nfitted initial polynomial parameter: ', popt_poly)\n",
    "\n",
    "        \n",
    "        def func_poly(x, *popt_poly):\n",
    "            poly_func = poly.Polynomial(popt_poly)\n",
    "            return poly_func(x)\n",
    "            \n",
    "        popt_poly, pcov_poly = curve_fit(func_poly, \n",
    "                                         linescan_pos, \n",
    "                                         linescan.data,\n",
    "                                         p0 = popt_poly,\n",
    "                                         maxfev=10000,\n",
    "                                         sigma =sigma_finite\n",
    "                                        )\n",
    "        \n",
    "        print('\\npolynomial weighted least squared fit: ', popt_poly, pcov_poly)\n",
    "        return popt_poly, pcov_poly\n",
    "    \n",
    "    \n",
    "    def arrange_peaks(self, \n",
    "                      peaks_ar, \n",
    "                      is_negative=False\n",
    "                     ):\n",
    "        peaks = peaks_ar[0]\n",
    "\n",
    "        pos    = 'position'\n",
    "        height = 'height'\n",
    "        width  = 'width'\n",
    "        nrows  = len(peaks)\n",
    "\n",
    "        if nrows != 0:\n",
    "            x0    = peaks[pos].astype(float)\n",
    "            A     = peaks[height].astype(float)\n",
    "            sigma = peaks[width].astype(float)\n",
    "\n",
    "        else:\n",
    "            x0     = [0.]\n",
    "            A      = [0.]\n",
    "            sigma  = [0.]\n",
    "            nrows += 1\n",
    "\n",
    "\n",
    "        if is_negative:\n",
    "            peaks = [(x0[i],-1*A[i], sigma[i]) for i in range(nrows)]\n",
    "        \n",
    "        else:\n",
    "            peaks = [(x0[i],   A[i], sigma[i]) for i in range(nrows)]\n",
    "\n",
    "        return peaks\n",
    "        \n",
    "        \n",
    "    def estimate_parametershift(self,\n",
    "                                linescan,\n",
    "                                show,\n",
    "                                force_positive = False,\n",
    "                                force_negative = False,\n",
    "                                enable_fit  = False,\n",
    "                                slope_th    = 0.,\n",
    "                                position    = 1.,\n",
    "                                maxpeakn    = 10,\n",
    "                                medfilt     = 3,\n",
    "                                peakgroup   = 10,\n",
    "                                sensitivity = 3,\n",
    "                                poly_gradn  = 2,\n",
    "                                only_poly   = False\n",
    "                               ):\n",
    "        \"\"\"\n",
    "        Calculate a parametershift by line scan analysis using a gaussian estimation\n",
    "        for signifcant shifts and a linear estimation for thickness dependence.\n",
    "        \"\"\"\n",
    "        print('\\nEstimation for: ' + linescan.metadata.General.title + '\\n')\n",
    "        \n",
    "        #estimate parameter shifts due to shear band influence\n",
    "        def func_gaus(x, x0, height, sigma):\n",
    "            return height * np.exp(- 1/(2 * sigma**2) * (x - x0)**2)\n",
    "\n",
    "        size                 = linescan.axes_manager.signal_axes[0].size\n",
    "        scale                = linescan.axes_manager.signal_axes[0].scale\n",
    "        offset               = linescan.axes_manager.signal_axes[0].offset\n",
    "        max_pos              = offset + size * scale\n",
    "\n",
    "        if (position == 1.):\n",
    "            position == (max_pos - offset) / 2\n",
    "            if (self.x0):\n",
    "                position = self.x0\n",
    "\n",
    "        else: \n",
    "            if (self.x0):\n",
    "                position = self.x0\n",
    "            else:\n",
    "                position = position\n",
    "\n",
    "        linescan_pos         = np.linspace(offset, max_pos, size)\n",
    "        linescan_func_pos    = np.linspace(offset, max_pos, size*100)\n",
    "        \n",
    "        sigma_finite = self.sigma_calc(linescan)\n",
    "        \n",
    "        mean = np.nanmean(linescan.data)\n",
    "        std  = np.nanstd(linescan.data)\n",
    "\n",
    "        popt_poly, pcov_poly = self.polynomial_fitting(linescan, poly_gradn)\n",
    "        \n",
    "        poly_val             = poly.polyval(linescan_pos, popt_poly)\n",
    "        \n",
    "        if (only_poly == False):\n",
    "            substracted          = hs.signals.Signal1D(linescan.data - poly_val)\n",
    "            substracted_inv      = hs.signals.Signal1D(poly_val - linescan.data)\n",
    "\n",
    "\n",
    "            # set the signal axis for both signals\n",
    "            substracted.axes_manager.signal_axes     = linescan.axes_manager.signal_axes\n",
    "            substracted_inv.axes_manager.signal_axes = linescan.axes_manager.signal_axes\n",
    "\n",
    "            if ('intensity' in linescan.metadata.General.title):\n",
    "                amp_thresh = std*0.01*(max_pos-offset)/2\n",
    "\n",
    "            elif ('Gamma' in linescan.metadata.General.title):\n",
    "                amp_thresh = std*0.01*(max_pos-offset)/2\n",
    "\n",
    "            else:\n",
    "                amp_thresh = std*0.01*(max_pos-offset)/2\n",
    "\n",
    "\n",
    "            if (force_positive == True):\n",
    "                try:\n",
    "                    peaks_positive       = substracted.find_peaks1D_ohaver(maxpeakn = maxpeakn,\n",
    "                                                                           medfilt_radius=medfilt,\n",
    "                                                                           slope_thresh=0,\n",
    "                                                                           amp_thresh=amp_thresh,\n",
    "                                                                           peakgroup=peakgroup\n",
    "                                                                          )\n",
    "                    print('OHaver estimates: ', peaks_positive)\n",
    "\n",
    "                except:\n",
    "                    peaks_positive       = [np.array([(0.,0.,1.)],\n",
    "                                                     dtype=[('position', '<f8'), ('height', '<f8'), ('width', '<f8')])]\n",
    "                    \n",
    "                peaks_result = self.arrange_peaks(peaks_positive, is_negative=False)\n",
    "\n",
    "            elif (force_negative == True):\n",
    "                try:\n",
    "                    peaks_negative       = substracted_inv.find_peaks1D_ohaver(maxpeakn = maxpeakn,\n",
    "                                                                               medfilt_radius=medfilt,\n",
    "                                                                               slope_thresh=slope_th,\n",
    "                                                                               amp_thresh=amp_thresh,\n",
    "                                                                               peakgroup=peakgroup\n",
    "                                                                              )\n",
    "\n",
    "                    print('OHaver estimates: ', peaks_negative)\n",
    "\n",
    "                except:\n",
    "                    peaks_negative       = [np.array([(0.,0.,1.)],\n",
    "                                                     dtype=[('position', '<f8'), ('height', '<f8'), ('width', '<f8')])]\n",
    "                \n",
    "                peaks_result = self.arrange_peaks(peaks_negative, is_negative=True)\n",
    "\n",
    "            else:\n",
    "                try:\n",
    "                    peaks_positive       = substracted.find_peaks1D_ohaver(maxpeakn = maxpeakn,\n",
    "                                                                           medfilt_radius=medfilt,\n",
    "                                                                           slope_thresh=slope_th,\n",
    "                                                                           amp_thresh=amp_thresh,\n",
    "                                                                           peakgroup=peakgroup\n",
    "                                                                          )\n",
    "                    print('OHaver estimates: ', peaks_positive)\n",
    "\n",
    "                except:\n",
    "                    peaks_positive       = [np.array([(0.,0.,1.)],\n",
    "                                                     dtype=[('position', '<f8'), ('height', '<f8'), ('width', '<f8')])]\n",
    "                \n",
    "                try:\n",
    "                    peaks_negative       = substracted_inv.find_peaks1D_ohaver(maxpeakn = maxpeakn,\n",
    "                                                                               medfilt_radius=medfilt,\n",
    "                                                                               slope_thresh=slope_th,\n",
    "                                                                               amp_thresh=amp_thresh,\n",
    "                                                                               peakgroup=peakgroup\n",
    "                                                                              )\n",
    "\n",
    "                    print('OHaver estimates: ', peaks_negative)\n",
    "\n",
    "                except:\n",
    "                    peaks_negative       = [np.array([(0.,0.,1.)],\n",
    "                                                     dtype=[('position', '<f8'), ('height', '<f8'), ('width', '<f8')])]\n",
    "            \n",
    "\n",
    "                peaks_pos = self.arrange_peaks(peaks_positive,is_negative=False)\n",
    "                peaks_neg = self.arrange_peaks(peaks_negative,is_negative=True)\n",
    "                peaks_result = np.concatenate((peaks_pos, peaks_neg), axis=0)\n",
    "            \n",
    "            result = self.check_peaks(peaks_result, position, max_pos, scale, offset, sensitivity)\n",
    "\n",
    "            if ((result == np.array([0.,0.,1.])).all()):\n",
    "                print('The parameter shifts found do not match expected ranges for gaussian estimation.'\n",
    "                      +'\\nMaybe sensitivity (scaling of lower bound of sigma), medfilt_radius (smoothing) or '\n",
    "                      +'\\npolygradn (higher DOF for thickness dependence) can lead improved peak estimation '\n",
    "                      +'\\nusing Ohaver.\\n')\n",
    "\n",
    "                popt_all, pcov_all = self.set_pgaus_zero(popt_poly, pcov_poly)\n",
    "\n",
    "            else:\n",
    "                # filter the most dominant peak by height to exclude broad peaks\n",
    "                # taken into account by area estimation\n",
    "                if (abs(result[1]) > abs(result[1])):\n",
    "                    params = result\n",
    "                    #params = np.round([peak[0], peak[1], peak[2]],5)\n",
    "                    # trafo fwhm|sigma:  abs(1/(2*np.sqrt(2*np.log(2)))*peak[2]\n",
    "\n",
    "                else:\n",
    "                    params = result\n",
    "                    #params = np.round([peak[0], -1*abs(peak[1]), peak[2]],5)\n",
    "                    # trafo fwhm|sigma:  abs(1/(2*np.sqrt(2*np.log(2)))*peak[2]\n",
    "\n",
    "                print('\\nUsed estimate for most dominant gaussian peak in bounds: ', result)\n",
    "\n",
    "                x0_min = params[0] - 2*params[2]\n",
    "                x0_max = params[0] + 2*params[2]\n",
    "\n",
    "                sigma_min = 1/2 * params[2]\n",
    "                sigma_max =   2 * params[2] \n",
    "\n",
    "                gaus_min = params[1] - (1/2*abs(std))\n",
    "                gaus_max = params[1] + (1/2*abs(std)) \n",
    "\n",
    "                bounds_gaus = ([x0_min, gaus_min, sigma_min],\n",
    "                               [x0_max, gaus_max, sigma_max]\n",
    "                              )\n",
    "\n",
    "                #check if peak_params in bounds and correct if needed\n",
    "                for i in range(len(params)):\n",
    "                    if (params[i] < bounds_gaus[0][i] or params[i] > bounds_gaus[1][i]):\n",
    "                        if (params[i] < bounds_gaus[0][i]):\n",
    "                            params[i] = bounds_gaus[0][i]\n",
    "                        elif (params[i] > bounds_gaus[1][i]):\n",
    "                            params[i] = bounds_gaus[1][i]\n",
    "\n",
    "\n",
    "                try:\n",
    "                    popt_gaus, pcov_gaus = curve_fit(func_gaus,\n",
    "                                                     linescan_pos, \n",
    "                                                     linescan.data - poly_val, \n",
    "                                                     p0 = params,\n",
    "                                                     bounds = bounds_gaus,\n",
    "                                                     max_nfev=10000,\n",
    "                                                     sigma = sigma_finite\n",
    "                                                    )\n",
    "\n",
    "                    #length   = len(popt_poly)\n",
    "                    #popt_all = np.concatenate((popt_gaus,popt_poly),axis=0)\n",
    "                    #pcov_all = np.full((len(popt_all), len(popt_all)), \n",
    "                    #                   0.\n",
    "                    #                  )\n",
    "\n",
    "                    #for i in range(len(popt_all)):\n",
    "                    #    for j in range(len(popt_all)):\n",
    "                    #        print(i, j)\n",
    "                    #        if (i < len(popt_gaus) and j < len(popt_gaus)):\n",
    "                    #            pcov_all[i][j] = pcov_gaus[i][j]\n",
    "                    #            print('if')\n",
    "                    #        else:\n",
    "                    #            pcov_all[i][j] = np.nan\n",
    "\n",
    "\n",
    "                    def func_all(x, x0, height, sigma, *popt_poly):\n",
    "                        poly_func = poly.Polynomial(popt_poly)\n",
    "\n",
    "                        return height * np.exp(- 1/(2 * sigma**2) * (x - x0)**2) + poly_func(x)\n",
    "\n",
    "                    popt_all_init        = [*popt_gaus, *popt_poly]\n",
    "                    popt_all, pcov_all   = curve_fit(func_all, \n",
    "                                                     linescan_pos, \n",
    "                                                     linescan.data,\n",
    "                                                     p0 = popt_all_init,\n",
    "                                                     maxfev=10000,\n",
    "                                                     sigma=sigma_finite\n",
    "                                                    )\n",
    "\n",
    "                except RuntimeError as err: \n",
    "                    print('Optimal parameters not found:' \n",
    "                          +str(err)\n",
    "                         )\n",
    "\n",
    "                    popt_all, pcov_all = self.set_pgaus_zero(popt_poly, pcov_poly)\n",
    "\n",
    "                #sigma shall be positive all times\n",
    "                popt_all[2] = abs(popt_all[2])\n",
    "\n",
    "                if (np.isfinite(popt_all[2])):\n",
    "                    if (self.x0_err == None):\n",
    "                        #set to infinity\n",
    "                        self.x0_err = np.Infinity\n",
    "                    if (abs(self.x0_err) > abs(pcov_all[2][2])):\n",
    "                        self.x0_err = pcov_all[2][2]\n",
    "                        self.x0     = popt_all[2]\n",
    "                        print('\\nPosition estimation of sheared region with lower standard deviation:\\n'\n",
    "                              +'$%5.3f \\pm %5.3f' % tuple([self.x0, self.x0_err]))\n",
    "\n",
    "        else:\n",
    "            popt_all, pcov_all = self.set_pgaus_zero(popt_poly, pcov_poly)\n",
    "        \n",
    "        lengaus = 3\n",
    "        popt_gaus_f = popt_all[:lengaus]\n",
    "        popt_poly_f = popt_all[lengaus:]\n",
    "\n",
    "        std_gaus_f  = [pcov_all[i][i] for i in range(lengaus)]\n",
    "        std_poly_f  = [pcov_all[i+lengaus][i+lengaus] for i in range(len(popt_all)-lengaus)]\n",
    "\n",
    "        print('\\nFit summarization - resulting parameters: ', popt_all)\n",
    "        print('\\nFit summarization - resulting covariance matrix: ', pcov_all)\n",
    "        \n",
    "        fig=self.plot_pshift(linescan,\n",
    "                             linescan_pos,\n",
    "                             linescan_func_pos,\n",
    "                             popt_gaus_f,\n",
    "                             std_gaus_f,\n",
    "                             popt_poly_f,\n",
    "                             std_poly_f,\n",
    "                             enable_fit=True,\n",
    "                             show=show\n",
    "                            )\n",
    "        \n",
    "        key_scan = {linescan.metadata.General.title : fig}\n",
    "        \n",
    "        self.linescan_plots.update(key_scan)\n",
    "        \n",
    "        return\n",
    "\n",
    "    \n",
    "    def set_pgaus_zero(self, popt_poly, pcov_poly):\n",
    "        popt_gaus = [0.,0.,0.]\n",
    "        pcov_gaus = np.full((len(popt_gaus), \n",
    "                             len(popt_gaus)\n",
    "                            ), np.inf\n",
    "                           )\n",
    "\n",
    "        length   = len(popt_poly)\n",
    "        popt_all = np.concatenate((popt_gaus,popt_poly),axis=0)\n",
    "        pcov_all = np.full((length+len(popt_gaus), \n",
    "                            length+len(popt_gaus)\n",
    "                           ), np.inf\n",
    "                          )\n",
    "\n",
    "        for i in range(len(popt_all)):\n",
    "            for j in range(len(popt_all)):\n",
    "                if (i < len(popt_gaus) and j < len(popt_gaus)):\n",
    "                    pcov_all[i][j] = pcov_gaus[i][j]\n",
    "                else:\n",
    "                    pcov_all[i][j] = np.nan\n",
    "\n",
    "        return popt_all, pcov_all\n",
    "                        \n",
    "        \n",
    "    def check_peaks(self, peaks, position, max_pos, scale, offset, sensitivity):\n",
    "        \n",
    "        #estimate parameter shifts due to shear band influence\n",
    "        def func_gaus(x, x0, height, sigma):\n",
    "            return height * np.exp(- 1/(2 * sigma**2) * (x - x0)**2)\n",
    "        \n",
    "        results  = []\n",
    "        peak_old = np.array([0.,0.,1.])\n",
    "        minimum  = np.array([])\n",
    "        for peak in list(peaks):\n",
    "            \n",
    "            minimum = np.append(minimum, np.array([peak[1]]))\n",
    "            if (not np.isnan(peak).any()):\n",
    "\n",
    "                if (peak[0]+abs(peak[2]) < max_pos and peak[0]-abs(peak[2]) > offset):\n",
    "                    \n",
    "                    if (abs(peak[1]) >= np.nanmin(abs(minimum))):\n",
    "                        \n",
    "                        if (position < peak[0] + 4*abs(peak[2]) and position > peak[0] - 4*abs(peak[2])):\n",
    "                            results.append(peak)\n",
    "                            print('peak accepted:', peak)\n",
    "            \n",
    "            else:\n",
    "\n",
    "                sigma = abs(scale * sensitivity)\n",
    "                if (peak[0]+abs(sigma) < max_pos and peak[0]-abs(sigma) > offset):\n",
    "                    \n",
    "                    if (abs(peak[1]) >= np.nanmin(abs(minimum))):\n",
    "\n",
    "                        if (position < peak[0] + 4*abs(sigma) and position > peak[0] - 4*abs(sigma)):\n",
    "                            results.append((peak[0], peak[1], sigma))\n",
    "                            print('peak accepted after ignoring bad sigma:', peak)\n",
    "\n",
    "        if (results != []):\n",
    "            \n",
    "            integral = np.empty(len(results))\n",
    "            for i in range(len(results)):\n",
    "                integral[i] = (integrate.quad(lambda x: func_gaus(x,*results[i]), offset, max_pos)[0])\n",
    "\n",
    "            result = results[np.where(integral==np.max(integral))[0][0]]\n",
    "\n",
    "            peak_result = np.array([result[0],result[1],result[2]], dtype=float)\n",
    "            \n",
    "        else:\n",
    "            peak_result = np.array([0.,0.,1.])\n",
    "            \n",
    "        return peak_result\n",
    "    \n",
    "    def cross_correlation(self,\n",
    "                          param_map\n",
    "                         ):\n",
    "        \"\"\"\n",
    "        Cross correlation of HAADF image and a given Plasmon parameter image\n",
    "        while both are nomalized to map values to {0, 1}.\n",
    "        \"\"\"\n",
    "        param_map_norm  = (( self.Ep_q0.data - np.min(self.Ep_q0.data) ) / \n",
    "                           ( np.max(self.Ep_q0.data) - np.min(self.Ep_q0.data) )\n",
    "                          )\n",
    "        \n",
    "        haadf_norm = (( self.haadf.data - np.min(self.haadf.data) ) / \n",
    "                      ( np.max(self.haadf.data) - np.min(self.haadf.data) )\n",
    "                     )\n",
    "\n",
    "        corr = correlate2d(param_map_norm, haadf_norm)\n",
    "\n",
    "        max_corr = np.max(corr)\n",
    "        mean_corr = np.mean(corr)\n",
    "        indices = np.where(corr >= max_corr)\n",
    "\n",
    "        plt.title('Correlation image of HAADF-image and Plasmon peak energy image\\n' +\n",
    "                  'Maximum correlation indices: ' + str(indices[0]) + str(indices[1]) + '\\n' +\n",
    "                  '[HAADF | Ep] - image dimensions: \\n(' + str(np.shape(haadf_norm)[0]) + \n",
    "                  ', ' + str(np.shape(haadf_norm)[1]) + ')' + ',(' + str(np.shape(param_map_norm)[0]) + \n",
    "                  ', ' + str(np.shape(param_map_norm)[1]) + ')'\n",
    "                 )\n",
    "        \n",
    "        plt.imshow(corr,\n",
    "                   cmap='hot'\n",
    "                  )\n",
    "        \n",
    "        return corr\n",
    "    \n",
    "    \n",
    "    def plot_3D(self, \n",
    "                param_map,\n",
    "                colorbar_title,\n",
    "                sigma = 5\n",
    "               ):\n",
    "        \"\"\"\n",
    "        Using mayavi to generate a 3 dimensional surface plot\n",
    "        Additionaly, a gaussian filter is applied to smoothen the data\n",
    "            sigma: standard deviation of gaussian filter setting the level\n",
    "                   of smoothening\n",
    "        \"\"\"\n",
    "        gaus_filt = scipy.ndimage.filters.gaussian_filter(param_map.data, sigma= (sigma, sigma))\n",
    "        \n",
    "        mlab.surf(gaus_filt, warp_scale='auto')\n",
    "        mlab.colorbar(title=colorbar_title, orientation='vertical', label_fmt='%.3f')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
